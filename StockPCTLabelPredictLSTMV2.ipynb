{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StockPCTLabelPredictLSTMV2\n",
      "/mnt/AIWorkSpace/work/fin-ml/data/\n",
      "/mnt/AIWorkSpace/work/fin-ml/runs/StockPCTLabelPredictLSTMV2\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas_datareader.data as web\n",
    "from matplotlib import pyplot\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "#Plotting \n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "#Libraries for Statistical Models\n",
    "import statsmodels.api as sm\n",
    "\n",
    "#logging\n",
    "from MyPyUtil.logconf import logging\n",
    "log = logging.getLogger(__name__)\n",
    "# log.setLevel(logging.ERROR)\n",
    "log.setLevel(logging.INFO)\n",
    "# log.setLevel(logging.WARN)\n",
    "# log.setLevel(logging.DEBUG)\n",
    "\n",
    "\n",
    "#Diable the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.expand_frame_repr = False\n",
    "pd.options.display.float_format = '{:.3f}'.format\n",
    "\n",
    "torch.seed = 42\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "%run 'nb_utils.ipynb'\n",
    "task_name = get_filename_of_ipynb()\n",
    "print(task_name)\n",
    "data_dir = f'{os.getcwd()}/data/'\n",
    "log_dir_base = f'{os.getcwd()}/runs/{task_name}'\n",
    "log_dir = log_dir_base\n",
    "print(f'{data_dir}\\n{log_dir}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-08 06:02:16,799\tINFO worker.py:1715 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ee13c51a3e7408999e6ab0440cafdc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<div class=\"lm-Widget p-Widget lm-Panel p-Panel jp-Cell-outputWrapper\">\n",
       "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
       "        <div class=\"jp-RenderedHTMLCommon\" style=\"display: flex; flex-direction: row;\">\n",
       "  <svg viewBox=\"0 0 567 224\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\" style=\"height: 3em;\">\n",
       "    <g clip-path=\"url(#clip0_4338_178347)\">\n",
       "        <path d=\"M341.29 165.561H355.29L330.13 129.051C345.63 123.991 354.21 112.051 354.21 94.2307C354.21 71.3707 338.72 58.1807 311.88 58.1807H271V165.561H283.27V131.661H311.8C314.25 131.661 316.71 131.501 319.01 131.351L341.25 165.561H341.29ZM283.29 119.851V70.0007H311.82C331.3 70.0007 342.34 78.2907 342.34 94.5507C342.34 111.271 331.34 119.861 311.82 119.861L283.29 119.851ZM451.4 138.411L463.4 165.561H476.74L428.74 58.1807H416L367.83 165.561H380.83L392.83 138.411H451.4ZM446.19 126.601H398L422 72.1407L446.24 126.601H446.19ZM526.11 128.741L566.91 58.1807H554.35L519.99 114.181L485.17 58.1807H472.44L514.01 129.181V165.541H526.13V128.741H526.11Z\" fill=\"var(--jp-ui-font-color0)\"/>\n",
       "        <path d=\"M82.35 104.44C84.0187 97.8827 87.8248 92.0678 93.1671 87.9146C98.5094 83.7614 105.083 81.5067 111.85 81.5067C118.617 81.5067 125.191 83.7614 130.533 87.9146C135.875 92.0678 139.681 97.8827 141.35 104.44H163.75C164.476 101.562 165.622 98.8057 167.15 96.2605L127.45 56.5605C121.071 60.3522 113.526 61.6823 106.235 60.3005C98.9443 58.9187 92.4094 54.9203 87.8602 49.0574C83.3109 43.1946 81.0609 35.8714 81.5332 28.4656C82.0056 21.0599 85.1679 14.0819 90.4252 8.8446C95.6824 3.60726 102.672 0.471508 110.08 0.0272655C117.487 -0.416977 124.802 1.86091 130.647 6.4324C136.493 11.0039 140.467 17.5539 141.821 24.8501C143.175 32.1463 141.816 39.6859 138 46.0505L177.69 85.7505C182.31 82.9877 187.58 81.4995 192.962 81.4375C198.345 81.3755 203.648 82.742 208.33 85.3976C213.012 88.0532 216.907 91.9029 219.616 96.5544C222.326 101.206 223.753 106.492 223.753 111.875C223.753 117.258 222.326 122.545 219.616 127.197C216.907 131.848 213.012 135.698 208.33 138.353C203.648 141.009 198.345 142.375 192.962 142.313C187.58 142.251 182.31 140.763 177.69 138L138 177.7C141.808 184.071 143.155 191.614 141.79 198.91C140.424 206.205 136.44 212.75 130.585 217.313C124.731 221.875 117.412 224.141 110.004 223.683C102.596 223.226 95.6103 220.077 90.3621 214.828C85.1139 209.58 81.9647 202.595 81.5072 195.187C81.0497 187.779 83.3154 180.459 87.878 174.605C92.4405 168.751 98.9853 164.766 106.281 163.401C113.576 162.035 121.119 163.383 127.49 167.19L167.19 127.49C165.664 124.941 164.518 122.182 163.79 119.3H141.39C139.721 125.858 135.915 131.673 130.573 135.826C125.231 139.98 118.657 142.234 111.89 142.234C105.123 142.234 98.5494 139.98 93.2071 135.826C87.8648 131.673 84.0587 125.858 82.39 119.3H60C58.1878 126.495 53.8086 132.78 47.6863 136.971C41.5641 141.163 34.1211 142.972 26.7579 142.059C19.3947 141.146 12.6191 137.574 7.70605 132.014C2.79302 126.454 0.0813599 119.29 0.0813599 111.87C0.0813599 104.451 2.79302 97.2871 7.70605 91.7272C12.6191 86.1673 19.3947 82.5947 26.7579 81.6817C34.1211 80.7686 41.5641 82.5781 47.6863 86.7696C53.8086 90.9611 58.1878 97.2456 60 104.44H82.35ZM100.86 204.32C103.407 206.868 106.759 208.453 110.345 208.806C113.93 209.159 117.527 208.258 120.522 206.256C123.517 204.254 125.725 201.276 126.771 197.828C127.816 194.38 127.633 190.677 126.253 187.349C124.874 184.021 122.383 181.274 119.205 179.577C116.027 177.88 112.359 177.337 108.826 178.042C105.293 178.746 102.113 180.654 99.8291 183.44C97.5451 186.226 96.2979 189.718 96.3 193.32C96.2985 195.364 96.7006 197.388 97.4831 199.275C98.2656 201.163 99.4132 202.877 100.86 204.32ZM204.32 122.88C206.868 120.333 208.453 116.981 208.806 113.396C209.159 109.811 208.258 106.214 206.256 103.219C204.254 100.223 201.275 98.0151 197.827 96.97C194.38 95.9249 190.676 96.1077 187.348 97.4873C184.02 98.8669 181.274 101.358 179.577 104.536C177.879 107.714 177.337 111.382 178.041 114.915C178.746 118.448 180.653 121.627 183.439 123.911C186.226 126.195 189.717 127.443 193.32 127.44C195.364 127.443 197.388 127.042 199.275 126.259C201.163 125.476 202.878 124.328 204.32 122.88ZM122.88 19.4205C120.333 16.8729 116.981 15.2876 113.395 14.9347C109.81 14.5817 106.213 15.483 103.218 17.4849C100.223 19.4868 98.0146 22.4654 96.9696 25.9131C95.9245 29.3608 96.1073 33.0642 97.4869 36.3922C98.8665 39.7202 101.358 42.4668 104.535 44.1639C107.713 45.861 111.381 46.4036 114.914 45.6992C118.447 44.9949 121.627 43.0871 123.911 40.301C126.195 37.515 127.442 34.0231 127.44 30.4205C127.44 28.3772 127.038 26.3539 126.255 24.4664C125.473 22.5788 124.326 20.8642 122.88 19.4205ZM19.42 100.86C16.8725 103.408 15.2872 106.76 14.9342 110.345C14.5813 113.93 15.4826 117.527 17.4844 120.522C19.4863 123.518 22.4649 125.726 25.9127 126.771C29.3604 127.816 33.0638 127.633 36.3918 126.254C39.7198 124.874 42.4664 122.383 44.1635 119.205C45.8606 116.027 46.4032 112.359 45.6988 108.826C44.9944 105.293 43.0866 102.114 40.3006 99.8296C37.5145 97.5455 34.0227 96.2983 30.42 96.3005C26.2938 96.3018 22.337 97.9421 19.42 100.86ZM100.86 100.86C98.3125 103.408 96.7272 106.76 96.3742 110.345C96.0213 113.93 96.9226 117.527 98.9244 120.522C100.926 123.518 103.905 125.726 107.353 126.771C110.8 127.816 114.504 127.633 117.832 126.254C121.16 124.874 123.906 122.383 125.604 119.205C127.301 116.027 127.843 112.359 127.139 108.826C126.434 105.293 124.527 102.114 121.741 99.8296C118.955 97.5455 115.463 96.2983 111.86 96.3005C109.817 96.299 107.793 96.701 105.905 97.4835C104.018 98.2661 102.303 99.4136 100.86 100.86Z\" fill=\"#00AEEF\"/>\n",
       "    </g>\n",
       "    <defs>\n",
       "        <clipPath id=\"clip0_4338_178347\">\n",
       "            <rect width=\"566.93\" height=\"223.75\" fill=\"white\"/>\n",
       "        </clipPath>\n",
       "    </defs>\n",
       "  </svg>\n",
       "</div>\n",
       "\n",
       "        <table class=\"jp-RenderedHTMLCommon\" style=\"border-collapse: collapse;color: var(--jp-ui-font-color1);font-size: var(--jp-ui-font-size1);\">\n",
       "    <tr>\n",
       "        <td style=\"text-align: left\"><b>Python version:</b></td>\n",
       "        <td style=\"text-align: left\"><b>3.8.18</b></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
       "        <td style=\"text-align: left\"><b>2.9.1</b></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "    <td style=\"text-align: left\"><b>Dashboard:</b></td>\n",
       "    <td style=\"text-align: left\"><b><a href=\"http://127.0.0.1:8265\" target=\"_blank\">http://127.0.0.1:8265</a></b></td>\n",
       "</tr>\n",
       "\n",
       "</table>\n",
       "\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "RayContext(dashboard_url='127.0.0.1:8265', python_version='3.8.18', ray_version='2.9.1', ray_commit='cfbf98c315cfb2710c56039a3c96477d196de049', protocol_version=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hyperparameters turning\n",
    "from ray import tune, train, ray\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "\n",
    "ray.init(log_to_driver=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read /mnt/AIWorkSpace/work/fin-ml/data/AAPL.csv completely!\n",
      "AAPL, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/MSFT.csv completely!\n",
      "MSFT, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/AMZN.csv completely!\n",
      "AMZN, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/NVDA.csv completely!\n",
      "NVDA, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/GOOGL.csv completely!\n",
      "GOOGL, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/GOOG.csv completely!\n",
      "GOOG, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/META.csv completely!\n",
      "META, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/TSLA.csv completely!\n",
      "TSLA, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/UNH.csv completely!\n",
      "UNH, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/LLY.csv completely!\n",
      "LLY, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/JPM.csv completely!\n",
      "JPM, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/XOM.csv completely!\n",
      "XOM, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/JNJ.csv completely!\n",
      "JNJ, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/V.csv completely!\n",
      "V, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/PG.csv completely!\n",
      "PG, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/AVGO.csv completely!\n",
      "AVGO, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/MA.csv completely!\n",
      "MA, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/HD.csv completely!\n",
      "HD, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CVX.csv completely!\n",
      "CVX, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/MRK.csv completely!\n",
      "MRK, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/ABBV.csv completely!\n",
      "ABBV, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/PEP.csv completely!\n",
      "PEP, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/COST.csv completely!\n",
      "COST, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/ADBE.csv completely!\n",
      "ADBE, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/KO.csv completely!\n",
      "KO, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CSCO.csv completely!\n",
      "CSCO, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/WMT.csv completely!\n",
      "WMT, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/TMO.csv completely!\n",
      "TMO, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/MCD.csv completely!\n",
      "MCD, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/PFE.csv completely!\n",
      "PFE, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CRM.csv completely!\n",
      "CRM, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/BAC.csv completely!\n",
      "BAC, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/ACN.csv completely!\n",
      "ACN, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CMCSA.csv completely!\n",
      "CMCSA, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/LIN.csv completely!\n",
      "LIN, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/NFLX.csv completely!\n",
      "NFLX, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/ABT.csv completely!\n",
      "ABT, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/ORCL.csv completely!\n",
      "ORCL, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/DHR.csv completely!\n",
      "DHR, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/AMD.csv completely!\n",
      "A total of 1 volume values ​​are zero. Delete these data.\n",
      "The cleaned data size is 2515. The original data size is 2516.\n",
      "AMD, size:2515\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/WFC.csv completely!\n",
      "WFC, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/DIS.csv completely!\n",
      "DIS, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/TXN.csv completely!\n",
      "TXN, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/PM.csv completely!\n",
      "PM, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/VZ.csv completely!\n",
      "VZ, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/INTU.csv completely!\n",
      "INTU, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/COP.csv completely!\n",
      "COP, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CAT.csv completely!\n",
      "CAT, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/AMGN.csv completely!\n",
      "AMGN, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/NEE.csv completely!\n",
      "NEE, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/INTC.csv completely!\n",
      "INTC, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/UNP.csv completely!\n",
      "UNP, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/LOW.csv completely!\n",
      "LOW, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/IBM.csv completely!\n",
      "IBM, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/BMY.csv completely!\n",
      "BMY, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/SPGI.csv completely!\n",
      "SPGI, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/RTX.csv completely!\n",
      "RTX, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/HON.csv completely!\n",
      "HON, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/BA.csv completely!\n",
      "BA, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/UPS.csv completely!\n",
      "UPS, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/GE.csv completely!\n",
      "GE, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/QCOM.csv completely!\n",
      "QCOM, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/AMAT.csv completely!\n",
      "AMAT, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/NKE.csv completely!\n",
      "NKE, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/PLD.csv completely!\n",
      "PLD, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/NOW.csv completely!\n",
      "NOW, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/BKNG.csv completely!\n",
      "BKNG, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/SBUX.csv completely!\n",
      "SBUX, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/MS.csv completely!\n",
      "MS, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/ELV.csv completely!\n",
      "ELV, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/MDT.csv completely!\n",
      "MDT, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/GS.csv completely!\n",
      "GS, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/DE.csv completely!\n",
      "DE, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/ADP.csv completely!\n",
      "ADP, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/LMT.csv completely!\n",
      "LMT, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/TJX.csv completely!\n",
      "TJX, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/T.csv completely!\n",
      "T, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/BLK.csv completely!\n",
      "BLK, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/ISRG.csv completely!\n",
      "ISRG, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/MDLZ.csv completely!\n",
      "MDLZ, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/GILD.csv completely!\n",
      "GILD, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/MMC.csv completely!\n",
      "MMC, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/AXP.csv completely!\n",
      "AXP, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/SYK.csv completely!\n",
      "SYK, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/REGN.csv completely!\n",
      "REGN, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/VRTX.csv completely!\n",
      "VRTX, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/ETN.csv completely!\n",
      "ETN, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/LRCX.csv completely!\n",
      "LRCX, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/ADI.csv completely!\n",
      "ADI, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/SCHW.csv completely!\n",
      "SCHW, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CVS.csv completely!\n",
      "CVS, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/ZTS.csv completely!\n",
      "ZTS, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CI.csv completely!\n",
      "CI, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CB.csv completely!\n",
      "CB, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/AMT.csv completely!\n",
      "AMT, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/SLB.csv completely!\n",
      "SLB, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/C.csv completely!\n",
      "C, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/BDX.csv completely!\n",
      "BDX, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/MO.csv completely!\n",
      "MO, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/PGR.csv completely!\n",
      "PGR, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/TMUS.csv completely!\n",
      "TMUS, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/FI.csv completely!\n",
      "FI, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/SO.csv completely!\n",
      "SO, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/EOG.csv completely!\n",
      "EOG, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/BSX.csv completely!\n",
      "BSX, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CME.csv completely!\n",
      "CME, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/EQIX.csv completely!\n",
      "EQIX, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/MU.csv completely!\n",
      "MU, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/DUK.csv completely!\n",
      "DUK, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/PANW.csv completely!\n",
      "PANW, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/PYPL.csv completely!\n",
      "PYPL, size:2138\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/AON.csv completely!\n",
      "AON, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/SNPS.csv completely!\n",
      "SNPS, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/ITW.csv completely!\n",
      "ITW, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/KLAC.csv completely!\n",
      "KLAC, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/LULU.csv completely!\n",
      "LULU, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/ICE.csv completely!\n",
      "ICE, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/APD.csv completely!\n",
      "APD, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/SHW.csv completely!\n",
      "SHW, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CDNS.csv completely!\n",
      "CDNS, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CSX.csv completely!\n",
      "CSX, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/NOC.csv completely!\n",
      "NOC, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CL.csv completely!\n",
      "CL, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/MPC.csv completely!\n",
      "MPC, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/HUM.csv completely!\n",
      "HUM, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/FDX.csv completely!\n",
      "FDX, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/WM.csv completely!\n",
      "WM, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/MCK.csv completely!\n",
      "MCK, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/TGT.csv completely!\n",
      "TGT, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/ORLY.csv completely!\n",
      "ORLY, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/HCA.csv completely!\n",
      "HCA, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/FCX.csv completely!\n",
      "FCX, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/EMR.csv completely!\n",
      "EMR, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/PXD.csv completely!\n",
      "PXD, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/MMM.csv completely!\n",
      "MMM, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/MCO.csv completely!\n",
      "MCO, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/ROP.csv completely!\n",
      "ROP, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CMG.csv completely!\n",
      "CMG, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/PSX.csv completely!\n",
      "PSX, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/MAR.csv completely!\n",
      "MAR, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/PH.csv completely!\n",
      "PH, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/APH.csv completely!\n",
      "APH, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/GD.csv completely!\n",
      "GD, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/USB.csv completely!\n",
      "USB, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/NXPI.csv completely!\n",
      "NXPI, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/AJG.csv completely!\n",
      "AJG, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/NSC.csv completely!\n",
      "NSC, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/PNC.csv completely!\n",
      "PNC, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/VLO.csv completely!\n",
      "VLO, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/GBP.csv completely!\n",
      "GBP: contains numerical errors. Ignore it.\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/F.csv completely!\n",
      "F, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/MSI.csv completely!\n",
      "MSI, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/GM.csv completely!\n",
      "GM, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/TT.csv completely!\n",
      "TT, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/EW.csv completely!\n",
      "EW, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CARR.csv completely!\n",
      "CARR, size:953\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/AZO.csv completely!\n",
      "AZO, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/ADSK.csv completely!\n",
      "ADSK, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/TDG.csv completely!\n",
      "TDG, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/ANET.csv completely!\n",
      "ANET, size:2409\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/SRE.csv completely!\n",
      "SRE, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/ECL.csv completely!\n",
      "ECL, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/OXY.csv completely!\n",
      "OXY, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/PCAR.csv completely!\n",
      "PCAR, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/ADM.csv completely!\n",
      "ADM, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/MNST.csv completely!\n",
      "MNST, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/KMB.csv completely!\n",
      "KMB, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/PSA.csv completely!\n",
      "PSA, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CCI.csv completely!\n",
      "A total of 1 volume values ​​are zero. Delete these data.\n",
      "The cleaned data size is 2515. The original data size is 2516.\n",
      "CCI, size:2515\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CHTR.csv completely!\n",
      "CHTR, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/MCHP.csv completely!\n",
      "MCHP, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/MSCI.csv completely!\n",
      "MSCI, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CTAS.csv completely!\n",
      "CTAS, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/WMB.csv completely!\n",
      "WMB, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/AIG.csv completely!\n",
      "AIG, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/STZ.csv completely!\n",
      "STZ, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/HES.csv completely!\n",
      "HES, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/NUE.csv completely!\n",
      "NUE, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/ROST.csv completely!\n",
      "ROST, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/AFL.csv completely!\n",
      "AFL, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/AEP.csv completely!\n",
      "AEP, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/IDXX.csv completely!\n",
      "IDXX, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/D.csv completely!\n",
      "D, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/TEL.csv completely!\n",
      "TEL, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/JCI.csv completely!\n",
      "JCI, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/MET.csv completely!\n",
      "MET, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/GIS.csv completely!\n",
      "GIS, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/IQV.csv completely!\n",
      "IQV, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/EXC.csv completely!\n",
      "EXC, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/WELL.csv completely!\n",
      "WELL, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/DXCM.csv completely!\n",
      "A total of 1 volume values ​​are zero. Delete these data.\n",
      "The cleaned data size is 2515. The original data size is 2516.\n",
      "DXCM, size:2515\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/HLT.csv completely!\n",
      "HLT, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/ON.csv completely!\n",
      "ON, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/COF.csv completely!\n",
      "COF, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/PAYX.csv completely!\n",
      "PAYX, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/TFC.csv completely!\n",
      "TFC, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/USD.csv completely!\n",
      "The total volume with a value of zero (6) is greater than the threshold(5). Ignore it.\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/BIIB.csv completely!\n",
      "A total of 1 volume values ​​are zero. Delete these data.\n",
      "The cleaned data size is 2515. The original data size is 2516.\n",
      "BIIB, size:2515\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/O.csv completely!\n",
      "O, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/FTNT.csv completely!\n",
      "FTNT, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/DOW.csv completely!\n",
      "DOW, size:1205\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/TRV.csv completely!\n",
      "TRV, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/DLR.csv completely!\n",
      "DLR, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/MRNA.csv completely!\n",
      "MRNA, size:1274\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CPRT.csv completely!\n",
      "CPRT, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/ODFL.csv completely!\n",
      "ODFL, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/DHI.csv completely!\n",
      "DHI, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/YUM.csv completely!\n",
      "YUM, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/SPG.csv completely!\n",
      "SPG, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CTSH.csv completely!\n",
      "CTSH, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/AME.csv completely!\n",
      "AME, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/BKR.csv completely!\n",
      "A total of 1 volume values ​​are zero. Delete these data.\n",
      "The cleaned data size is 2515. The original data size is 2516.\n",
      "BKR, size:2515\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/SYY.csv completely!\n",
      "SYY, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/A.csv completely!\n",
      "A, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CTVA.csv completely!\n",
      "CTVA, size:1159\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CNC.csv completely!\n",
      "A total of 1 volume values ​​are zero. Delete these data.\n",
      "The cleaned data size is 2515. The original data size is 2516.\n",
      "CNC, size:2515\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/EL.csv completely!\n",
      "EL, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/AMP.csv completely!\n",
      "AMP, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/HAL.csv completely!\n",
      "HAL, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/ROK.csv completely!\n",
      "ROK, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/PRU.csv completely!\n",
      "PRU, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/DD.csv completely!\n",
      "DD, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/KMI.csv completely!\n",
      "KMI, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/VRSK.csv completely!\n",
      "VRSK, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/LHX.csv completely!\n",
      "LHX, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/DG.csv completely!\n",
      "DG, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/FIS.csv completely!\n",
      "FIS, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CMI.csv completely!\n",
      "CMI, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CSGP.csv completely!\n",
      "CSGP, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/FAST.csv completely!\n",
      "FAST, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/PPG.csv completely!\n",
      "PPG, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/GPN.csv completely!\n",
      "GPN, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/GWW.csv completely!\n",
      "GWW, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/HSY.csv completely!\n",
      "HSY, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/BK.csv completely!\n",
      "BK, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/XEL.csv completely!\n",
      "A total of 1 volume values ​​are zero. Delete these data.\n",
      "The cleaned data size is 2515. The original data size is 2516.\n",
      "XEL, size:2515\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/DVN.csv completely!\n",
      "DVN, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/EA.csv completely!\n",
      "EA, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/NEM.csv completely!\n",
      "NEM, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/ED.csv completely!\n",
      "ED, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/URI.csv completely!\n",
      "URI, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/VICI.csv completely!\n",
      "VICI, size:1509\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/PEG.csv completely!\n",
      "PEG, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/KR.csv completely!\n",
      "KR, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/RSG.csv completely!\n",
      "RSG, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/LEN.csv completely!\n",
      "LEN, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/PWR.csv completely!\n",
      "PWR, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/WST.csv completely!\n",
      "WST, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/COR.csv completely!\n",
      "COR, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/OKE.csv completely!\n",
      "OKE, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/VMC.csv completely!\n",
      "VMC, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/KDP.csv completely!\n",
      "KDP, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/WBD.csv completely!\n",
      "WBD, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/ACGL.csv completely!\n",
      "ACGL, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/ALL.csv completely!\n",
      "ALL, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/IR.csv completely!\n",
      "IR, size:1670\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CDW.csv completely!\n",
      "CDW, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/FANG.csv completely!\n",
      "FANG, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/MLM.csv completely!\n",
      "MLM, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/PCG.csv completely!\n",
      "PCG, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/DAL.csv completely!\n",
      "DAL, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/EXR.csv completely!\n",
      "EXR, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/FTV.csv completely!\n",
      "FTV, size:1886\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/AWK.csv completely!\n",
      "AWK, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/IT.csv completely!\n",
      "IT, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/KHC.csv completely!\n",
      "KHC, size:2138\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/WEC.csv completely!\n",
      "WEC, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/HPQ.csv completely!\n",
      "HPQ, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/EIX.csv completely!\n",
      "EIX, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CBRE.csv completely!\n",
      "CBRE, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/APTV.csv completely!\n",
      "APTV, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/ANSS.csv completely!\n",
      "ANSS, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/MTD.csv completely!\n",
      "MTD, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/DLTR.csv completely!\n",
      "DLTR, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/AVB.csv completely!\n",
      "AVB, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/ILMN.csv completely!\n",
      "ILMN, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/ALGN.csv completely!\n",
      "ALGN, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/LYB.csv completely!\n",
      "LYB, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/TROW.csv completely!\n",
      "TROW, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/GLW.csv completely!\n",
      "GLW, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/EFX.csv completely!\n",
      "EFX, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/WY.csv completely!\n",
      "WY, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/ZBH.csv completely!\n",
      "ZBH, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/XYL.csv completely!\n",
      "XYL, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/SBAC.csv completely!\n",
      "A total of 1 volume values ​​are zero. Delete these data.\n",
      "The cleaned data size is 2515. The original data size is 2516.\n",
      "SBAC, size:2515\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/RMD.csv completely!\n",
      "RMD, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/TSCO.csv completely!\n",
      "TSCO, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/EBAY.csv completely!\n",
      "EBAY, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/KEYS.csv completely!\n",
      "KEYS, size:2315\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CHD.csv completely!\n",
      "A total of 1 volume values ​​are zero. Delete these data.\n",
      "The cleaned data size is 2515. The original data size is 2516.\n",
      "CHD, size:2515\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/STT.csv completely!\n",
      "STT, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/DFS.csv completely!\n",
      "DFS, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/HIG.csv completely!\n",
      "HIG, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/ALB.csv completely!\n",
      "ALB, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/STE.csv completely!\n",
      "STE, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/ES.csv completely!\n",
      "ES, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/TTWO.csv completely!\n",
      "TTWO, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/MPWR.csv completely!\n",
      "MPWR, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CAH.csv completely!\n",
      "CAH, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/EQR.csv completely!\n",
      "EQR, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/RCL.csv completely!\n",
      "RCL, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/WTW.csv completely!\n",
      "A total of 1 volume values ​​are zero. Delete these data.\n",
      "The cleaned data size is 2515. The original data size is 2516.\n",
      "WTW, size:2515\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/HPE.csv completely!\n",
      "HPE, size:2064\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/DTE.csv completely!\n",
      "DTE, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/GPC.csv completely!\n",
      "GPC, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/BR.csv completely!\n",
      "BR, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/ULTA.csv completely!\n",
      "ULTA, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/FICO.csv completely!\n",
      "FICO, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CTRA.csv completely!\n",
      "CTRA, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/BAX.csv completely!\n",
      "BAX, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/AEE.csv completely!\n",
      "AEE, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/MTB.csv completely!\n",
      "MTB, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/MKC.csv completely!\n",
      "MKC, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/ETR.csv completely!\n",
      "ETR, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/WAB.csv completely!\n",
      "WAB, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/DOV.csv completely!\n",
      "DOV, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/FE.csv completely!\n",
      "FE, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/RJF.csv completely!\n",
      "RJF, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/INVH.csv completely!\n",
      "INVH, size:1740\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/FLT.csv completely!\n",
      "FLT, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CLX.csv completely!\n",
      "CLX, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/TDY.csv completely!\n",
      "TDY, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/TRGP.csv completely!\n",
      "TRGP, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/DRI.csv completely!\n",
      "DRI, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/LH.csv completely!\n",
      "LH, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/HOLX.csv completely!\n",
      "HOLX, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/VRSN.csv completely!\n",
      "VRSN, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/MOH.csv completely!\n",
      "MOH, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/LUV.csv completely!\n",
      "LUV, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/PPL.csv completely!\n",
      "PPL, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/ARE.csv completely!\n",
      "ARE, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/NVR.csv completely!\n",
      "NVR, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/COO.csv completely!\n",
      "COO, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/WBA.csv completely!\n",
      "WBA, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/PHM.csv completely!\n",
      "PHM, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/NDAQ.csv completely!\n",
      "NDAQ, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/HWM.csv completely!\n",
      "The total volume with a value of zero (35) is greater than the threshold(5). Ignore it.\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/RF.csv completely!\n",
      "RF, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CNP.csv completely!\n",
      "CNP, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/IRM.csv completely!\n",
      "IRM, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/LVS.csv completely!\n",
      "LVS, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/FITB.csv completely!\n",
      "FITB, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/EXPD.csv completely!\n",
      "EXPD, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/VTR.csv completely!\n",
      "VTR, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/FSLR.csv completely!\n",
      "FSLR, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/PFG.csv completely!\n",
      "A total of 2 volume values ​​are zero. Delete these data.\n",
      "The cleaned data size is 2514. The original data size is 2516.\n",
      "PFG, size:2514\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/BRO.csv completely!\n",
      "BRO, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/J.csv completely!\n",
      "J, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/IEX.csv completely!\n",
      "IEX, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/BG.csv completely!\n",
      "BG, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/ATO.csv completely!\n",
      "ATO, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/FDS.csv completely!\n",
      "FDS, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/ENPH.csv completely!\n",
      "ENPH, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/MAA.csv completely!\n",
      "MAA, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CMS.csv completely!\n",
      "CMS, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/IFF.csv completely!\n",
      "IFF, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/BALL.csv completely!\n",
      "BALL, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/SWKS.csv completely!\n",
      "SWKS, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CINF.csv completely!\n",
      "CINF, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/NTAP.csv completely!\n",
      "NTAP, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/STLD.csv completely!\n",
      "STLD, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/UAL.csv completely!\n",
      "UAL, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/WAT.csv completely!\n",
      "WAT, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/OMC.csv completely!\n",
      "OMC, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/TER.csv completely!\n",
      "TER, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CCL.csv completely!\n",
      "CCL, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/JBHT.csv completely!\n",
      "JBHT, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/MRO.csv completely!\n",
      "MRO, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/TYL.csv completely!\n",
      "TYL, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/HBAN.csv completely!\n",
      "HBAN, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/K.csv completely!\n",
      "K, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/GRMN.csv completely!\n",
      "GRMN, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CBOE.csv completely!\n",
      "CBOE, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/NTRS.csv completely!\n",
      "NTRS, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/TSN.csv completely!\n",
      "TSN, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/AKAM.csv completely!\n",
      "AKAM, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/EG.csv completely!\n",
      "EG, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/ESS.csv completely!\n",
      "ESS, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/EQT.csv completely!\n",
      "EQT, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/TXT.csv completely!\n",
      "TXT, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/EXPE.csv completely!\n",
      "EXPE, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/SJM.csv completely!\n",
      "SJM, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/PTC.csv completely!\n",
      "PTC, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/DGX.csv completely!\n",
      "DGX, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/AVY.csv completely!\n",
      "AVY, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/RVTY.csv completely!\n",
      "RVTY, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/BBY.csv completely!\n",
      "BBY, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CF.csv completely!\n",
      "CF, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CAG.csv completely!\n",
      "CAG, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/EPAM.csv completely!\n",
      "EPAM, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/AMCR.csv completely!\n",
      "The total volume with a value of zero (1110) is greater than the threshold(5). Ignore it.\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/LW.csv completely!\n",
      "LW, size:1795\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/PAYC.csv completely!\n",
      "PAYC, size:2445\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/SNA.csv completely!\n",
      "SNA, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/AXON.csv completely!\n",
      "AXON, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/POOL.csv completely!\n",
      "POOL, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/SYF.csv completely!\n",
      "SYF, size:2371\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/SWK.csv completely!\n",
      "SWK, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/ZBRA.csv completely!\n",
      "ZBRA, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/DPZ.csv completely!\n",
      "DPZ, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/PKG.csv completely!\n",
      "PKG, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CFG.csv completely!\n",
      "CFG, size:2333\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/LDOS.csv completely!\n",
      "LDOS, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/VTRS.csv completely!\n",
      "VTRS, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/PODD.csv completely!\n",
      "PODD, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/LKQ.csv completely!\n",
      "LKQ, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/MOS.csv completely!\n",
      "MOS, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/APA.csv completely!\n",
      "APA, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/EVRG.csv completely!\n",
      "EVRG, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/TRMB.csv completely!\n",
      "TRMB, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/MGM.csv completely!\n",
      "MGM, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/NDSN.csv completely!\n",
      "NDSN, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/WDC.csv completely!\n",
      "WDC, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/MAS.csv completely!\n",
      "MAS, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/LNT.csv completely!\n",
      "LNT, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/IPG.csv completely!\n",
      "IPG, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/MTCH.csv completely!\n",
      "MTCH, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/STX.csv completely!\n",
      "STX, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/KMX.csv completely!\n",
      "KMX, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/TECH.csv completely!\n",
      "TECH, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/WRB.csv completely!\n",
      "WRB, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/LYV.csv completely!\n",
      "LYV, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/IP.csv completely!\n",
      "IP, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/UDR.csv completely!\n",
      "UDR, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/AES.csv completely!\n",
      "AES, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CE.csv completely!\n",
      "CE, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/INCY.csv completely!\n",
      "INCY, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/L.csv completely!\n",
      "L, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/TAP.csv completely!\n",
      "TAP, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/GEN.csv completely!\n",
      "A total of 1 volume values ​​are zero. Delete these data.\n",
      "The cleaned data size is 2515. The original data size is 2516.\n",
      "GEN, size:2515\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CPT.csv completely!\n",
      "CPT, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/KIM.csv completely!\n",
      "KIM, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/JKHY.csv completely!\n",
      "JKHY, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/HRL.csv completely!\n",
      "HRL, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/HST.csv completely!\n",
      "HST, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/FMC.csv completely!\n",
      "FMC, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CZR.csv completely!\n",
      "CZR, size:2335\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/PEAK.csv completely!\n",
      "A total of 1 volume values ​​are zero. Delete these data.\n",
      "The cleaned data size is 2515. The original data size is 2516.\n",
      "PEAK, size:2515\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CDAY.csv completely!\n",
      "CDAY, size:1430\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/PNR.csv completely!\n",
      "PNR, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/NI.csv completely!\n",
      "NI, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CHRW.csv completely!\n",
      "CHRW, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/HSIC.csv completely!\n",
      "HSIC, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CRL.csv completely!\n",
      "CRL, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/REG.csv completely!\n",
      "REG, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/QRVO.csv completely!\n",
      "QRVO, size:2264\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/TFX.csv completely!\n",
      "TFX, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/KEY.csv completely!\n",
      "KEY, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/GL.csv completely!\n",
      "GL, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/EMN.csv completely!\n",
      "EMN, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/WYNN.csv completely!\n",
      "WYNN, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/ALLE.csv completely!\n",
      "ALLE, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/AAL.csv completely!\n",
      "AAL, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/FFIV.csv completely!\n",
      "FFIV, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/BWA.csv completely!\n",
      "BWA, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/BXP.csv completely!\n",
      "BXP, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/MKTX.csv completely!\n",
      "MKTX, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/ROL.csv completely!\n",
      "ROL, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/JNPR.csv completely!\n",
      "JNPR, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/PNW.csv completely!\n",
      "PNW, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/ETSY.csv completely!\n",
      "ETSY, size:2193\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/BLDR.csv completely!\n",
      "BLDR, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/FOXA.csv completely!\n",
      "FOXA, size:1211\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/AOS.csv completely!\n",
      "AOS, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/HAS.csv completely!\n",
      "HAS, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/HII.csv completely!\n",
      "HII, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/NRG.csv completely!\n",
      "NRG, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CPB.csv completely!\n",
      "CPB, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/UHS.csv completely!\n",
      "UHS, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/BIO.csv completely!\n",
      "BIO, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/WRK.csv completely!\n",
      "WRK, size:2145\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/RHI.csv completely!\n",
      "RHI, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CTLT.csv completely!\n",
      "CTLT, size:2371\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/XRAY.csv completely!\n",
      "XRAY, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/BBWI.csv completely!\n",
      "BBWI, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/NWSA.csv completely!\n",
      "NWSA, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/TPR.csv completely!\n",
      "TPR, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/PARA.csv completely!\n",
      "PARA, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/WHR.csv completely!\n",
      "WHR, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/BEN.csv completely!\n",
      "BEN, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/AIZ.csv completely!\n",
      "AIZ, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/NCLH.csv completely!\n",
      "NCLH, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/GNRC.csv completely!\n",
      "GNRC, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/FRT.csv completely!\n",
      "FRT, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/IVZ.csv completely!\n",
      "IVZ, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/VFC.csv completely!\n",
      "VFC, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CMA.csv completely!\n",
      "CMA, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/DVA.csv completely!\n",
      "DVA, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/JBL.csv completely!\n",
      "JBL, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/HUBB.csv completely!\n",
      "A total of 1 volume values ​​are zero. Delete these data.\n",
      "The cleaned data size is 2515. The original data size is 2516.\n",
      "HUBB, size:2515\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/ZION.csv completely!\n",
      "ZION, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/UBER.csv completely!\n",
      "UBER, size:1169\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/MHK.csv completely!\n",
      "MHK, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/RL.csv completely!\n",
      "RL, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/FOX.csv completely!\n",
      "FOX, size:1210\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/BX.csv completely!\n",
      "BX, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/ABNB.csv completely!\n",
      "ABNB, size:768\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/NWS.csv completely!\n",
      "NWS, size:2516\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import yfinance as yfin\n",
    "from MyPyUtil.util import is_contained\n",
    "\n",
    "# Loading the data\n",
    "stk_symbols = [\n",
    "    \"AAPL\",\n",
    "    \"MSFT\",\n",
    "    \"AMZN\",\n",
    "    \"NVDA\",\n",
    "    \"GOOGL\",\n",
    "    \"GOOG\",\n",
    "    \"META\",\n",
    "    \"TSLA\",\n",
    "    \"UNH\",\n",
    "    \"LLY\",\n",
    "    \"JPM\",\n",
    "    \"XOM\",\n",
    "    \"JNJ\",\n",
    "    \"V\",\n",
    "    \"PG\",\n",
    "    \"AVGO\",\n",
    "    \"MA\",\n",
    "    \"HD\",\n",
    "    \"CVX\",\n",
    "    \"MRK\",\n",
    "    \"ABBV\",\n",
    "    \"PEP\",\n",
    "    \"COST\",\n",
    "    \"ADBE\",\n",
    "    \"KO\",\n",
    "    \"CSCO\",\n",
    "    \"WMT\",\n",
    "    \"TMO\",\n",
    "    \"MCD\",\n",
    "    \"PFE\",\n",
    "    \"CRM\",\n",
    "    \"BAC\",\n",
    "    \"ACN\",\n",
    "    \"CMCSA\",\n",
    "    \"LIN\",\n",
    "    \"NFLX\",\n",
    "    \"ABT\",\n",
    "    \"ORCL\",\n",
    "    \"DHR\",\n",
    "    \"AMD\",\n",
    "    \"WFC\",\n",
    "    \"DIS\",\n",
    "    \"TXN\",\n",
    "    \"PM\",\n",
    "    \"VZ\",\n",
    "    \"INTU\",\n",
    "    \"COP\",\n",
    "    \"CAT\",\n",
    "    \"AMGN\",\n",
    "    \"NEE\",\n",
    "    \"INTC\",\n",
    "    \"UNP\",\n",
    "    \"LOW\",\n",
    "    \"IBM\",\n",
    "    \"BMY\",\n",
    "    \"SPGI\",\n",
    "    \"RTX\",\n",
    "    \"HON\",\n",
    "    \"BA\",\n",
    "    \"UPS\",\n",
    "    \"GE\",\n",
    "    \"QCOM\",\n",
    "    \"AMAT\",\n",
    "    \"NKE\",\n",
    "    \"PLD\",\n",
    "    \"NOW\",\n",
    "    \"BKNG\",\n",
    "    \"SBUX\",\n",
    "    \"MS\",\n",
    "    \"ELV\",\n",
    "    \"MDT\",\n",
    "    \"GS\",\n",
    "    \"DE\",\n",
    "    \"ADP\",\n",
    "    \"LMT\",\n",
    "    \"TJX\",\n",
    "    \"T\",\n",
    "    \"BLK\",\n",
    "    \"ISRG\",\n",
    "    \"MDLZ\",\n",
    "    \"GILD\",\n",
    "    \"MMC\",\n",
    "    \"AXP\",\n",
    "    \"SYK\",\n",
    "    \"REGN\",\n",
    "    \"VRTX\",\n",
    "    \"ETN\",\n",
    "    \"LRCX\",\n",
    "    \"ADI\",\n",
    "    \"SCHW\",\n",
    "    \"CVS\",\n",
    "    \"ZTS\",\n",
    "    \"CI\",\n",
    "    \"CB\",\n",
    "    \"AMT\",\n",
    "    \"SLB\",\n",
    "    \"C\",\n",
    "    \"BDX\",\n",
    "    \"MO\",\n",
    "    \"PGR\",\n",
    "    \"TMUS\",\n",
    "    \"FI\",\n",
    "    \"SO\",\n",
    "    \"EOG\",\n",
    "    \"BSX\",\n",
    "    \"CME\",\n",
    "    \"EQIX\",\n",
    "    \"MU\",\n",
    "    \"DUK\",\n",
    "    \"PANW\",\n",
    "    \"PYPL\",\n",
    "    \"AON\",\n",
    "    \"SNPS\",\n",
    "    \"ITW\",\n",
    "    \"KLAC\",\n",
    "    \"LULU\",\n",
    "    \"ICE\",\n",
    "    \"APD\",\n",
    "    \"SHW\",\n",
    "    \"CDNS\",\n",
    "    \"CSX\",\n",
    "    \"NOC\",\n",
    "    \"CL\",\n",
    "    \"MPC\",\n",
    "    \"HUM\",\n",
    "    \"FDX\",\n",
    "    \"WM\",\n",
    "    \"MCK\",\n",
    "    \"TGT\",\n",
    "    \"ORLY\",\n",
    "    \"HCA\",\n",
    "    \"FCX\",\n",
    "    \"EMR\",\n",
    "    \"PXD\",\n",
    "    \"MMM\",\n",
    "    \"MCO\",\n",
    "    \"ROP\",\n",
    "    \"CMG\",\n",
    "    \"PSX\",\n",
    "    \"MAR\",\n",
    "    \"PH\",\n",
    "    \"APH\",\n",
    "    \"GD\",\n",
    "    \"USB\",\n",
    "    \"NXPI\",\n",
    "    \"AJG\",\n",
    "    \"NSC\",\n",
    "    \"PNC\",\n",
    "    \"VLO\",\n",
    "    \"GBP\",\n",
    "    \"F\",\n",
    "    \"MSI\",\n",
    "    \"GM\",\n",
    "    \"TT\",\n",
    "    \"EW\",\n",
    "    \"CARR\",\n",
    "    \"AZO\",\n",
    "    \"ADSK\",\n",
    "    \"TDG\",\n",
    "    \"ANET\",\n",
    "    \"SRE\",\n",
    "    \"ECL\",\n",
    "    \"OXY\",\n",
    "    \"PCAR\",\n",
    "    \"ADM\",\n",
    "    \"MNST\",\n",
    "    \"KMB\",\n",
    "    \"PSA\",\n",
    "    \"CCI\",\n",
    "    \"CHTR\",\n",
    "    \"MCHP\",\n",
    "    \"MSCI\",\n",
    "    \"CTAS\",\n",
    "    \"WMB\",\n",
    "    \"AIG\",\n",
    "    \"STZ\",\n",
    "    \"HES\",\n",
    "    \"NUE\",\n",
    "    \"ROST\",\n",
    "    \"AFL\",\n",
    "    \"AEP\",\n",
    "    \"IDXX\",\n",
    "    \"D\",\n",
    "    \"TEL\",\n",
    "    \"JCI\",\n",
    "    \"MET\",\n",
    "    \"GIS\",\n",
    "    \"IQV\",\n",
    "    \"EXC\",\n",
    "    \"WELL\",\n",
    "    \"DXCM\",\n",
    "    \"HLT\",\n",
    "    \"ON\",\n",
    "    \"COF\",\n",
    "    \"PAYX\",\n",
    "    \"TFC\",\n",
    "    \"USD\",\n",
    "    \"BIIB\",\n",
    "    \"O\",\n",
    "    \"FTNT\",\n",
    "    \"DOW\",\n",
    "    \"TRV\",\n",
    "    \"DLR\",\n",
    "    \"MRNA\",\n",
    "    \"CPRT\",\n",
    "    \"ODFL\",\n",
    "    \"DHI\",\n",
    "    \"YUM\",\n",
    "    \"SPG\",\n",
    "    \"CTSH\",\n",
    "    \"AME\",\n",
    "    \"BKR\",\n",
    "    \"SYY\",\n",
    "    \"A\",\n",
    "    \"CTVA\",\n",
    "    \"CNC\",\n",
    "    \"EL\",\n",
    "    \"AMP\",\n",
    "    # \"CEG\",  # PCT <= -0.05,  size = 0\n",
    "    \"HAL\",\n",
    "    # \"OTIS\",  # PCT <= -0.05,  size = 0\n",
    "    \"ROK\",\n",
    "    \"PRU\",\n",
    "    \"DD\",\n",
    "    \"KMI\",\n",
    "    \"VRSK\",\n",
    "    \"LHX\",\n",
    "    \"DG\",\n",
    "    \"FIS\",\n",
    "    \"CMI\",\n",
    "    \"CSGP\",\n",
    "    \"FAST\",\n",
    "    \"PPG\",\n",
    "    \"GPN\",\n",
    "    \"GWW\",\n",
    "    \"HSY\",\n",
    "    \"BK\",\n",
    "    \"XEL\",\n",
    "    \"DVN\",\n",
    "    \"EA\",\n",
    "    \"NEM\",\n",
    "    \"ED\",\n",
    "    \"URI\",\n",
    "    \"VICI\",\n",
    "    \"PEG\",\n",
    "    \"KR\",\n",
    "    \"RSG\",\n",
    "    \"LEN\",\n",
    "    \"PWR\",\n",
    "    \"WST\",\n",
    "    \"COR\",\n",
    "    \"OKE\",\n",
    "    \"VMC\",\n",
    "    \"KDP\",\n",
    "    \"WBD\",\n",
    "    \"ACGL\",\n",
    "    \"ALL\",\n",
    "    \"IR\",\n",
    "    \"CDW\",\n",
    "    \"FANG\",\n",
    "    \"MLM\",\n",
    "    \"PCG\",\n",
    "    \"DAL\",\n",
    "    \"EXR\",\n",
    "    \"FTV\",\n",
    "    \"AWK\",\n",
    "    \"IT\",\n",
    "    \"KHC\",\n",
    "    # \"GEHC\",  # PCT <= -0.05,  size = 0\n",
    "    \"WEC\",\n",
    "    \"HPQ\",\n",
    "    \"EIX\",\n",
    "    \"CBRE\",\n",
    "    \"APTV\",\n",
    "    \"ANSS\",\n",
    "    \"MTD\",\n",
    "    \"DLTR\",\n",
    "    \"AVB\",\n",
    "    \"ILMN\",\n",
    "    \"ALGN\",\n",
    "    \"LYB\",\n",
    "    \"TROW\",\n",
    "    \"GLW\",\n",
    "    \"EFX\",\n",
    "    \"WY\",\n",
    "    \"ZBH\",\n",
    "    \"XYL\",\n",
    "    \"SBAC\",\n",
    "    \"RMD\",\n",
    "    \"TSCO\",\n",
    "    \"EBAY\",\n",
    "    \"KEYS\",\n",
    "    \"CHD\",\n",
    "    \"STT\",\n",
    "    \"DFS\",\n",
    "    \"HIG\",\n",
    "    \"ALB\",\n",
    "    \"STE\",\n",
    "    \"ES\",\n",
    "    \"TTWO\",\n",
    "    \"MPWR\",\n",
    "    \"CAH\",\n",
    "    \"EQR\",\n",
    "    \"RCL\",\n",
    "    \"WTW\",\n",
    "    \"HPE\",\n",
    "    \"DTE\",\n",
    "    \"GPC\",\n",
    "    \"BR\",\n",
    "    \"ULTA\",\n",
    "    \"FICO\",\n",
    "    \"CTRA\",\n",
    "    \"BAX\",\n",
    "    \"AEE\",\n",
    "    \"MTB\",\n",
    "    \"MKC\",\n",
    "    \"ETR\",\n",
    "    \"WAB\",\n",
    "    \"DOV\",\n",
    "    \"FE\",\n",
    "    \"RJF\",\n",
    "    \"INVH\",\n",
    "    \"FLT\",\n",
    "    \"CLX\",\n",
    "    \"TDY\",\n",
    "    \"TRGP\",\n",
    "    \"DRI\",\n",
    "    \"LH\",\n",
    "    \"HOLX\",\n",
    "    \"VRSN\",\n",
    "    \"MOH\",\n",
    "    \"LUV\",\n",
    "    \"PPL\",\n",
    "    \"ARE\",\n",
    "    \"NVR\",\n",
    "    \"COO\",\n",
    "    \"WBA\",\n",
    "    \"PHM\",\n",
    "    \"NDAQ\",\n",
    "    \"HWM\",\n",
    "    \"RF\",\n",
    "    \"CNP\",\n",
    "    \"IRM\",\n",
    "    \"LVS\",\n",
    "    \"FITB\",\n",
    "    \"EXPD\",\n",
    "    \"VTR\",\n",
    "    \"FSLR\",\n",
    "    \"PFG\",\n",
    "    \"BRO\",\n",
    "    \"J\",\n",
    "    \"IEX\",\n",
    "    \"BG\",\n",
    "    \"ATO\",\n",
    "    \"FDS\",\n",
    "    \"ENPH\",\n",
    "    \"MAA\",\n",
    "    \"CMS\",\n",
    "    \"IFF\",\n",
    "    \"BALL\",\n",
    "    \"SWKS\",\n",
    "    \"CINF\",\n",
    "    \"NTAP\",\n",
    "    \"STLD\",\n",
    "    \"UAL\",\n",
    "    \"WAT\",\n",
    "    \"OMC\",\n",
    "    \"TER\",\n",
    "    \"CCL\",\n",
    "    \"JBHT\",\n",
    "    \"MRO\",\n",
    "    \"TYL\",\n",
    "    \"HBAN\",\n",
    "    \"K\",\n",
    "    \"GRMN\",\n",
    "    \"CBOE\",\n",
    "    \"NTRS\",\n",
    "    \"TSN\",\n",
    "    \"AKAM\",\n",
    "    \"EG\",\n",
    "    \"ESS\",\n",
    "    \"EQT\",\n",
    "    \"TXT\",\n",
    "    \"EXPE\",\n",
    "    \"SJM\",\n",
    "    \"PTC\",\n",
    "    \"DGX\",\n",
    "    \"AVY\",\n",
    "    \"RVTY\",\n",
    "    \"BBY\",\n",
    "    \"CF\",\n",
    "    \"CAG\",\n",
    "    \"EPAM\",\n",
    "    \"AMCR\",\n",
    "    \"LW\",\n",
    "    \"PAYC\",\n",
    "    \"SNA\",\n",
    "    \"AXON\",\n",
    "    \"POOL\",\n",
    "    \"SYF\",\n",
    "    \"SWK\",\n",
    "    \"ZBRA\",\n",
    "    \"DPZ\",\n",
    "    \"PKG\",\n",
    "    \"CFG\",\n",
    "    \"LDOS\",\n",
    "    \"VTRS\",\n",
    "    \"PODD\",\n",
    "    \"LKQ\",\n",
    "    \"MOS\",\n",
    "    \"APA\",\n",
    "    \"EVRG\",\n",
    "    \"TRMB\",\n",
    "    \"MGM\",\n",
    "    \"NDSN\",\n",
    "    \"WDC\",\n",
    "    \"MAS\",\n",
    "    \"LNT\",\n",
    "    \"IPG\",\n",
    "    \"MTCH\",\n",
    "    \"STX\",\n",
    "    \"KMX\",\n",
    "    \"TECH\",\n",
    "    \"WRB\",\n",
    "    \"LYV\",\n",
    "    \"IP\",\n",
    "    \"UDR\",\n",
    "    \"AES\",\n",
    "    \"CE\",\n",
    "    \"INCY\",\n",
    "    \"L\",\n",
    "    \"TAP\",\n",
    "    \"GEN\",\n",
    "    \"CPT\",\n",
    "    \"KIM\",\n",
    "    \"JKHY\",\n",
    "    \"HRL\",\n",
    "    \"HST\",\n",
    "    \"FMC\",\n",
    "    \"CZR\",\n",
    "    \"PEAK\",\n",
    "    \"CDAY\",\n",
    "    \"PNR\",\n",
    "    \"NI\",\n",
    "    \"CHRW\",\n",
    "    \"HSIC\",\n",
    "    \"CRL\",\n",
    "    \"REG\",\n",
    "    \"QRVO\",\n",
    "    \"TFX\",\n",
    "    \"KEY\",\n",
    "    \"GL\",\n",
    "    \"EMN\",\n",
    "    \"WYNN\",\n",
    "    \"ALLE\",\n",
    "    \"AAL\",\n",
    "    \"FFIV\",\n",
    "    \"BWA\",\n",
    "    \"BXP\",\n",
    "    \"MKTX\",\n",
    "    \"ROL\",\n",
    "    \"JNPR\",\n",
    "    \"PNW\",\n",
    "    \"ETSY\",\n",
    "    \"BLDR\",\n",
    "    \"FOXA\",\n",
    "    \"AOS\",\n",
    "    \"HAS\",\n",
    "    \"HII\",\n",
    "    \"NRG\",\n",
    "    \"CPB\",\n",
    "    \"UHS\",\n",
    "    \"BIO\",\n",
    "    \"WRK\",\n",
    "    \"RHI\",\n",
    "    \"CTLT\",\n",
    "    \"XRAY\",\n",
    "    \"BBWI\",\n",
    "    \"NWSA\",\n",
    "    \"TPR\",\n",
    "    \"PARA\",\n",
    "    \"WHR\",\n",
    "    \"BEN\",\n",
    "    \"AIZ\",\n",
    "    \"NCLH\",\n",
    "    \"GNRC\",\n",
    "    \"FRT\",\n",
    "    \"IVZ\",\n",
    "    \"VFC\",\n",
    "    \"CMA\",\n",
    "    \"DVA\",\n",
    "    \"JBL\",\n",
    "    \"HUBB\",\n",
    "    \"ZION\",\n",
    "    \"UBER\",\n",
    "    \"MHK\",\n",
    "    \"RL\",\n",
    "    \"FOX\",\n",
    "    \"BX\",\n",
    "    \"ABNB\",\n",
    "    \"NWS\",\n",
    "]\n",
    "# stk_symbols = [\n",
    "#     \"AAPL\",\n",
    "#     \"MSFT\",\n",
    "#     \"AMZN\",\n",
    "#     \"NVDA\",\n",
    "#     \"GOOGL\",\n",
    "#     \"TSLA\",\n",
    "#     \"META\",\n",
    "#     \"GOOG\",\n",
    "#     \"ADBE\",\n",
    "#     \"NFLX\",\n",
    "#     \"CSCO\",\n",
    "#     \"INTC\",\n",
    "#     \"INTU\",\n",
    "#     \"CMCSA\",\n",
    "#     \"TXN\",\n",
    "#     \"AMAT\",\n",
    "#     \"ADSK\",\n",
    "#     \"AMD\",\n",
    "#     \"QCOM\",\n",
    "#     \"MU\",\n",
    "# ]\n",
    "\n",
    "# stk_symbols = [\n",
    "#     \"AAPL\",\n",
    "#     \"MSFT\",\n",
    "#     \"AMZN\",\n",
    "#     \"NVDA\",\n",
    "#     \"GOOGL\",\n",
    "#     \"TSLA\",\n",
    "#     \"META\",\n",
    "#     \"GOOG\",\n",
    "# ]\n",
    "\n",
    "empty_vol_threshold = 5\n",
    "start = datetime(2014, 1, 1)\n",
    "end = datetime(2023, 12, 31)\n",
    "\n",
    "ticks_data = []\n",
    "for symbol in stk_symbols:\n",
    "    stk_file = f\"{data_dir}{symbol}.csv\"\n",
    "    bLoad = False\n",
    "    if os.path.isfile(stk_file):\n",
    "        try:\n",
    "            _stk_data = pd.read_csv(stk_file).set_index(\"Date\")\n",
    "            bLoad = True\n",
    "            print(f\"read {stk_file} completely!\")\n",
    "        except:\n",
    "            None\n",
    "    if bLoad == False:\n",
    "        # _stk_data = web.get_data_yahoo(stk_tickers, start, end)\n",
    "        _stk_data = yfin.download([symbol], start, end).dropna()\n",
    "        _stk_data.to_csv(stk_file)\n",
    "        print(f\"download {symbol} from yfin and write to {stk_file} completely!\")\n",
    "\n",
    "    statistics = _stk_data.describe()\n",
    "    if is_contained(statistics, 0):\n",
    "        if is_contained(\n",
    "            statistics.loc[:, [\"Open\", \"High\", \"Low\", \"Close\", \"Adj Close\"]], 0\n",
    "        ) or is_contained(statistics.loc[\"std\"], 0):\n",
    "            print(f\"{symbol}: contains numerical errors. Ignore it.\")\n",
    "            continue\n",
    "        else:\n",
    "            empty_vol_index = _stk_data[_stk_data[\"Volume\"] == 0].index\n",
    "            if len(empty_vol_index) > empty_vol_threshold:\n",
    "                print(\n",
    "                    f\"The total volume with a value of zero ({len(empty_vol_index)}) is greater than the threshold({empty_vol_threshold}). Ignore it.\"\n",
    "                )\n",
    "                continue\n",
    "            print(\n",
    "                f\"A total of {len(empty_vol_index)} volume values ​​are zero. Delete these data.\"\n",
    "            )\n",
    "\n",
    "            cleaned_data = _stk_data.drop(empty_vol_index)\n",
    "            print(\n",
    "                f\"The cleaned data size is {len(cleaned_data)}. The original data size is {len(_stk_data)}.\"\n",
    "            )\n",
    "            if len(cleaned_data) == 0:\n",
    "                continue\n",
    "            _stk_data = cleaned_data\n",
    "\n",
    "    ticks_data.append(_stk_data)\n",
    "    print(f\"{symbol}, size:{len(_stk_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2516\n",
      "          Open     High      Low    Close  Adj Close        Volume\n",
      "count 2516.000 2516.000 2516.000 2516.000   2516.000      2516.000\n",
      "mean    43.107   43.990   42.206   43.115     43.115  54964631.876\n",
      "std     42.265   43.114   41.379   42.262     42.262  37508800.880\n",
      "min      1.620    1.690    1.610    1.620      1.620         0.000\n",
      "25%      5.097    5.190    4.990    5.100      5.100  29457475.000\n",
      "50%     23.645   24.210   23.215   23.680     23.680  48602500.000\n",
      "75%     82.067   83.462   80.595   82.003     82.003  73106175.000\n",
      "max    163.280  164.460  156.100  161.910    161.910 325058400.000\n",
      "1\n",
      "True\n",
      "1\n",
      "          Open     High      Low    Close  Adj Close        Volume\n",
      "count 2515.000 2515.000 2515.000 2515.000   2515.000      2515.000\n",
      "mean    43.123   44.006   42.221   43.131     43.131  54986486.600\n",
      "std     42.266   43.115   41.380   42.263     42.263  37500234.414\n",
      "min      1.620    1.690    1.610    1.620      1.620   2606600.000\n",
      "25%      5.115    5.190    5.000    5.110      5.110  29471700.000\n",
      "50%     23.660   24.230   23.220   23.680     23.680  48604800.000\n",
      "75%     82.075   83.475   80.610   82.005     82.005  73113250.000\n",
      "max    163.280  164.460  156.100  161.910    161.910 325058400.000\n"
     ]
    }
   ],
   "source": [
    "stk_data = ticks_data[39]\n",
    "print(len(stk_data))\n",
    "describe = stk_data.describe()\n",
    "print(describe)\n",
    "aa = (describe == 0).any(axis=1)\n",
    "print(len(describe[aa]))\n",
    "print(is_contained(describe, 0))\n",
    "print((stk_data[\"Volume\"] == 0).sum())\n",
    "if (stk_data[\"Volume\"] == 0).sum() > 0:\n",
    "    aa = stk_data.drop(stk_data[stk_data[\"Volume\"] == 0].index)\n",
    "    print(aa.describe())\n",
    "# print(pd.isnu describe[describe > 0])\n",
    "# for i, stk_data in enumerate(ticks_data):\n",
    "#     if (stk_data.describe() == 0).sum() > 0:\n",
    "#         print(f\"{i}, {stk_symbols[i]}\\n,{stk_data.describe()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device_name:cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device_name = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    ")\n",
    "device = torch.device(device_name)\n",
    "return_period = 5\n",
    "seq_len = 3\n",
    "validation_size = 0.2\n",
    "epoch_num = 100\n",
    "batch_size = 32\n",
    "num_workers = 0\n",
    "pin_memory = False\n",
    "shuffle = False\n",
    "print(f\"device_name:{device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pct_threshold = 0.05\n",
    "class_percentage_threshold = 0.01  # percentage threshold for class size\n",
    "classificationThreshold = 0.5\n",
    "\n",
    "\n",
    "# # number of classes = 3\n",
    "# # 0: PCT <= -0.05\n",
    "# # 1: 0.05 < PCT < -0.05\n",
    "# # 2: PCT >= 0.05\n",
    "# num_classes = 3\n",
    "\n",
    "\n",
    "# def gen_pct_label(stk_data, _return_period):\n",
    "#     max_price_period = (\n",
    "#         stk_data[\"Adj Close\"].rolling(_return_period).max().shift(-_return_period)\n",
    "#     )\n",
    "#     max_pct_period = (max_price_period - stk_data[\"Adj Close\"]) / stk_data[\"Adj Close\"]\n",
    "#     pct_label = max_pct_period.apply(\n",
    "#         lambda x: 2 if x >= pct_threshold else 0 if x <= -pct_threshold else 1\n",
    "#     ).astype(\"int8\")\n",
    "#     pct_label.name = \"label\"\n",
    "#     return pct_label\n",
    "\n",
    "\n",
    "# number of classes = 2\n",
    "# 0: PCT < 0.05\n",
    "# 1: PCT >= -0.05\n",
    "num_classes = 2\n",
    "\n",
    "\n",
    "def gen_pct_label(stk_data, _return_period):\n",
    "    max_price_period = (\n",
    "        stk_data[\"Adj Close\"].rolling(_return_period).max().shift(-_return_period)\n",
    "    )\n",
    "    max_pct_period = (max_price_period - stk_data[\"Adj Close\"]) / stk_data[\"Adj Close\"]\n",
    "    pct_label = max_pct_period.apply(lambda x: 1 if x >= pct_threshold else 0).astype(\n",
    "        \"int8\"\n",
    "    )\n",
    "    pct_label.name = \"label\"\n",
    "    return pct_label\n",
    "\n",
    "\n",
    "def class_percentage(analysis_data):\n",
    "    stat = analysis_data.groupby(\"label\").size()\n",
    "    total = len(analysis_data)\n",
    "    p = []\n",
    "    for i in range(num_classes):\n",
    "        p.append(stat[i] / total if i in stat.index else 0.0)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_adjusted(stk_data):\n",
    "    \"\"\"\n",
    "    Adjusted Open = Open * Adjusted Close / Close\n",
    "    Adjusted High = High * Adjusted Close / Close\n",
    "    Adjusted Low = Low * Adjusted Close / Close\n",
    "    Adjusted volume = Volume / (Adjusted Close / Close)\n",
    "    \"\"\"\n",
    "    ratio_data = stk_data[\"Adj Close\"] / stk_data[\"Close\"]\n",
    "    adjusted_OHLV = pd.DataFrame(index=stk_data.index)\n",
    "    adjusted_OHLV[\"Adj Open\"] = ratio_data * stk_data[\"Open\"]\n",
    "    adjusted_OHLV[\"Adj High\"] = ratio_data * stk_data[\"High\"]\n",
    "    adjusted_OHLV[\"Adj Low\"] = ratio_data * stk_data[\"Low\"]\n",
    "    adjusted_OHLV[\"Adj Close\"] = stk_data[\"Adj Close\"]\n",
    "    adjusted_OHLV[\"Adj Volume\"] = (ratio_data * stk_data[\"Volume\"]).astype(\"int\")\n",
    "    adjusted_OHLV[\"Pre Adj Close\"] = stk_data[\"Adj Close\"].shift(1)\n",
    "    adjusted_OHLV[\"Pre Adj Volume\"] = adjusted_OHLV[\"Adj Volume\"].shift(1)\n",
    "    adjusted_OHLV = adjusted_OHLV.dropna()\n",
    "    adjusted_OHLV[\"Pre Adj Volume\"] = adjusted_OHLV[\"Pre Adj Volume\"].astype(\"int\")\n",
    "    adjusted_OHLV[\"Adj Open pct\"] = (\n",
    "        adjusted_OHLV[\"Adj Open\"] - adjusted_OHLV[\"Pre Adj Close\"]\n",
    "    ) / adjusted_OHLV[\"Pre Adj Close\"]\n",
    "    adjusted_OHLV[\"Adj High pct\"] = (\n",
    "        adjusted_OHLV[\"Adj High\"] - adjusted_OHLV[\"Pre Adj Close\"]\n",
    "    ) / adjusted_OHLV[\"Pre Adj Close\"]\n",
    "    adjusted_OHLV[\"Adj Low pct\"] = (\n",
    "        adjusted_OHLV[\"Adj Low\"] - adjusted_OHLV[\"Pre Adj Close\"]\n",
    "    ) / adjusted_OHLV[\"Pre Adj Close\"]\n",
    "    adjusted_OHLV[\"Adj Volume pct\"] = (\n",
    "        adjusted_OHLV[\"Adj Volume\"] - adjusted_OHLV[\"Pre Adj Volume\"]\n",
    "    ) / adjusted_OHLV[\"Pre Adj Volume\"]\n",
    "\n",
    "    return adjusted_OHLV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_ta as ta\n",
    "\n",
    "# help(ta.kvo)\n",
    "# help(ta.adosc)\n",
    "stk_data = ticks_data[0]\n",
    "print(stk_data)\n",
    "adjusted_OHLV = to_adjusted(stk_data)\n",
    "print(adjusted_OHLV.head(20))\n",
    "print(adjusted_OHLV.ta.stoch(high=\"Adj High\", low=\"Adj Low\", close=\"Adj Close\", k=10))\n",
    "print(stk_data.ta.stoch(k=10))\n",
    "\n",
    "print(\n",
    "    adjusted_OHLV.ta.adosc(\n",
    "        high=\"Adj High\", low=\"Adj Low\", close=\"Adj Close\", volume=\"Adj Volume\"\n",
    "    )\n",
    ")\n",
    "print(stk_data.ta.adosc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_buy_sell_signal(stk_data):\n",
    "    import pandas_ta as ta\n",
    "\n",
    "    sma = pd.concat(\n",
    "        [\n",
    "            stk_data.ta.sma(close=\"Adj Close\", length=10),\n",
    "            stk_data.ta.sma(close=\"Adj Close\", length=60),\n",
    "        ],\n",
    "        axis=1,\n",
    "    ).dropna()\n",
    "    buy_signal = sma[\"SMA_10\"] > sma[\"SMA_60\"]\n",
    "\n",
    "    buy_sell_signal = stk_data[[]].copy()\n",
    "    buy_sell_signal[\"Signal\"] = (buy_signal).astype(\"int\")\n",
    "\n",
    "    return buy_sell_signal\n",
    "\n",
    "\n",
    "def gen_analysis_data(stk_data, _return_period):\n",
    "    import pandas_ta as ta\n",
    "\n",
    "    adjusted_OHLV = to_adjusted(stk_data)\n",
    "    data = pd.concat(\n",
    "        [\n",
    "            adjusted_OHLV.ta.adosc(\n",
    "                high=\"Adj High\", low=\"Adj Low\", close=\"Adj Close\", volume=\"Adj Volume\"\n",
    "            ),\n",
    "            adjusted_OHLV.ta.kvo(\n",
    "                high=\"Adj High\", low=\"Adj Low\", close=\"Adj Close\", volume=\"Adj Volume\"\n",
    "            ),\n",
    "            stk_data.ta.rsi(close=\"Adj Close\", length=10) / 100,\n",
    "            stk_data.ta.rsi(close=\"Adj Close\", length=30) / 100,\n",
    "            stk_data.ta.rsi(close=\"Adj Close\", length=200) / 100,\n",
    "            stk_data.ta.stoch(k=10) / 100,\n",
    "            stk_data.ta.stoch(k=30) / 100,\n",
    "            stk_data.ta.stoch(k=200) / 100,\n",
    "            adjusted_OHLV.loc[\n",
    "                :, [\"Adj Open pct\", \"Adj High pct\", \"Adj Low pct\", \"Adj Volume pct\"]\n",
    "            ],\n",
    "            gen_buy_sell_signal(stk_data),\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    data = pd.concat(\n",
    "        [data.astype(\"float32\"), gen_pct_label(stk_data, _return_period)],\n",
    "        axis=1,\n",
    "    ).dropna()\n",
    "    return data\n",
    "\n",
    "\n",
    "def prepare_analysis_data(_return_period, verbose=False):\n",
    "    from tqdm import tqdm\n",
    "\n",
    "    ticks_dataset = []\n",
    "    ignore_ticks_data_count = 0\n",
    "    for i, tick_data in enumerate(tqdm(ticks_data)):\n",
    "        analysis_data = gen_analysis_data(tick_data, _return_period)\n",
    "        classes_percentage = class_percentage(analysis_data)\n",
    "        if 0 in classes_percentage:\n",
    "            if verbose:\n",
    "                print(\n",
    "                    f\"Some classes don't have any data  : {stk_symbols[i]}, {classes_percentage}\"\n",
    "                )\n",
    "            ignore_ticks_data_count += 1\n",
    "        elif any(p < class_percentage_threshold for p in classes_percentage):\n",
    "            if verbose:\n",
    "                print(\n",
    "                    f\"Some classes are too small  : {stk_symbols[i]}, {classes_percentage}\"\n",
    "                )\n",
    "            ignore_ticks_data_count += 1\n",
    "        else:\n",
    "            ticks_dataset.append(analysis_data)\n",
    "    if ignore_ticks_data_count > 0:\n",
    "        print(\n",
    "            f\"There are {ignore_ticks_data_count} stocks in total, some classes have no data or are too small\"\n",
    "        )\n",
    "    return ticks_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Open     High      Low    Close  Adj Close   Volume\n",
      "count 1895.000 1895.000 1895.000 1895.000   1895.000 1895.000\n",
      "mean   138.768  139.178  138.372  138.781    138.781    0.000\n",
      "std     13.660   13.624   13.688   13.655     13.655    0.000\n",
      "min    115.170  116.750  111.300  114.580    114.580    0.000\n",
      "25%    128.855  129.240  128.485  128.885    128.885    0.000\n",
      "50%    132.970  133.600  132.600  133.020    133.020    0.000\n",
      "75%    149.030  149.495  148.645  148.845    148.845    0.000\n",
      "max    171.630  171.900  171.410  171.650    171.650    0.000\n",
      "False\n",
      "39,AMD\n",
      "          Open     High      Low    Close  Adj Close        Volume\n",
      "count 2515.000 2515.000 2515.000 2515.000   2515.000      2515.000\n",
      "mean    43.123   44.006   42.221   43.131     43.131  54986486.600\n",
      "std     42.266   43.115   41.380   42.263     42.263  37500234.414\n",
      "min      1.620    1.690    1.610    1.620      1.620   2606600.000\n",
      "25%      5.115    5.190    5.000    5.110      5.110  29471700.000\n",
      "50%     23.660   24.230   23.220   23.680     23.680  48604800.000\n",
      "75%     82.075   83.475   80.610   82.005     82.005  73113250.000\n",
      "max    163.280  164.460  156.100  161.910    161.910 325058400.000\n",
      "149,GBP\n",
      "168,CCI\n",
      "          Open     High      Low    Close  Adj Close       Volume\n",
      "count 2515.000 2515.000 2515.000 2515.000   2515.000     2515.000\n",
      "mean   121.140  122.312  119.898  121.145    102.334  2282142.227\n",
      "std     36.807   37.273   36.260   36.803     38.768  1272282.255\n",
      "min     68.870   69.270   68.440   68.960     47.598   521800.000\n",
      "25%     87.600   88.175   87.030   87.620     66.583  1557850.000\n",
      "50%    110.520  111.460  109.550  110.480     91.589  2017700.000\n",
      "75%    152.000  154.085  149.840  152.405    136.384  2646300.000\n",
      "max    209.000  209.870  207.540  208.740    190.326 27304700.000\n",
      "190,DXCM\n",
      "          Open     High      Low    Close  Adj Close        Volume\n",
      "count 2515.000 2515.000 2515.000 2515.000   2515.000      2515.000\n",
      "mean    54.027   54.996   53.014   54.033     54.033   4002265.726\n",
      "std     42.947   43.654   42.163   42.920     42.920   4131268.529\n",
      "min      7.418    7.633    7.023    7.420      7.420    784400.000\n",
      "25%     17.500   17.739   17.181   17.495     17.495   2333650.000\n",
      "50%     31.920   32.778   31.103   32.077     32.077   3234000.000\n",
      "75%     96.661   98.960   94.620   96.539     96.539   4636600.000\n",
      "max    164.258  164.863  161.630  162.815    162.815 123168400.000\n",
      "196,USD\n",
      "          Open     High      Low    Close  Adj Close      Volume\n",
      "count 2510.000 2510.000 2510.000 2510.000   2510.000    2510.000\n",
      "mean    15.407   15.728   15.047   15.401     15.281  170103.147\n",
      "std     13.186   13.500   12.829   13.178     13.202  170427.742\n",
      "min      2.012    2.047    1.998    2.025      1.935    4800.000\n",
      "25%      4.134    4.171    4.067    4.111      3.966   77525.000\n",
      "50%     10.989   11.136   10.766   10.930     10.739  129600.000\n",
      "75%     23.488   24.045   22.843   23.387     23.330  210800.000\n",
      "max     56.670   58.410   54.890   56.220     56.044 3158400.000\n",
      "197,BIIB\n",
      "          Open     High      Low    Close  Adj Close       Volume\n",
      "count 2515.000 2515.000 2515.000 2515.000   2515.000     2515.000\n",
      "mean   289.650  293.437  285.756  289.512    289.512  1581704.254\n",
      "std     46.027   46.693   45.366   46.022     46.022  1294600.206\n",
      "min    190.560  193.890  187.160  187.540    187.540      600.000\n",
      "25%    263.275  266.965  260.345  263.205    263.205   983300.000\n",
      "50%    286.520  290.470  283.060  286.400    286.400  1306100.000\n",
      "75%    316.605  320.990  312.550  316.755    316.755  1769300.000\n",
      "max    475.920  480.180  460.500  475.980    475.980 21843100.000\n",
      "211,BKR\n",
      "          Open     High      Low    Close  Adj Close       Volume\n",
      "count 2515.000 2515.000 2515.000 2515.000   2515.000     2515.000\n",
      "mean    37.339   37.872   36.795   37.336     27.059  5860510.775\n",
      "std     16.366   16.488   16.231   16.359      6.858  4408315.457\n",
      "min      9.670   10.100    9.120    9.330      8.315   888700.000\n",
      "25%     24.280   24.645   23.865   24.270     22.180  3312950.000\n",
      "50%     32.480   32.950   32.030   32.510     27.498  4887600.000\n",
      "75%     52.085   53.055   51.430   52.320     32.360  7268850.000\n",
      "max     75.380   75.640   74.730   75.350     41.867 79090500.000\n",
      "215,CNC\n",
      "          Open     High      Low    Close  Adj Close       Volume\n",
      "count 2515.000 2515.000 2515.000 2515.000   2515.000     2515.000\n",
      "mean    52.260   52.948   51.550   52.269     52.269  3746108.350\n",
      "std     20.224   20.462   19.972   20.217     20.217  2935147.423\n",
      "min     14.010   14.210   13.778   13.915     13.915   572800.000\n",
      "25%     33.878   34.275   33.497   33.855     33.855  2343250.000\n",
      "50%     55.700   56.840   54.870   55.840     55.840  3067600.000\n",
      "75%     67.192   68.068   66.262   67.275     67.275  4258500.000\n",
      "max     96.940   98.530   96.010   97.220     97.220 78417800.000\n",
      "235,XEL\n",
      "          Open     High      Low    Close  Adj Close       Volume\n",
      "count 2515.000 2515.000 2515.000 2515.000   2515.000     2515.000\n",
      "mean    52.556   53.019   52.077   52.574     46.314  3168760.398\n",
      "std     13.974   14.137   13.789   13.963     15.575  1328279.662\n",
      "min     27.450   27.620   27.270   27.350     19.971   598400.000\n",
      "25%     40.675   40.930   40.350   40.690     32.652  2314450.000\n",
      "50%     51.360   51.840   50.850   51.380     44.251  2891200.000\n",
      "75%     65.345   65.950   64.640   65.315     61.250  3672900.000\n",
      "max     77.090   77.660   76.820   77.410     73.856 15991200.000\n",
      "284,SBAC\n",
      "          Open     High      Low    Close  Adj Close       Volume\n",
      "count 2515.000 2515.000 2515.000 2515.000   2515.000     2515.000\n",
      "mean   200.132  202.467  197.669  200.127    194.164   886673.956\n",
      "std     85.749   86.946   84.371   85.649     84.302   674166.084\n",
      "min     84.510   86.210   82.800   84.960     81.581   182800.000\n",
      "25%    115.475  116.405  114.245  115.320    110.733   572500.000\n",
      "50%    172.000  173.660  170.070  172.350    165.494   765900.000\n",
      "75%    280.855  284.645  276.625  281.210    273.411  1042950.000\n",
      "max    388.590  391.150  387.020  389.020    379.927 23507200.000\n",
      "289,CHD\n",
      "          Open     High      Low    Close  Adj Close       Volume\n",
      "count 2515.000 2515.000 2515.000 2515.000   2515.000     2515.000\n",
      "mean    64.638   65.211   64.079   64.661     61.412  1606878.648\n",
      "std     21.195   21.427   20.961   21.196     22.213  1276233.666\n",
      "min     30.975   31.735   30.500   31.030     26.928   265400.000\n",
      "25%     45.590   45.955   45.175   45.663     41.482  1090550.000\n",
      "50%     65.060   65.800   64.160   64.960     61.403  1388300.000\n",
      "75%     84.685   85.405   83.955   84.600     82.438  1842950.000\n",
      "max    104.300  105.280  103.160  104.220    101.974 51369000.000\n",
      "301,WTW\n",
      "          Open     High      Low    Close  Adj Close       Volume\n",
      "count 2515.000 2515.000 2515.000 2515.000   2515.000     2515.000\n",
      "mean   171.484  173.141  169.823  171.549    160.883   715959.207\n",
      "std     45.870   46.495   45.359   45.894     49.499   696763.860\n",
      "min    103.868  105.430  103.603  104.662     89.958    67497.000\n",
      "25%    125.629  126.457  124.688  125.620    111.513   402700.000\n",
      "50%    161.120  162.860  159.820  161.210    148.487   576700.000\n",
      "75%    210.615  212.770  208.095  210.300    203.441   845850.000\n",
      "max    271.870  271.870  268.020  270.070    259.676 22046981.000\n",
      "336,HWM\n",
      "          Open     High      Low    Close  Adj Close       Volume\n",
      "count 1767.000 1767.000 1767.000 1767.000   1767.000     1767.000\n",
      "mean    28.965   29.354   28.579   28.976     28.679  3517170.741\n",
      "std      9.288    9.325    9.257    9.297      9.371  2203294.829\n",
      "min     10.400   11.060    9.870   10.590     10.507   559500.000\n",
      "25%     22.100   22.410   21.870   22.155     21.812  2240800.000\n",
      "50%     27.600   27.920   27.200   27.560     27.060  2997900.000\n",
      "75%     34.005   34.490   33.455   33.965     33.753  4186600.000\n",
      "max     54.380   54.530   54.070   54.210     54.210 42345700.000\n",
      "345,PFG\n",
      "          Open     High      Low    Close  Adj Close       Volume\n",
      "count 2514.000 2514.000 2514.000 2514.000   2514.000     2514.000\n",
      "mean    57.933   58.557   57.304   57.950     48.941  1452502.307\n",
      "std     12.495   12.586   12.416   12.517     14.932   735210.512\n",
      "min     25.310   25.840   23.310   24.160     20.887   252500.000\n",
      "25%     49.192   49.737   48.760   49.170     37.194   995050.000\n",
      "50%     55.620   56.135   55.120   55.700     45.849  1304300.000\n",
      "75%     66.465   67.082   65.877   66.620     58.772  1703900.000\n",
      "max     94.580   96.170   93.700   95.000     91.001 14716700.000\n",
      "390,AMCR\n",
      "          Open     High      Low    Close  Adj Close       Volume\n",
      "count 1406.000 1406.000 1406.000 1406.000   1406.000     1406.000\n",
      "mean    10.863   10.959   10.764   10.863      9.544  6218750.925\n",
      "std      1.152    1.152    1.145    1.151      1.417  5412518.335\n",
      "min      5.900    6.230    5.800    5.950      5.066      100.000\n",
      "25%      9.950   10.030    9.843    9.950      8.571  3793200.000\n",
      "50%     11.050   11.140   10.940   11.020      9.648  5789150.000\n",
      "75%     11.720   11.820   11.650   11.730     10.639  8015925.000\n",
      "max     13.450   13.610   13.380   13.490     12.579 86363100.000\n",
      "429,GEN\n",
      "          Open     High      Low    Close  Adj Close        Volume\n",
      "count 2515.000 2515.000 2515.000 2515.000   2515.000      2515.000\n",
      "mean    23.106   23.377   22.839   23.115     15.095   6364070.338\n",
      "std      3.585    3.603    3.568    3.590      5.537   4891698.837\n",
      "min     15.510   16.040   15.120   15.460      6.970    957900.000\n",
      "25%     20.490   20.735   20.240   20.480     10.049   3744800.000\n",
      "50%     22.760   23.030   22.500   22.790     14.148   5224600.000\n",
      "75%     25.360   25.670   25.075   25.375     19.576   7443800.000\n",
      "max     34.180   34.200   33.720   34.160     29.367 112357800.000\n",
      "437,PEAK\n",
      "          Open     High      Low    Close  Adj Close       Volume\n",
      "count 2515.000 2515.000 2515.000 2515.000   2515.000     2515.000\n",
      "mean    30.460   30.764   30.123   30.453     23.717  3755113.700\n",
      "std      5.515    5.516    5.516    5.519      3.810  1766603.742\n",
      "min     15.670   15.670   15.240   15.550     15.279   431300.000\n",
      "25%     26.575   26.860   26.255   26.570     20.981  2652200.000\n",
      "50%     31.010   31.300   30.692   31.000     23.200  3384300.000\n",
      "75%     34.563   34.909   34.262   34.620     25.720  4415364.500\n",
      "max     45.137   45.182   43.679   43.907     33.265 23569800.000\n",
      "489,HUBB\n",
      "          Open     High      Low    Close  Adj Close       Volume\n",
      "count 2515.000 2515.000 2515.000 2515.000   2515.000     2515.000\n",
      "mean   150.495  152.034  148.894  150.496    137.872   337153.240\n",
      "std     57.673   58.388   57.009   57.728     62.772   298465.389\n",
      "min     83.160   83.780   80.330   82.960     68.406    57674.000\n",
      "25%    111.050  111.970  110.045  110.980     93.690   207353.500\n",
      "50%    123.300  124.640  122.230  123.310    109.886   285584.000\n",
      "75%    184.195  186.412  182.338  184.370    177.116   403190.000\n",
      "max    338.700  340.060  334.975  337.810    335.262 11191392.000\n"
     ]
    }
   ],
   "source": [
    "stk_data = ticks_data[149]\n",
    "d = stk_data.describe()\n",
    "print(d)\n",
    "# print(type(d).__name__)\n",
    "# print((d.loc[\"count\"] == 0).any())\n",
    "print(is_contained(d.loc[:, [\"Open\", \"High\", \"Low\", \"Close\", \"Adj Close\"]], 0))\n",
    "\n",
    "# xx = gen_analysis_data(stk_data, return_period)\n",
    "# print(xx.sort_values(\"Adj Volume pct\", ascending=False))\n",
    "# xx.describe()\n",
    "# sd = pd.DataFrame()\n",
    "# # sd.drop()\n",
    "for i, stk_data in enumerate(ticks_data):\n",
    "    if is_contained(stk_data.loc[:, [\"Open\", \"High\", \"Low\", \"Close\", \"Adj Close\"]], 0):\n",
    "        print(f\"{i},{stk_symbols[i]}\")\n",
    "    if is_contained(stk_data.describe().loc[\"std\"], 0):\n",
    "        print(f\"{i},{stk_symbols[i]}\")\n",
    "    elif (stk_data[\"Volume\"] == 0).sum() > 0:\n",
    "        print(f\"{i},{stk_symbols[i]}\")\n",
    "        xx = stk_data.drop(stk_data[stk_data[\"Volume\"] == 0].index)\n",
    "        print(xx.describe())\n",
    "# if (stk_data[\"Volume\"] == 0).sum() > 0:\n",
    "#     print(stk_data.describe())\n",
    "#     print(f\"{i},{stk_symbols[i]}\")\n",
    "#     xx = stk_data.drop(stk_data[stk_data[\"Volume\"] == 0].index)\n",
    "#     print(xx.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import math\n",
    "from MyPyUtil.util import ivmax\n",
    "\n",
    "\n",
    "class LSTMDataSet(Dataset):\n",
    "    def __init__(self, ticks_data_X, ticks_data_Y, _seq_len, balanced, pattern):\n",
    "        self.ticks_data_X = ticks_data_X\n",
    "        self.ticks_data_Y = ticks_data_Y\n",
    "        self.seq_len = _seq_len\n",
    "        self.balanced = balanced\n",
    "        self.pattern = pattern\n",
    "        self.pattern_size = 0 if pattern == None else len(pattern)\n",
    "\n",
    "        len_array = [len(d) - self.seq_len + 1 for d in ticks_data_X]\n",
    "        self.idx_boundary = [len_array[0]]\n",
    "\n",
    "        for i in range(1, len(len_array)):\n",
    "            self.idx_boundary.append(len_array[i] + self.idx_boundary[i - 1])\n",
    "\n",
    "        self.build_class_indices()\n",
    "        if self.balanced and self.pattern != None and len(self.pattern) > 0:\n",
    "            self.build_pattern_info()\n",
    "\n",
    "    def build_class_indices(self):\n",
    "        total_y = pd.concat(\n",
    "            [t[self.seq_len - 1 :][\"label\"] for t in self.ticks_data_Y]\n",
    "        ).reset_index()\n",
    "        self.class_indices = []\n",
    "        for i in range(num_classes):\n",
    "            class_idx_list = total_y.index[total_y[\"label\"] == i].tolist()\n",
    "            # random.shuffle(class_idx_list)\n",
    "            self.class_indices.append(class_idx_list)\n",
    "\n",
    "        self.class_num_of_max_size, self.max_class_size = ivmax(\n",
    "            [len(class_idx_list) for class_idx_list in self.class_indices]\n",
    "        )\n",
    "\n",
    "    def build_pattern_info(self):\n",
    "        self.inner_class_count_of_pattern = list(np.zeros(num_classes, dtype=int))\n",
    "        self.inner_offset_of_pattern = list(np.zeros(self.pattern_size, dtype=int))\n",
    "        for i, c in enumerate(self.pattern):\n",
    "            self.inner_offset_of_pattern[i] = self.inner_class_count_of_pattern[c]\n",
    "            self.inner_class_count_of_pattern[c] += 1\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.balanced:\n",
    "            if self.pattern != None and len(self.pattern) > 0:\n",
    "                return math.ceil(\n",
    "                    self.max_class_size\n",
    "                    / self.inner_class_count_of_pattern[self.class_num_of_max_size]\n",
    "                ) * len(self.pattern)\n",
    "                # return math.ceil(\n",
    "                #     self.max_class_size\n",
    "                #     * (\n",
    "                #         len(self.pattern)\n",
    "                #         / self.inner_class_count_of_pattern[self.class_num_of_max_size]\n",
    "                #     )\n",
    "                # )\n",
    "            else:\n",
    "                return self.max_class_size * num_classes\n",
    "\n",
    "        return self.idx_boundary[-1]\n",
    "\n",
    "    def info(self):\n",
    "        print(f\"Dataset size: {self.idx_boundary[-1]}\")\n",
    "        for i in range(num_classes):\n",
    "            print(\n",
    "                f\"class {i}: {len(self.class_indices[i]) * 100 /self.idx_boundary[-1]:.1f}% {len(self.class_indices[i])}\"\n",
    "            )\n",
    "        if self.balanced:\n",
    "            new_size = self.__len__()\n",
    "            print(f\"\\nNew dataset size after balancing classes: {new_size}\")\n",
    "            if self.pattern != None and len(self.pattern) > 0:\n",
    "                for i in range(num_classes):\n",
    "                    ratio = self.inner_class_count_of_pattern[i] / len(self.pattern)\n",
    "                    print(f\"class {i}: {100 * ratio:.1f}% {new_size * ratio:g}\")\n",
    "            # size_ary = list(np.zeros(num_classes))\n",
    "            # size_ary[self.class_num_of_max_size] = self.max_class_size\n",
    "            # tmp_total = self.max_class_size\n",
    "            # for i in range(num_classes):\n",
    "            #     if i == self.class_num_of_max_size:\n",
    "            #         print(\n",
    "            #             f\"class {i}: {100 * size_ary[i]/new_size:.1f}% {size_ary[i]}\"\n",
    "            #         )\n",
    "            #         continue\n",
    "\n",
    "            #     if i == num_classes - 1:\n",
    "            #         size_ary[i] = new_size - tmp_total\n",
    "            #     else:\n",
    "            #         if (new_size % self.pattern_size) == 0:\n",
    "            #             size_ary[i] = (\n",
    "            #                 new_size / self.pattern_size\n",
    "            #             ) * self.inner_class_count_of_pattern[i]\n",
    "            #         else:\n",
    "            #             size_ary[i] = (\n",
    "            #                 math.ceil(new_size / self.pattern_size)\n",
    "            #                 if i < self.class_num_of_max_size\n",
    "            #                 else math.floor(new_size / self.pattern_size)\n",
    "            #             ) * self.inner_class_count_of_pattern[i]\n",
    "            #         tmp_total += size_ary[i]\n",
    "\n",
    "            else:\n",
    "                for i in range(num_classes):\n",
    "                    print(f\"class {i}: {100/num_classes:.1f}% {self.max_class_size}\")\n",
    "\n",
    "    def idx_of_balanced_data_to_original_idx(self, idx_of_balanced_data):\n",
    "        if self.pattern != None and self.pattern_size > 0:\n",
    "            pattern_idx = idx_of_balanced_data % self.pattern_size\n",
    "            selected_class = self.pattern[pattern_idx]\n",
    "            idx_of_balanced_class = (\n",
    "                (idx_of_balanced_data // self.pattern_size)\n",
    "                * self.inner_class_count_of_pattern[selected_class]\n",
    "            ) + self.inner_offset_of_pattern[pattern_idx]\n",
    "        else:\n",
    "            selected_class = idx_of_balanced_data % num_classes\n",
    "            idx_of_balanced_class = idx_of_balanced_data // num_classes\n",
    "\n",
    "        offset_balanced_class = idx_of_balanced_class % len(\n",
    "            self.class_indices[selected_class]\n",
    "        )\n",
    "        return self.class_indices[selected_class][offset_balanced_class]\n",
    "\n",
    "    def __getitem__(self, idx_of_balanced_data):\n",
    "        idx = (\n",
    "            self.idx_of_balanced_data_to_original_idx(idx_of_balanced_data)\n",
    "            if self.balanced\n",
    "            else idx_of_balanced_data\n",
    "        )\n",
    "\n",
    "        # print(f\"getitem, idx_of_balanced_data:{idx_of_balanced_data}, idx:{idx}\")\n",
    "        for ticks_data_idx in range(len(self.ticks_data_X)):\n",
    "            if self.idx_boundary[ticks_data_idx] > idx:\n",
    "                break\n",
    "        offset = (\n",
    "            idx if ticks_data_idx == 0 else idx - self.idx_boundary[ticks_data_idx - 1]\n",
    "        )\n",
    "        x = np.array(self.ticks_data_X[ticks_data_idx][offset : offset + self.seq_len])\n",
    "        y = int(self.ticks_data_Y[ticks_data_idx].iloc[offset + self.seq_len - 1, :])\n",
    "        return (x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "\n",
    "\n",
    "def prepare_LSTMDataset(_return_period, _seq_len, train_data_pattern=None):\n",
    "    ticks_dataset = prepare_analysis_data(_return_period)\n",
    "    ticks_X_train_data = []\n",
    "    ticks_Y_train_data = []\n",
    "    ticks_X_test_data = []\n",
    "    ticks_Y_test_data = []\n",
    "    ticks_X_dfm = []\n",
    "    for idx, dataset in enumerate(ticks_dataset):\n",
    "        # test_size = int(dataset.shape[0] * validation_size)\n",
    "        train_size = int(dataset.shape[0] * (1 - validation_size))\n",
    "        # random.seed(42)\n",
    "        train_data = dataset.iloc[0:train_size]\n",
    "        test_data = dataset.iloc[train_size - seq_len + 1 :]\n",
    "\n",
    "        X_train_data = train_data.iloc[:, :-1]\n",
    "        Y_train_data = train_data.iloc[:, -1:]\n",
    "\n",
    "        X_test_data = test_data.iloc[:, :-1]\n",
    "        Y_test_data = test_data.iloc[:, -1:]\n",
    "\n",
    "        features = [\n",
    "            ([column], StandardScaler()) for column in X_train_data.columns[:-1].values\n",
    "        ]\n",
    "        features.extend(\n",
    "            [([column], None) for column in X_train_data.columns[-1:].values]\n",
    "        )\n",
    "        if len(features) != 17:\n",
    "            print(f\"Wrong data: {stk_symbols[idx]}, {X_train_data.columns.values}\")\n",
    "            break\n",
    "        # print(idx)\n",
    "        X_dfm = DataFrameMapper(features, input_df=True, df_out=True)\n",
    "        X_train_data = X_dfm.fit_transform(X_train_data)\n",
    "        X_test_data = X_dfm.transform(X_test_data)\n",
    "\n",
    "        ticks_X_dfm.append(X_dfm)\n",
    "        ticks_X_train_data.append(X_train_data)\n",
    "        ticks_Y_train_data.append(Y_train_data)\n",
    "        ticks_X_test_data.append(X_test_data)\n",
    "        ticks_Y_test_data.append(Y_test_data)\n",
    "\n",
    "    train_dataset = LSTMDataSet(\n",
    "        ticks_X_train_data,\n",
    "        ticks_Y_train_data,\n",
    "        _seq_len,\n",
    "        balanced=True,\n",
    "        pattern=train_data_pattern,\n",
    "    )\n",
    "    test_dataset = LSTMDataSet(\n",
    "        ticks_X_test_data, ticks_Y_test_data, _seq_len, balanced=False, pattern=None\n",
    "    )\n",
    "\n",
    "    print(\"Training data:\")\n",
    "    train_dataset.info()\n",
    "    print(\"\\nTest data\")\n",
    "    test_dataset.info()\n",
    "\n",
    "    return [train_dataset, test_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_LSTMDataset(return_period, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t, s = prepare_LSTMDataset(return_period, seq_len, [0, 1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "\n",
    "\n",
    "def prepare_dataloader(_return_period, _seq_len, train_data_pattern=None):\n",
    "    data = prepare_LSTMDataset(_return_period, _seq_len, train_data_pattern)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        data[0],\n",
    "        batch_size,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory,\n",
    "        pin_memory_device=device_name,\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        data[1],\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory,\n",
    "        pin_memory_device=device_name,\n",
    "    )\n",
    "\n",
    "    return train_loader, test_loader, data[0].ticks_data_X[0].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "\n",
    "class StockPCTLabelPredictLSTM(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size,\n",
    "        hidden_size,\n",
    "        num_layers,\n",
    "        num_fc_layers,\n",
    "        activation_type,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.setup_model(\n",
    "            input_size,\n",
    "            hidden_size,\n",
    "            num_layers,\n",
    "            num_fc_layers,\n",
    "            activation_type,\n",
    "        )\n",
    "\n",
    "    def __init__(self, input_size, config):\n",
    "        super().__init__()\n",
    "        self.setup_model(\n",
    "            input_size=input_size,\n",
    "            hidden_size=config[\"hidden_size\"],\n",
    "            num_layers=config[\"num_layers\"],\n",
    "            num_fc_layers=config[\"num_fc_layers\"],\n",
    "            activation_type=config[\"activation_type\"],\n",
    "        )\n",
    "\n",
    "    def setup_model(\n",
    "        self,\n",
    "        input_size,\n",
    "        hidden_size,\n",
    "        num_layers,\n",
    "        num_fc_layers,\n",
    "        activation_type,\n",
    "    ):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \"\"\"\n",
    "            input_size    : The number of expected features in the input x\n",
    "            hidden_size   : The number of features in the hidden state h\n",
    "            num_layers    : Number of recurrent layers. E.g., setting num_layers=2 would mean stacking two LSTMs together to form a stacked LSTM, with the second LSTM taking in outputs of the first LSTM and computing the final results. Default: 1\n",
    "            bias          : If False, then the layer does not use bias weights b_ih and b_hh. Default: True\n",
    "            batch_first   : If True, then the input and output tensors are provided as (batch, seq, feature) instead of (seq, batch, feature). Note that this does not apply to hidden or cell states. See the Inputs/Outputs sections below for details. Default: False\n",
    "            dropout       : If non-zero, introduces a Dropout layer on the outputs of each LSTM layer except the last layer, with dropout probability equal to dropout. Default: 0\n",
    "            bidirectional : If True, becomes a bidirectional LSTM. Default: False\n",
    "            proj_size     : If > 0, will use LSTM with projections of corresponding size. Default: 0\n",
    "        \"\"\"\n",
    "        self.rnn = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "\n",
    "        layers = []\n",
    "        in_features = self.hidden_size\n",
    "        for i in range(1, num_fc_layers):\n",
    "            out_features = int(in_features / 2)\n",
    "            if out_features <= num_classes:\n",
    "                break\n",
    "            layers.append(nn.Linear(in_features, out_features))\n",
    "            (\n",
    "                layers.append(nn.ReLU() if activation_type == 1 else nn.Sigmoid())\n",
    "                if activation_type == 2\n",
    "                else nn.Tanh()\n",
    "            )\n",
    "            in_features = out_features\n",
    "\n",
    "        layers.append(nn.Linear(in_features, num_classes))\n",
    "        self.fc = nn.Sequential(*layers)\n",
    "        self.fc.apply(self.init_weights)\n",
    "\n",
    "    def init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            initrange = 0.5\n",
    "            nn.init.uniform_(m.weight, -initrange, initrange)\n",
    "            nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h_0 = torch.zeros(self.num_layers, x.shape[0], self.hidden_size).to(device)\n",
    "        c_0 = torch.zeros(self.num_layers, x.shape[0], self.hidden_size).to(device)\n",
    "        out, (h_out, _) = self.rnn(x, (h_0, c_0))\n",
    "\n",
    "        fc_input = h_out[-1].view(-1, self.hidden_size)\n",
    "        return self.fc(fc_input)\n",
    "\n",
    "\n",
    "def save_model(model, hyper_parameters, file_path, epoch_num=None):\n",
    "    state = {\n",
    "        \"epoch_num\": epoch_num,\n",
    "        \"time\": str(datetime.now),\n",
    "        \"model_state\": model.state_dict(),\n",
    "        \"input_size\": model.input_size,\n",
    "        \"hyper_parameters\": hyper_parameters,\n",
    "    }\n",
    "    torch.save(state, file_path)\n",
    "\n",
    "\n",
    "def load_model(file_path):\n",
    "    data_dict = torch.load(file_path)\n",
    "    hyper_parameters = data_dict[\"hyper_parameters\"]\n",
    "    model = StockPCTLabelPredictLSTM(\n",
    "        input_size=data_dict[\"input_size\"],\n",
    "        hidden_size=int(hyper_parameters[\"hidden_size\"]),\n",
    "        num_layers=int(hyper_parameters[\"num_layers\"]),\n",
    "        num_fc_layers=int(hyper_parameters[\"num_fc_layers\"]),\n",
    "        activation_type=int(hyper_parameters[\"activation_type\"]),\n",
    "    )\n",
    "    model.load_state_dict(data_dict[\"model_state\"])\n",
    "    return model, hyper_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "METRICS_LABEL_NDX = 0  # ground_truth\n",
    "METRICS_PBTY_NDX = 1  # Probability of predicition\n",
    "METRICS_PRED_NDX = 2  # class(label) of predicition\n",
    "METRICS_LOSS_NDX = 3\n",
    "METRICS_SIZE = 4\n",
    "softmax = nn.Softmax(dim=1)\n",
    "totalTrainingSamples_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-08 09:57:46.712561: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-08 09:57:46.713891: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-02-08 09:57:46.734207: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-08 09:57:47.125065: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from collections import namedtuple\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "def logMetrics(\n",
    "    epoch_ndx,\n",
    "    mode_str,\n",
    "    metrics_t,\n",
    "    classificationThreshold=0.5,\n",
    "    config=None,\n",
    "    log_hparam=False,\n",
    "):\n",
    "    log.info(\n",
    "        \"E{} {}\".format(\n",
    "            epoch_ndx,\n",
    "            task_name,\n",
    "        )\n",
    "    )\n",
    "    F1_rec = namedtuple(\n",
    "        \"f1_rec\",\n",
    "        \"target_class pos_correct neg_correct pos_count neg_count pos_loss neg_loss precision recall F1\",\n",
    "    )\n",
    "    F1_metrics = []\n",
    "    for target_class in reversed(range(num_classes)):\n",
    "        posLabel_mask = metrics_t[METRICS_LABEL_NDX] == target_class\n",
    "        pos_count = posLabel_mask.sum()\n",
    "        negLabel_mask = metrics_t[METRICS_LABEL_NDX] != target_class\n",
    "        neg_count = negLabel_mask.sum()\n",
    "\n",
    "        posPred_mask = metrics_t[METRICS_PRED_NDX] == target_class\n",
    "        threshold_mask = metrics_t[METRICS_PBTY_NDX] > classificationThreshold\n",
    "        # TP, truePos_count\n",
    "        TP = pos_correct = int((posLabel_mask & posPred_mask & threshold_mask).sum())\n",
    "\n",
    "        negPred_mask = metrics_t[METRICS_PRED_NDX] != target_class\n",
    "        # TN, trueNeg_count\n",
    "        TN = neg_correct = int((negLabel_mask & negPred_mask).sum())\n",
    "\n",
    "        # FP, falsePos_count\n",
    "        FP = neg_count - neg_correct\n",
    "        # FN, falseNeg_count\n",
    "        FN = pos_count - pos_correct\n",
    "\n",
    "        # precision = TP / (TP + FP)\n",
    "        precision = 0.0 if (TP + FP) == 0 else TP / np.float32(TP + FP)\n",
    "        # recall = TP / (TP + FN)\n",
    "        recall = 0.0 if (TP + FN) == 0 else TP / np.float32(TP + FN)\n",
    "        # F1 = 2 * precision * recall / (precision + recall)\n",
    "        F1 = (\n",
    "            0.0\n",
    "            if (precision + recall) == 0.0\n",
    "            else (2 * precision * recall) / np.float32(precision + recall)\n",
    "        )\n",
    "        F1_metrics.append(\n",
    "            F1_rec(\n",
    "                target_class,\n",
    "                pos_correct,\n",
    "                neg_correct,\n",
    "                pos_count,\n",
    "                neg_count,\n",
    "                metrics_t[METRICS_LOSS_NDX, posLabel_mask].mean(),\n",
    "                metrics_t[METRICS_LOSS_NDX, negLabel_mask].mean(),\n",
    "                precision,\n",
    "                recall,\n",
    "                F1,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        if num_classes == 2:\n",
    "            break\n",
    "\n",
    "    metrics_dict = {}\n",
    "    metrics_dict[\" e_loss/all\"] = metrics_t[METRICS_LOSS_NDX].mean()\n",
    "    log.info(\n",
    "        (\"E{} {:8} { e_loss/all:.4f} loss\").format(\n",
    "            epoch_ndx,\n",
    "            mode_str,\n",
    "            **metrics_dict,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    for target_class, rec in enumerate(F1_metrics):\n",
    "        target_class_str = f\"class {rec.target_class}\" if num_classes > 2 else \"\"\n",
    "        metrics_dict[f\"{target_class_str} e_loss/pos\"] = rec.pos_loss\n",
    "        metrics_dict[f\"{target_class_str} e_loss/neg\"] = rec.neg_loss\n",
    "\n",
    "        metrics_dict[f\"{target_class_str} correct/all\"] = (\n",
    "            (rec.pos_correct + rec.neg_correct) / metrics_t.shape[1] * 100\n",
    "        )\n",
    "        metrics_dict[f\"{target_class_str} correct/neg\"] = (\n",
    "            (rec.neg_correct) / rec.neg_count * 100\n",
    "        )\n",
    "        metrics_dict[f\"{target_class_str} correct/pos\"] = (\n",
    "            (rec.pos_correct) / rec.pos_count * 100\n",
    "        )\n",
    "        metrics_dict[f\"{target_class_str} pr/precision\"] = rec.precision\n",
    "        metrics_dict[f\"{target_class_str} pr/recall\"] = rec.recall\n",
    "        metrics_dict[f\"{target_class_str} pr/f1_score\"] = rec.F1\n",
    "\n",
    "        log.info(\n",
    "            (\n",
    "                \"E{} {:8} {} {\"\n",
    "                + f\"{target_class_str}\"\n",
    "                + \" correct/all:-5.1f}% correct, \"\n",
    "                + \"{\"\n",
    "                + f\"{target_class_str}\"\n",
    "                + \" pr/precision:.4f} precision, \"\n",
    "                + \"{\"\n",
    "                + f\"{target_class_str}\"\n",
    "                + \" pr/recall:.4f} recall, \"\n",
    "                + \"{\"\n",
    "                + f\"{target_class_str}\"\n",
    "                + \" pr/f1_score:.4f} f1 score\"\n",
    "            ).format(epoch_ndx, mode_str, target_class_str, **metrics_dict)\n",
    "        )\n",
    "        log.info(\n",
    "            (\n",
    "                \"E{} {:8} {} {\"\n",
    "                + f\"{target_class_str}\"\n",
    "                + \" e_loss/neg:.4f} loss, \"\n",
    "                + \"{\"\n",
    "                + f\"{target_class_str}\"\n",
    "                + \" correct/neg:-5.1f}% correct ({neg_correct:} of {neg_count:})\"\n",
    "            ).format(\n",
    "                epoch_ndx,\n",
    "                mode_str + \"_neg\",\n",
    "                target_class_str,\n",
    "                neg_correct=rec.neg_correct,\n",
    "                neg_count=rec.neg_count,\n",
    "                **metrics_dict,\n",
    "            )\n",
    "        )\n",
    "        log.info(\n",
    "            (\n",
    "                \"E{} {:8} {} {\"\n",
    "                + f\"{target_class_str}\"\n",
    "                + \" e_loss/pos:.4f} loss, \"\n",
    "                + \"{\"\n",
    "                + f\"{target_class_str}\"\n",
    "                + \" correct/pos:-5.1f}% correct ({pos_correct:} of {pos_count:})\"\n",
    "            ).format(\n",
    "                epoch_ndx,\n",
    "                mode_str + \"_pos\",\n",
    "                target_class_str,\n",
    "                pos_correct=rec.pos_correct,\n",
    "                pos_count=rec.pos_count,\n",
    "                **metrics_dict,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    writer = SummaryWriter(log_dir=log_dir + f\"/{mode_str}_cls\")\n",
    "    for key, value in metrics_dict.items():\n",
    "        writer.add_scalar(key, value, totalTrainingSamples_count)\n",
    "\n",
    "    writer.add_pr_curve(\n",
    "        \"pr\",\n",
    "        metrics_t[METRICS_LABEL_NDX],\n",
    "        metrics_t[METRICS_PRED_NDX],\n",
    "        totalTrainingSamples_count,\n",
    "    )\n",
    "\n",
    "    bins = [x / 50.0 for x in range(51)]\n",
    "    negHist_mask = negLabel_mask & (metrics_t[METRICS_PBTY_NDX] > 0.01)\n",
    "    posHist_mask = posLabel_mask & (metrics_t[METRICS_PBTY_NDX] < 0.99)\n",
    "    if negHist_mask.any():\n",
    "        writer.add_histogram(\n",
    "            \"is_neg\",\n",
    "            metrics_t[METRICS_PBTY_NDX, negHist_mask],\n",
    "            totalTrainingSamples_count,\n",
    "            bins=bins,\n",
    "        )\n",
    "    if posHist_mask.any():\n",
    "        writer.add_histogram(\n",
    "            \"is_pos\",\n",
    "            metrics_t[METRICS_PBTY_NDX, posHist_mask],\n",
    "            totalTrainingSamples_count,\n",
    "            bins=bins,\n",
    "        )\n",
    "\n",
    "    if log_hparam:\n",
    "        hparam = config.copy()\n",
    "        hparam[\"0:trn,1:val\"] = 0 if mode_str == \"trn\" else 1\n",
    "        writer.add_hparams(\n",
    "            hparam,\n",
    "            {\n",
    "                \"loss\": metrics_t[METRICS_LOSS_NDX].mean(),\n",
    "                \"F1\": F1_metrics[-1].F1,\n",
    "            },\n",
    "        )\n",
    "\n",
    "    writer.close()\n",
    "\n",
    "    return float(metrics_dict[\" e_loss/all\"]), F1_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "\n",
    "def computeBatchLoss(model, loss_fn, x, y, metrics_g, batch_idx):\n",
    "    x_g = x.to(device)\n",
    "    y_g = y.to(device)\n",
    "    outputs = model(x_g)\n",
    "    if outputs.isnan().sum() > 0:\n",
    "        return sys.float_info.max\n",
    "\n",
    "    loss_g = loss_fn(outputs, y_g)\n",
    "    probability_g, predition_g = torch.max(softmax(outputs), dim=1)\n",
    "\n",
    "    start_ndx = batch_idx * batch_size\n",
    "    end_ndx = start_ndx + y.size(0)\n",
    "\n",
    "    metrics_g[METRICS_LABEL_NDX, start_ndx:end_ndx] = y_g\n",
    "    metrics_g[METRICS_PBTY_NDX, start_ndx:end_ndx] = probability_g\n",
    "    metrics_g[METRICS_PRED_NDX, start_ndx:end_ndx] = predition_g\n",
    "    metrics_g[METRICS_LOSS_NDX, start_ndx:end_ndx] = loss_g\n",
    "    loss = loss_g.mean()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MyPyUtil.util import enumerateWithEstimate\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def doTraining(model, optimizer, loss_fn, epoch_ndx, train_dl):\n",
    "    global totalTrainingSamples_count\n",
    "    model.train()\n",
    "    trnMetrics_g = torch.zeros(\n",
    "        METRICS_SIZE,\n",
    "        len(train_dl.dataset),\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    batch_iter = enumerateWithEstimate(\n",
    "        train_dl,\n",
    "        \"E{} Training\".format(epoch_ndx),\n",
    "        start_ndx=train_dl.num_workers,\n",
    "    )\n",
    "    for batch_ndx, (x, y) in batch_iter:\n",
    "        # for batch_ndx, (x, y) in enumerate(tqdm(train_dl)):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss = computeBatchLoss(\n",
    "            model,\n",
    "            loss_fn,\n",
    "            x,\n",
    "            y,\n",
    "            trnMetrics_g,\n",
    "            batch_ndx,\n",
    "        )\n",
    "\n",
    "        if loss == sys.float_info.max:\n",
    "            print(f\"forward error: {batch_ndx}\")\n",
    "        else:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    totalTrainingSamples_count += len(train_dl.dataset)\n",
    "    return trnMetrics_g.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doValidation(model, loss_fn, epoch_ndx, val_dl):\n",
    "    from sklearn.metrics import f1_score\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        valMetrics_g = torch.zeros(\n",
    "            METRICS_SIZE,\n",
    "            len(val_dl.dataset),\n",
    "            device=device,\n",
    "        )\n",
    "\n",
    "        batch_iter = enumerateWithEstimate(\n",
    "            val_dl,\n",
    "            \"E{} Validation \".format(epoch_ndx),\n",
    "            start_ndx=val_dl.num_workers,\n",
    "        )\n",
    "        for batch_ndx, (x, y) in batch_iter:\n",
    "            # for batch_ndx, (x, y) in enumerate(tqdm(val_dl)):\n",
    "            loss = computeBatchLoss(model, loss_fn, x, y, valMetrics_g, batch_ndx)\n",
    "            if loss == sys.float_info.max:\n",
    "                print(f\"forward error: {batch_ndx}\")\n",
    "\n",
    "    return valMetrics_g.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_LSTM(config):\n",
    "    global totalTrainingSamples_count\n",
    "    best_f1 = 0\n",
    "\n",
    "    lr = config[\"lr\"]\n",
    "    momentum = config[\"momentum\"]\n",
    "    optim_type = config[\"optim_type\"]\n",
    "    totalTrainingSamples_count = 0\n",
    "\n",
    "    id_str = \"_\".join(str(v) if v < 1 else f\"{v:g}\" for v in config.values())\n",
    "    # print(id_str)\n",
    "    model_name = f\"{log_dir}/{id_str}.pt\"\n",
    "\n",
    "    train_loader, test_loader, features_size = prepare_dataloader(\n",
    "        config[\"return_period\"], config[\"seq_len\"], train_data_pattern=[0, 0, 1]\n",
    "    )\n",
    "\n",
    "    model = StockPCTLabelPredictLSTM(input_size=features_size, config=config)\n",
    "    model = model.to(device)\n",
    "\n",
    "    optimizer = (\n",
    "        torch.optim.Adam(model.parameters(), lr=lr)\n",
    "        if optim_type == 1\n",
    "        else torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "    )\n",
    "    loss_fn = torch.nn.CrossEntropyLoss(reduction=\"none\")\n",
    "\n",
    "    for epoch_ndx in range(epoch_num):\n",
    "        trnMetrics_t = doTraining(model, optimizer, loss_fn, epoch_ndx, train_loader)\n",
    "        loss, _ = logMetrics(\n",
    "            epoch_ndx,\n",
    "            \"trn\",\n",
    "            trnMetrics_t,\n",
    "            classificationThreshold,\n",
    "            config,\n",
    "            (epoch_ndx == epoch_num - 1),\n",
    "        )\n",
    "\n",
    "        valMetrics_t = doValidation(model, loss_fn, epoch_ndx, test_loader)\n",
    "        _, F1_metrics = logMetrics(\n",
    "            epoch_ndx,\n",
    "            \"val\",\n",
    "            valMetrics_t,\n",
    "            classificationThreshold,\n",
    "            config,\n",
    "            (epoch_ndx == epoch_num - 1),\n",
    "        )\n",
    "        if F1_metrics[0].F1 > best_f1:\n",
    "            best_f1 = F1_metrics[0].F1\n",
    "            save_model(model, config, model_name)\n",
    "            print(f\"current loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/AIWorkSpace/work/fin-ml/runs/StockPCTLabelPredictLSTMV2/2024-02-08_09.59.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 494/494 [00:06<00:00, 78.10it/s]\n",
      "2024-02-08 10:00:02,076 INFO     pid:26301 MyPyUtil.util:146:enumerateWithEstimate E0 Training ----/37103, starting\n",
      "2024-02-08 10:00:02,158 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E0 Training    4/37103, done at 2024-02-08 10:10:02, 0:10:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data:\n",
      "Dataset size: 897349\n",
      "class 0: 88.2% 791528\n",
      "class 1: 11.8% 105821\n",
      "\n",
      "New dataset size after balancing classes: 1187292\n",
      "class 0: 66.7% 791528\n",
      "class 1: 33.3% 395764\n",
      "\n",
      "Test data\n",
      "Dataset size: 224838\n",
      "class 0: 84.8% 190583\n",
      "class 1: 15.2% 34255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-08 10:00:02,262 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E0 Training   32/37103, done at 2024-02-08 10:03:29, 0:03:27\n",
      "2024-02-08 10:00:03,062 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E0 Training  256/37103, done at 2024-02-08 10:02:24, 0:02:22\n",
      "2024-02-08 10:00:10,560 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E0 Training 2048/37103, done at 2024-02-08 10:02:35, 0:02:33\n",
      "2024-02-08 10:01:05,223 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E0 Training 16384/37103, done at 2024-02-08 10:02:25, 0:02:22\n",
      "2024-02-08 10:02:24,545 INFO     pid:26301 MyPyUtil.util:181:enumerateWithEstimate E0 Training 37103/37103, done at 2024-02-08 10:02:24\n",
      "2024-02-08 10:02:24,550 INFO     pid:26301 __main__:013:logMetrics E0 StockPCTLabelPredictLSTMV2\n",
      "2024-02-08 10:02:24,560 INFO     pid:26301 __main__:074:logMetrics E0 trn      0.5761 loss\n",
      "2024-02-08 10:02:24,561 INFO     pid:26301 __main__:100:logMetrics E0 trn        71.4% correct, 0.6528 precision, 0.3007 recall, 0.4117 f1 score\n",
      "2024-02-08 10:02:24,561 INFO     pid:26301 __main__:116:logMetrics E0 trn_neg   0.3704 loss,  92.0% correct (728233 of 791528)\n",
      "2024-02-08 10:02:24,562 INFO     pid:26301 __main__:133:logMetrics E0 trn_pos   0.9875 loss,  30.1% correct (119006 of 395764)\n",
      "2024-02-08 10:02:24,652 INFO     pid:26301 MyPyUtil.util:146:enumerateWithEstimate E0 Validation  ----/7027, starting\n",
      "2024-02-08 10:02:24,669 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E0 Validation     4/7027, done at 2024-02-08 10:02:47, 0:00:23\n",
      "2024-02-08 10:02:24,707 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E0 Validation    16/7027, done at 2024-02-08 10:02:46, 0:00:22\n",
      "2024-02-08 10:02:24,846 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E0 Validation    64/7027, done at 2024-02-08 10:02:45, 0:00:20\n",
      "2024-02-08 10:02:25,389 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E0 Validation   256/7027, done at 2024-02-08 10:02:44, 0:00:20\n",
      "2024-02-08 10:02:27,582 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E0 Validation  1024/7027, done at 2024-02-08 10:02:44, 0:00:20\n",
      "2024-02-08 10:02:38,068 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E0 Validation  4096/7027, done at 2024-02-08 10:02:47, 0:00:23\n",
      "2024-02-08 10:02:47,307 INFO     pid:26301 MyPyUtil.util:181:enumerateWithEstimate E0 Validation  7027/7027, done at 2024-02-08 10:02:47\n",
      "2024-02-08 10:02:47,309 INFO     pid:26301 __main__:013:logMetrics E0 StockPCTLabelPredictLSTMV2\n",
      "2024-02-08 10:02:47,310 INFO     pid:26301 __main__:074:logMetrics E0 val      0.6091 loss\n",
      "2024-02-08 10:02:47,310 INFO     pid:26301 __main__:100:logMetrics E0 val        67.3% correct, 0.2199 precision, 0.4512 recall, 0.2957 f1 score\n",
      "2024-02-08 10:02:47,310 INFO     pid:26301 __main__:116:logMetrics E0 val_neg   0.5680 loss,  71.2% correct (135759 of 190583)\n",
      "2024-02-08 10:02:47,311 INFO     pid:26301 __main__:133:logMetrics E0 val_pos   0.8380 loss,  45.1% correct (15457 of 34255)\n",
      "2024-02-08 10:02:47,333 INFO     pid:26301 MyPyUtil.util:146:enumerateWithEstimate E1 Training ----/37103, starting\n",
      "2024-02-08 10:02:47,355 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E1 Training    4/37103, done at 2024-02-08 10:05:25, 0:02:38\n",
      "2024-02-08 10:02:47,454 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E1 Training   32/37103, done at 2024-02-08 10:05:02, 0:02:15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current loss: 0.5760806202888489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-08 10:02:48,237 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E1 Training  256/37103, done at 2024-02-08 10:04:57, 0:02:10\n",
      "2024-02-08 10:02:54,650 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E1 Training 2048/37103, done at 2024-02-08 10:04:59, 0:02:12\n",
      "2024-02-08 10:03:47,813 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E1 Training 16384/37103, done at 2024-02-08 10:05:04, 0:02:16\n",
      "2024-02-08 10:05:09,425 INFO     pid:26301 MyPyUtil.util:181:enumerateWithEstimate E1 Training 37103/37103, done at 2024-02-08 10:05:09\n",
      "2024-02-08 10:05:09,618 INFO     pid:26301 __main__:013:logMetrics E1 StockPCTLabelPredictLSTMV2\n",
      "2024-02-08 10:05:09,773 INFO     pid:26301 __main__:074:logMetrics E1 trn      0.5670 loss\n",
      "2024-02-08 10:05:09,774 INFO     pid:26301 __main__:100:logMetrics E1 trn        71.7% correct, 0.6497 precision, 0.3273 recall, 0.4353 f1 score\n",
      "2024-02-08 10:05:09,774 INFO     pid:26301 __main__:116:logMetrics E1 trn_neg   0.3649 loss,  91.2% correct (721695 of 791528)\n",
      "2024-02-08 10:05:09,774 INFO     pid:26301 __main__:133:logMetrics E1 trn_pos   0.9711 loss,  32.7% correct (129537 of 395764)\n",
      "2024-02-08 10:05:09,856 INFO     pid:26301 MyPyUtil.util:146:enumerateWithEstimate E1 Validation  ----/7027, starting\n",
      "2024-02-08 10:05:09,874 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E1 Validation     4/7027, done at 2024-02-08 10:05:35, 0:00:25\n",
      "2024-02-08 10:05:09,913 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E1 Validation    16/7027, done at 2024-02-08 10:05:33, 0:00:23\n",
      "2024-02-08 10:05:10,062 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E1 Validation    64/7027, done at 2024-02-08 10:05:32, 0:00:22\n",
      "2024-02-08 10:05:10,623 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E1 Validation   256/7027, done at 2024-02-08 10:05:30, 0:00:20\n",
      "2024-02-08 10:05:12,883 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E1 Validation  1024/7027, done at 2024-02-08 10:05:30, 0:00:20\n",
      "2024-02-08 10:05:22,128 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E1 Validation  4096/7027, done at 2024-02-08 10:05:30, 0:00:21\n",
      "2024-02-08 10:05:31,216 INFO     pid:26301 MyPyUtil.util:181:enumerateWithEstimate E1 Validation  7027/7027, done at 2024-02-08 10:05:31\n",
      "2024-02-08 10:05:31,217 INFO     pid:26301 __main__:013:logMetrics E1 StockPCTLabelPredictLSTMV2\n",
      "2024-02-08 10:05:31,218 INFO     pid:26301 __main__:074:logMetrics E1 val      0.6099 loss\n",
      "2024-02-08 10:05:31,219 INFO     pid:26301 __main__:100:logMetrics E1 val        67.4% correct, 0.2222 precision, 0.4553 recall, 0.2987 f1 score\n",
      "2024-02-08 10:05:31,219 INFO     pid:26301 __main__:116:logMetrics E1 val_neg   0.5701 loss,  71.4% correct (136004 of 190583)\n",
      "2024-02-08 10:05:31,219 INFO     pid:26301 __main__:133:logMetrics E1 val_pos   0.8316 loss,  45.5% correct (15596 of 34255)\n",
      "2024-02-08 10:05:31,242 INFO     pid:26301 MyPyUtil.util:146:enumerateWithEstimate E2 Training ----/37103, starting\n",
      "2024-02-08 10:05:31,265 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E2 Training    4/37103, done at 2024-02-08 10:08:16, 0:02:44\n",
      "2024-02-08 10:05:31,364 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E2 Training   32/37103, done at 2024-02-08 10:07:47, 0:02:16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current loss: 0.5669662356376648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-08 10:05:32,143 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E2 Training  256/37103, done at 2024-02-08 10:07:41, 0:02:10\n",
      "2024-02-08 10:05:38,376 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E2 Training 2048/37103, done at 2024-02-08 10:07:40, 0:02:09\n",
      "2024-02-08 10:06:32,855 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E2 Training 16384/37103, done at 2024-02-08 10:07:50, 0:02:19\n",
      "2024-02-08 10:07:52,397 INFO     pid:26301 MyPyUtil.util:181:enumerateWithEstimate E2 Training 37103/37103, done at 2024-02-08 10:07:52\n",
      "2024-02-08 10:07:52,592 INFO     pid:26301 __main__:013:logMetrics E2 StockPCTLabelPredictLSTMV2\n",
      "2024-02-08 10:07:52,761 INFO     pid:26301 __main__:074:logMetrics E2 trn      0.5633 loss\n",
      "2024-02-08 10:07:52,762 INFO     pid:26301 __main__:100:logMetrics E2 trn        71.9% correct, 0.6559 precision, 0.3326 recall, 0.4414 f1 score\n",
      "2024-02-08 10:07:52,762 INFO     pid:26301 __main__:116:logMetrics E2 trn_neg   0.3623 loss,  91.3% correct (722484 of 791528)\n",
      "2024-02-08 10:07:52,762 INFO     pid:26301 __main__:133:logMetrics E2 trn_pos   0.9654 loss,  33.3% correct (131616 of 395764)\n",
      "2024-02-08 10:07:52,843 INFO     pid:26301 MyPyUtil.util:146:enumerateWithEstimate E2 Validation  ----/7027, starting\n",
      "2024-02-08 10:07:52,861 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E2 Validation     4/7027, done at 2024-02-08 10:08:16, 0:00:23\n",
      "2024-02-08 10:07:52,900 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E2 Validation    16/7027, done at 2024-02-08 10:08:15, 0:00:23\n",
      "2024-02-08 10:07:53,067 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E2 Validation    64/7027, done at 2024-02-08 10:08:16, 0:00:24\n",
      "2024-02-08 10:07:53,627 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E2 Validation   256/7027, done at 2024-02-08 10:08:14, 0:00:21\n",
      "2024-02-08 10:07:55,874 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E2 Validation  1024/7027, done at 2024-02-08 10:08:13, 0:00:20\n",
      "2024-02-08 10:08:05,058 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E2 Validation  4096/7027, done at 2024-02-08 10:08:13, 0:00:20\n",
      "2024-02-08 10:08:14,174 INFO     pid:26301 MyPyUtil.util:181:enumerateWithEstimate E2 Validation  7027/7027, done at 2024-02-08 10:08:14\n",
      "2024-02-08 10:08:14,175 INFO     pid:26301 __main__:013:logMetrics E2 StockPCTLabelPredictLSTMV2\n",
      "2024-02-08 10:08:14,176 INFO     pid:26301 __main__:074:logMetrics E2 val      0.6032 loss\n",
      "2024-02-08 10:08:14,177 INFO     pid:26301 __main__:100:logMetrics E2 val        68.7% correct, 0.2272 precision, 0.4396 recall, 0.2995 f1 score\n",
      "2024-02-08 10:08:14,177 INFO     pid:26301 __main__:116:logMetrics E2 val_neg   0.5606 loss,  73.1% correct (139353 of 190583)\n",
      "2024-02-08 10:08:14,177 INFO     pid:26301 __main__:133:logMetrics E2 val_pos   0.8400 loss,  44.0% correct (15058 of 34255)\n",
      "2024-02-08 10:08:14,206 INFO     pid:26301 MyPyUtil.util:146:enumerateWithEstimate E3 Training ----/37103, starting\n",
      "2024-02-08 10:08:14,227 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E3 Training    4/37103, done at 2024-02-08 10:10:44, 0:02:30\n",
      "2024-02-08 10:08:14,330 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E3 Training   32/37103, done at 2024-02-08 10:10:32, 0:02:18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current loss: 0.5633395910263062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-08 10:08:15,121 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E3 Training  256/37103, done at 2024-02-08 10:10:26, 0:02:12\n",
      "2024-02-08 10:08:21,444 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E3 Training 2048/37103, done at 2024-02-08 10:10:25, 0:02:11\n",
      "2024-02-08 10:09:12,861 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E3 Training 16384/37103, done at 2024-02-08 10:10:27, 0:02:12\n",
      "2024-02-08 10:10:33,305 INFO     pid:26301 MyPyUtil.util:181:enumerateWithEstimate E3 Training 37103/37103, done at 2024-02-08 10:10:33\n",
      "2024-02-08 10:10:33,666 INFO     pid:26301 __main__:013:logMetrics E3 StockPCTLabelPredictLSTMV2\n",
      "2024-02-08 10:10:33,696 INFO     pid:26301 __main__:074:logMetrics E3 trn      0.5599 loss\n",
      "2024-02-08 10:10:33,697 INFO     pid:26301 __main__:100:logMetrics E3 trn        72.2% correct, 0.6617 precision, 0.3391 recall, 0.4484 f1 score\n",
      "2024-02-08 10:10:33,697 INFO     pid:26301 __main__:116:logMetrics E3 trn_neg   0.3599 loss,  91.3% correct (722905 of 791528)\n",
      "2024-02-08 10:10:33,697 INFO     pid:26301 __main__:133:logMetrics E3 trn_pos   0.9600 loss,  33.9% correct (134221 of 395764)\n",
      "2024-02-08 10:10:33,776 INFO     pid:26301 MyPyUtil.util:146:enumerateWithEstimate E3 Validation  ----/7027, starting\n",
      "2024-02-08 10:10:33,793 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E3 Validation     4/7027, done at 2024-02-08 10:10:57, 0:00:23\n",
      "2024-02-08 10:10:33,831 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E3 Validation    16/7027, done at 2024-02-08 10:10:56, 0:00:22\n",
      "2024-02-08 10:10:33,979 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E3 Validation    64/7027, done at 2024-02-08 10:10:55, 0:00:21\n",
      "2024-02-08 10:10:34,538 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E3 Validation   256/7027, done at 2024-02-08 10:10:54, 0:00:20\n",
      "2024-02-08 10:10:36,785 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E3 Validation  1024/7027, done at 2024-02-08 10:10:54, 0:00:20\n",
      "2024-02-08 10:10:45,999 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E3 Validation  4096/7027, done at 2024-02-08 10:10:54, 0:00:20\n",
      "2024-02-08 10:10:55,115 INFO     pid:26301 MyPyUtil.util:181:enumerateWithEstimate E3 Validation  7027/7027, done at 2024-02-08 10:10:55\n",
      "2024-02-08 10:10:55,116 INFO     pid:26301 __main__:013:logMetrics E3 StockPCTLabelPredictLSTMV2\n",
      "2024-02-08 10:10:55,117 INFO     pid:26301 __main__:074:logMetrics E3 val      0.5978 loss\n",
      "2024-02-08 10:10:55,117 INFO     pid:26301 __main__:100:logMetrics E3 val        69.4% correct, 0.2307 precision, 0.4332 recall, 0.3011 f1 score\n",
      "2024-02-08 10:10:55,118 INFO     pid:26301 __main__:116:logMetrics E3 val_neg   0.5530 loss,  74.0% correct (141103 of 190583)\n",
      "2024-02-08 10:10:55,118 INFO     pid:26301 __main__:133:logMetrics E3 val_pos   0.8466 loss,  43.3% correct (14838 of 34255)\n",
      "2024-02-08 10:10:55,144 INFO     pid:26301 MyPyUtil.util:146:enumerateWithEstimate E4 Training ----/37103, starting\n",
      "2024-02-08 10:10:55,167 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E4 Training    4/37103, done at 2024-02-08 10:13:43, 0:02:48\n",
      "2024-02-08 10:10:55,266 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E4 Training   32/37103, done at 2024-02-08 10:13:12, 0:02:16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current loss: 0.5599337816238403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-08 10:10:56,053 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E4 Training  256/37103, done at 2024-02-08 10:13:06, 0:02:11\n",
      "2024-02-08 10:11:02,354 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E4 Training 2048/37103, done at 2024-02-08 10:13:05, 0:02:10\n",
      "2024-02-08 10:11:58,938 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E4 Training 16384/37103, done at 2024-02-08 10:13:19, 0:02:24\n",
      "2024-02-08 10:13:14,901 INFO     pid:26301 MyPyUtil.util:181:enumerateWithEstimate E4 Training 37103/37103, done at 2024-02-08 10:13:14\n",
      "2024-02-08 10:13:15,172 INFO     pid:26301 __main__:013:logMetrics E4 StockPCTLabelPredictLSTMV2\n",
      "2024-02-08 10:13:15,207 INFO     pid:26301 __main__:074:logMetrics E4 trn      0.5574 loss\n",
      "2024-02-08 10:13:15,207 INFO     pid:26301 __main__:100:logMetrics E4 trn        72.4% correct, 0.6668 precision, 0.3443 recall, 0.4541 f1 score\n",
      "2024-02-08 10:13:15,207 INFO     pid:26301 __main__:116:logMetrics E4 trn_neg   0.3581 loss,  91.4% correct (723419 of 791528)\n",
      "2024-02-08 10:13:15,208 INFO     pid:26301 __main__:133:logMetrics E4 trn_pos   0.9560 loss,  34.4% correct (136276 of 395764)\n",
      "2024-02-08 10:13:15,286 INFO     pid:26301 MyPyUtil.util:146:enumerateWithEstimate E4 Validation  ----/7027, starting\n",
      "2024-02-08 10:13:15,304 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E4 Validation     4/7027, done at 2024-02-08 10:13:39, 0:00:23\n",
      "2024-02-08 10:13:15,355 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E4 Validation    16/7027, done at 2024-02-08 10:13:43, 0:00:28\n",
      "2024-02-08 10:13:15,506 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E4 Validation    64/7027, done at 2024-02-08 10:13:39, 0:00:23\n",
      "2024-02-08 10:13:16,063 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E4 Validation   256/7027, done at 2024-02-08 10:13:36, 0:00:21\n",
      "2024-02-08 10:13:18,302 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E4 Validation  1024/7027, done at 2024-02-08 10:13:35, 0:00:20\n",
      "2024-02-08 10:13:27,452 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E4 Validation  4096/7027, done at 2024-02-08 10:13:36, 0:00:20\n",
      "2024-02-08 10:13:36,609 INFO     pid:26301 MyPyUtil.util:181:enumerateWithEstimate E4 Validation  7027/7027, done at 2024-02-08 10:13:36\n",
      "2024-02-08 10:13:36,610 INFO     pid:26301 __main__:013:logMetrics E4 StockPCTLabelPredictLSTMV2\n",
      "2024-02-08 10:13:36,611 INFO     pid:26301 __main__:074:logMetrics E4 val      0.5916 loss\n",
      "2024-02-08 10:13:36,612 INFO     pid:26301 __main__:100:logMetrics E4 val        69.8% correct, 0.2310 precision, 0.4226 recall, 0.2987 f1 score\n",
      "2024-02-08 10:13:36,612 INFO     pid:26301 __main__:116:logMetrics E4 val_neg   0.5441 loss,  74.7% correct (142387 of 190583)\n",
      "2024-02-08 10:13:36,612 INFO     pid:26301 __main__:133:logMetrics E4 val_pos   0.8558 loss,  42.3% correct (14476 of 34255)\n",
      "2024-02-08 10:13:36,630 INFO     pid:26301 MyPyUtil.util:146:enumerateWithEstimate E5 Training ----/37103, starting\n",
      "2024-02-08 10:13:36,652 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E5 Training    4/37103, done at 2024-02-08 10:16:19, 0:02:43\n",
      "2024-02-08 10:13:36,753 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E5 Training   32/37103, done at 2024-02-08 10:15:54, 0:02:18\n",
      "2024-02-08 10:13:37,526 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E5 Training  256/37103, done at 2024-02-08 10:15:45, 0:02:09\n",
      "2024-02-08 10:13:43,792 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E5 Training 2048/37103, done at 2024-02-08 10:15:46, 0:02:09\n",
      "2024-02-08 10:14:35,235 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E5 Training 16384/37103, done at 2024-02-08 10:15:49, 0:02:12\n",
      "2024-02-08 10:15:56,998 INFO     pid:26301 MyPyUtil.util:181:enumerateWithEstimate E5 Training 37103/37103, done at 2024-02-08 10:15:56\n",
      "2024-02-08 10:15:57,254 INFO     pid:26301 __main__:013:logMetrics E5 StockPCTLabelPredictLSTMV2\n",
      "2024-02-08 10:15:57,297 INFO     pid:26301 __main__:074:logMetrics E5 trn      0.5548 loss\n",
      "2024-02-08 10:15:57,298 INFO     pid:26301 __main__:100:logMetrics E5 trn        72.6% correct, 0.6716 precision, 0.3489 recall, 0.4592 f1 score\n",
      "2024-02-08 10:15:57,298 INFO     pid:26301 __main__:116:logMetrics E5 trn_neg   0.3562 loss,  91.5% correct (724016 of 791528)\n",
      "2024-02-08 10:15:57,298 INFO     pid:26301 __main__:133:logMetrics E5 trn_pos   0.9520 loss,  34.9% correct (138083 of 395764)\n",
      "2024-02-08 10:15:57,379 INFO     pid:26301 MyPyUtil.util:146:enumerateWithEstimate E5 Validation  ----/7027, starting\n",
      "2024-02-08 10:15:57,396 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E5 Validation     4/7027, done at 2024-02-08 10:16:20, 0:00:23\n",
      "2024-02-08 10:15:57,434 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E5 Validation    16/7027, done at 2024-02-08 10:16:20, 0:00:22\n",
      "2024-02-08 10:15:57,573 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E5 Validation    64/7027, done at 2024-02-08 10:16:18, 0:00:20\n",
      "2024-02-08 10:15:58,097 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E5 Validation   256/7027, done at 2024-02-08 10:16:16, 0:00:19\n",
      "2024-02-08 10:16:00,210 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E5 Validation  1024/7027, done at 2024-02-08 10:16:16, 0:00:19\n",
      "2024-02-08 10:16:08,853 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E5 Validation  4096/7027, done at 2024-02-08 10:16:17, 0:00:19\n",
      "2024-02-08 10:16:17,472 INFO     pid:26301 MyPyUtil.util:181:enumerateWithEstimate E5 Validation  7027/7027, done at 2024-02-08 10:16:17\n",
      "2024-02-08 10:16:17,473 INFO     pid:26301 __main__:013:logMetrics E5 StockPCTLabelPredictLSTMV2\n",
      "2024-02-08 10:16:17,474 INFO     pid:26301 __main__:074:logMetrics E5 val      0.5895 loss\n",
      "2024-02-08 10:16:17,475 INFO     pid:26301 __main__:100:logMetrics E5 val        70.0% correct, 0.2320 precision, 0.4198 recall, 0.2989 f1 score\n",
      "2024-02-08 10:16:17,475 INFO     pid:26301 __main__:116:logMetrics E5 val_neg   0.5412 loss,  75.0% correct (142986 of 190583)\n",
      "2024-02-08 10:16:17,475 INFO     pid:26301 __main__:133:logMetrics E5 val_pos   0.8583 loss,  42.0% correct (14380 of 34255)\n",
      "2024-02-08 10:16:17,493 INFO     pid:26301 MyPyUtil.util:146:enumerateWithEstimate E6 Training ----/37103, starting\n",
      "2024-02-08 10:16:17,513 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E6 Training    4/37103, done at 2024-02-08 10:18:44, 0:02:26\n",
      "2024-02-08 10:16:17,608 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E6 Training   32/37103, done at 2024-02-08 10:18:26, 0:02:08\n",
      "2024-02-08 10:16:18,361 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E6 Training  256/37103, done at 2024-02-08 10:18:22, 0:02:05\n",
      "2024-02-08 10:16:24,282 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E6 Training 2048/37103, done at 2024-02-08 10:18:20, 0:02:02\n",
      "2024-02-08 10:17:12,663 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E6 Training 16384/37103, done at 2024-02-08 10:18:22, 0:02:04\n",
      "2024-02-08 10:18:33,128 INFO     pid:26301 MyPyUtil.util:181:enumerateWithEstimate E6 Training 37103/37103, done at 2024-02-08 10:18:33\n",
      "2024-02-08 10:18:33,382 INFO     pid:26301 __main__:013:logMetrics E6 StockPCTLabelPredictLSTMV2\n",
      "2024-02-08 10:18:33,422 INFO     pid:26301 __main__:074:logMetrics E6 trn      0.5523 loss\n",
      "2024-02-08 10:18:33,423 INFO     pid:26301 __main__:100:logMetrics E6 trn        72.8% correct, 0.6760 precision, 0.3539 recall, 0.4646 f1 score\n",
      "2024-02-08 10:18:33,423 INFO     pid:26301 __main__:116:logMetrics E6 trn_neg   0.3544 loss,  91.5% correct (724387 of 791528)\n",
      "2024-02-08 10:18:33,423 INFO     pid:26301 __main__:133:logMetrics E6 trn_pos   0.9481 loss,  35.4% correct (140079 of 395764)\n",
      "2024-02-08 10:18:33,498 INFO     pid:26301 MyPyUtil.util:146:enumerateWithEstimate E6 Validation  ----/7027, starting\n",
      "2024-02-08 10:18:33,515 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E6 Validation     4/7027, done at 2024-02-08 10:18:56, 0:00:22\n",
      "2024-02-08 10:18:33,552 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E6 Validation    16/7027, done at 2024-02-08 10:18:55, 0:00:22\n",
      "2024-02-08 10:18:33,694 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E6 Validation    64/7027, done at 2024-02-08 10:18:54, 0:00:21\n",
      "2024-02-08 10:18:34,224 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E6 Validation   256/7027, done at 2024-02-08 10:18:53, 0:00:19\n",
      "2024-02-08 10:18:36,374 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E6 Validation  1024/7027, done at 2024-02-08 10:18:53, 0:00:19\n",
      "2024-02-08 10:18:45,087 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E6 Validation  4096/7027, done at 2024-02-08 10:18:53, 0:00:19\n",
      "2024-02-08 10:18:53,787 INFO     pid:26301 MyPyUtil.util:181:enumerateWithEstimate E6 Validation  7027/7027, done at 2024-02-08 10:18:53\n",
      "2024-02-08 10:18:53,788 INFO     pid:26301 __main__:013:logMetrics E6 StockPCTLabelPredictLSTMV2\n",
      "2024-02-08 10:18:53,789 INFO     pid:26301 __main__:074:logMetrics E6 val      0.5899 loss\n",
      "2024-02-08 10:18:53,790 INFO     pid:26301 __main__:100:logMetrics E6 val        70.0% correct, 0.2313 precision, 0.4182 recall, 0.2979 f1 score\n",
      "2024-02-08 10:18:53,790 INFO     pid:26301 __main__:116:logMetrics E6 val_neg   0.5416 loss,  75.0% correct (142974 of 190583)\n",
      "2024-02-08 10:18:53,790 INFO     pid:26301 __main__:133:logMetrics E6 val_pos   0.8585 loss,  41.8% correct (14325 of 34255)\n",
      "2024-02-08 10:18:53,816 INFO     pid:26301 MyPyUtil.util:146:enumerateWithEstimate E7 Training ----/37103, starting\n",
      "2024-02-08 10:18:53,840 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E7 Training    4/37103, done at 2024-02-08 10:21:46, 0:02:52\n",
      "2024-02-08 10:18:53,954 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E7 Training   32/37103, done at 2024-02-08 10:21:28, 0:02:34\n",
      "2024-02-08 10:18:54,713 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E7 Training  256/37103, done at 2024-02-08 10:21:03, 0:02:09\n",
      "2024-02-08 10:19:00,678 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E7 Training 2048/37103, done at 2024-02-08 10:20:58, 0:02:04\n",
      "2024-02-08 10:19:52,115 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E7 Training 16384/37103, done at 2024-02-08 10:21:05, 0:02:12\n",
      "2024-02-08 10:21:07,829 INFO     pid:26301 MyPyUtil.util:181:enumerateWithEstimate E7 Training 37103/37103, done at 2024-02-08 10:21:07\n",
      "2024-02-08 10:21:08,092 INFO     pid:26301 __main__:013:logMetrics E7 StockPCTLabelPredictLSTMV2\n",
      "2024-02-08 10:21:08,138 INFO     pid:26301 __main__:074:logMetrics E7 trn      0.5498 loss\n",
      "2024-02-08 10:21:08,139 INFO     pid:26301 __main__:100:logMetrics E7 trn        73.0% correct, 0.6798 precision, 0.3591 recall, 0.4700 f1 score\n",
      "2024-02-08 10:21:08,139 INFO     pid:26301 __main__:116:logMetrics E7 trn_neg   0.3527 loss,  91.5% correct (724592 of 791528)\n",
      "2024-02-08 10:21:08,139 INFO     pid:26301 __main__:133:logMetrics E7 trn_pos   0.9441 loss,  35.9% correct (142134 of 395764)\n",
      "2024-02-08 10:21:08,224 INFO     pid:26301 MyPyUtil.util:146:enumerateWithEstimate E7 Validation  ----/7027, starting\n",
      "2024-02-08 10:21:08,243 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E7 Validation     4/7027, done at 2024-02-08 10:21:33, 0:00:25\n",
      "2024-02-08 10:21:08,281 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E7 Validation    16/7027, done at 2024-02-08 10:21:31, 0:00:23\n",
      "2024-02-08 10:21:08,422 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E7 Validation    64/7027, done at 2024-02-08 10:21:29, 0:00:21\n",
      "2024-02-08 10:21:08,978 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E7 Validation   256/7027, done at 2024-02-08 10:21:28, 0:00:20\n",
      "2024-02-08 10:21:11,137 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E7 Validation  1024/7027, done at 2024-02-08 10:21:28, 0:00:19\n",
      "2024-02-08 10:21:20,277 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E7 Validation  4096/7027, done at 2024-02-08 10:21:28, 0:00:20\n",
      "2024-02-08 10:21:29,177 INFO     pid:26301 MyPyUtil.util:181:enumerateWithEstimate E7 Validation  7027/7027, done at 2024-02-08 10:21:29\n",
      "2024-02-08 10:21:29,178 INFO     pid:26301 __main__:013:logMetrics E7 StockPCTLabelPredictLSTMV2\n",
      "2024-02-08 10:21:29,179 INFO     pid:26301 __main__:074:logMetrics E7 val      0.5894 loss\n",
      "2024-02-08 10:21:29,180 INFO     pid:26301 __main__:100:logMetrics E7 val        70.1% correct, 0.2312 precision, 0.4152 recall, 0.2970 f1 score\n",
      "2024-02-08 10:21:29,180 INFO     pid:26301 __main__:116:logMetrics E7 val_neg   0.5406 loss,  75.2% correct (143290 of 190583)\n",
      "2024-02-08 10:21:29,180 INFO     pid:26301 __main__:133:logMetrics E7 val_pos   0.8606 loss,  41.5% correct (14224 of 34255)\n",
      "2024-02-08 10:21:29,197 INFO     pid:26301 MyPyUtil.util:146:enumerateWithEstimate E8 Training ----/37103, starting\n",
      "2024-02-08 10:21:29,218 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E8 Training    4/37103, done at 2024-02-08 10:24:04, 0:02:35\n",
      "2024-02-08 10:21:29,316 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E8 Training   32/37103, done at 2024-02-08 10:23:41, 0:02:12\n",
      "2024-02-08 10:21:30,066 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E8 Training  256/37103, done at 2024-02-08 10:23:34, 0:02:05\n",
      "2024-02-08 10:21:36,196 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E8 Training 2048/37103, done at 2024-02-08 10:23:35, 0:02:06\n",
      "2024-02-08 10:22:27,594 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E8 Training 16384/37103, done at 2024-02-08 10:23:41, 0:02:12\n",
      "2024-02-08 10:23:53,154 INFO     pid:26301 MyPyUtil.util:181:enumerateWithEstimate E8 Training 37103/37103, done at 2024-02-08 10:23:53\n",
      "2024-02-08 10:23:53,419 INFO     pid:26301 __main__:013:logMetrics E8 StockPCTLabelPredictLSTMV2\n",
      "2024-02-08 10:23:53,458 INFO     pid:26301 __main__:074:logMetrics E8 trn      0.5473 loss\n",
      "2024-02-08 10:23:53,458 INFO     pid:26301 __main__:100:logMetrics E8 trn        73.2% correct, 0.6831 precision, 0.3645 recall, 0.4753 f1 score\n",
      "2024-02-08 10:23:53,458 INFO     pid:26301 __main__:116:logMetrics E8 trn_neg   0.3510 loss,  91.5% correct (724605 of 791528)\n",
      "2024-02-08 10:23:53,459 INFO     pid:26301 __main__:133:logMetrics E8 trn_pos   0.9399 loss,  36.4% correct (144238 of 395764)\n",
      "2024-02-08 10:23:53,532 INFO     pid:26301 MyPyUtil.util:146:enumerateWithEstimate E8 Validation  ----/7027, starting\n",
      "2024-02-08 10:23:53,550 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E8 Validation     4/7027, done at 2024-02-08 10:24:17, 0:00:24\n",
      "2024-02-08 10:23:53,588 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E8 Validation    16/7027, done at 2024-02-08 10:24:16, 0:00:22\n",
      "2024-02-08 10:23:53,733 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E8 Validation    64/7027, done at 2024-02-08 10:24:15, 0:00:21\n",
      "2024-02-08 10:23:54,292 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E8 Validation   256/7027, done at 2024-02-08 10:24:14, 0:00:20\n",
      "2024-02-08 10:23:56,572 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E8 Validation  1024/7027, done at 2024-02-08 10:24:14, 0:00:20\n",
      "2024-02-08 10:24:05,781 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E8 Validation  4096/7027, done at 2024-02-08 10:24:14, 0:00:21\n",
      "2024-02-08 10:24:14,585 INFO     pid:26301 MyPyUtil.util:181:enumerateWithEstimate E8 Validation  7027/7027, done at 2024-02-08 10:24:14\n",
      "2024-02-08 10:24:14,585 INFO     pid:26301 __main__:013:logMetrics E8 StockPCTLabelPredictLSTMV2\n",
      "2024-02-08 10:24:14,587 INFO     pid:26301 __main__:074:logMetrics E8 val      0.5884 loss\n",
      "2024-02-08 10:24:14,588 INFO     pid:26301 __main__:100:logMetrics E8 val        70.2% correct, 0.2301 precision, 0.4086 recall, 0.2944 f1 score\n",
      "2024-02-08 10:24:14,588 INFO     pid:26301 __main__:116:logMetrics E8 val_neg   0.5386 loss,  75.4% correct (143749 of 190583)\n",
      "2024-02-08 10:24:14,588 INFO     pid:26301 __main__:133:logMetrics E8 val_pos   0.8653 loss,  40.9% correct (13998 of 34255)\n",
      "2024-02-08 10:24:14,615 INFO     pid:26301 MyPyUtil.util:146:enumerateWithEstimate E9 Training ----/37103, starting\n",
      "2024-02-08 10:24:14,647 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E9 Training    4/37103, done at 2024-02-08 10:28:12, 0:03:58\n",
      "2024-02-08 10:24:14,744 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E9 Training   32/37103, done at 2024-02-08 10:26:39, 0:02:24\n",
      "2024-02-08 10:24:15,527 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E9 Training  256/37103, done at 2024-02-08 10:26:26, 0:02:11\n",
      "2024-02-08 10:24:21,790 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E9 Training 2048/37103, done at 2024-02-08 10:26:24, 0:02:09\n",
      "2024-02-08 10:25:12,627 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E9 Training 16384/37103, done at 2024-02-08 10:26:25, 0:02:11\n",
      "2024-02-08 10:26:28,623 INFO     pid:26301 MyPyUtil.util:181:enumerateWithEstimate E9 Training 37103/37103, done at 2024-02-08 10:26:28\n",
      "2024-02-08 10:26:28,888 INFO     pid:26301 __main__:013:logMetrics E9 StockPCTLabelPredictLSTMV2\n",
      "2024-02-08 10:26:28,951 INFO     pid:26301 __main__:074:logMetrics E9 trn      0.5447 loss\n",
      "2024-02-08 10:26:28,952 INFO     pid:26301 __main__:100:logMetrics E9 trn        73.4% correct, 0.6861 precision, 0.3703 recall, 0.4810 f1 score\n",
      "2024-02-08 10:26:28,952 INFO     pid:26301 __main__:116:logMetrics E9 trn_neg   0.3492 loss,  91.5% correct (724484 of 791528)\n",
      "2024-02-08 10:26:28,953 INFO     pid:26301 __main__:133:logMetrics E9 trn_pos   0.9355 loss,  37.0% correct (146546 of 395764)\n",
      "2024-02-08 10:26:29,045 INFO     pid:26301 MyPyUtil.util:146:enumerateWithEstimate E9 Validation  ----/7027, starting\n",
      "2024-02-08 10:26:29,064 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E9 Validation     4/7027, done at 2024-02-08 10:26:55, 0:00:26\n",
      "2024-02-08 10:26:29,102 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E9 Validation    16/7027, done at 2024-02-08 10:26:52, 0:00:23\n",
      "2024-02-08 10:26:29,250 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E9 Validation    64/7027, done at 2024-02-08 10:26:51, 0:00:22\n",
      "2024-02-08 10:26:29,813 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E9 Validation   256/7027, done at 2024-02-08 10:26:50, 0:00:20\n",
      "2024-02-08 10:26:32,057 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E9 Validation  1024/7027, done at 2024-02-08 10:26:49, 0:00:20\n",
      "2024-02-08 10:26:41,073 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E9 Validation  4096/7027, done at 2024-02-08 10:26:49, 0:00:20\n",
      "2024-02-08 10:26:50,004 INFO     pid:26301 MyPyUtil.util:181:enumerateWithEstimate E9 Validation  7027/7027, done at 2024-02-08 10:26:50\n",
      "2024-02-08 10:26:50,004 INFO     pid:26301 __main__:013:logMetrics E9 StockPCTLabelPredictLSTMV2\n",
      "2024-02-08 10:26:50,006 INFO     pid:26301 __main__:074:logMetrics E9 val      0.5886 loss\n",
      "2024-02-08 10:26:50,007 INFO     pid:26301 __main__:100:logMetrics E9 val        70.2% correct, 0.2287 precision, 0.4035 recall, 0.2919 f1 score\n",
      "2024-02-08 10:26:50,007 INFO     pid:26301 __main__:116:logMetrics E9 val_neg   0.5383 loss,  75.5% correct (143962 of 190583)\n",
      "2024-02-08 10:26:50,007 INFO     pid:26301 __main__:133:logMetrics E9 val_pos   0.8688 loss,  40.4% correct (13822 of 34255)\n",
      "2024-02-08 10:26:50,033 INFO     pid:26301 MyPyUtil.util:146:enumerateWithEstimate E10 Training ----/37103, starting\n",
      "2024-02-08 10:26:50,057 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E10 Training    4/37103, done at 2024-02-08 10:29:43, 0:02:53\n",
      "2024-02-08 10:26:50,157 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E10 Training   32/37103, done at 2024-02-08 10:29:09, 0:02:19\n",
      "2024-02-08 10:26:50,953 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E10 Training  256/37103, done at 2024-02-08 10:29:02, 0:02:12\n",
      "2024-02-08 10:26:57,369 INFO     pid:26301 MyPyUtil.util:166:enumerateWithEstimate E10 Training 2048/37103, done at 2024-02-08 10:29:02, 0:02:12\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "time_str = datetime.now().strftime(\"%Y-%m-%d_%H.%M.%S\")\n",
    "log_dir = f\"{log_dir_base}/{time_str}\"\n",
    "config = {\n",
    "    \"return_period\": return_period,\n",
    "    \"seq_len\": seq_len,\n",
    "    \"lr\": 0.1,\n",
    "    \"momentum\": 0.11646759543664197,\n",
    "    \"optim_type\": 2,  # 1: Adam, 2: SGD  => Adam bad result\n",
    "    \"weight decay\": 0.00001,\n",
    "    \"num_layers\": 4,\n",
    "    \"hidden_size\": 256,\n",
    "    \"num_fc_layers\": 1,\n",
    "    \"activation_type\": 2,  # Sigmoid\n",
    "}\n",
    "epoch_num = 100\n",
    "# os.mkdir(log_dir)\n",
    "print(log_dir)\n",
    "start = datetime.now()\n",
    "torch.seed = 42\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "train_LSTM(config)\n",
    "print(f\"Elapsed time:{datetime.now() - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ray_train_task(config, data):\n",
    "    global totalTrainingSamples_count\n",
    "    global log_dir\n",
    "\n",
    "    best_f1 = 0\n",
    "\n",
    "    lr = config[\"lr\"]\n",
    "    momentum = config[\"momentum\"]\n",
    "    optim_type = config[\"optim_type\"]\n",
    "    totalTrainingSamples_count = 0\n",
    "\n",
    "    id_str = \"_\".join(str(v) if v < 1 else f\"{v:g}\" for v in config.values())\n",
    "    # print(id_str)\n",
    "    log_dir = f\"{log_dir_base}/{time_str}/{id_str}\"\n",
    "    os.mkdir(log_dir)\n",
    "\n",
    "    model_name = f\"{log_dir}/{id_str}.pt\"\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        data[0],\n",
    "        batch_size,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory,\n",
    "        pin_memory_device=device_name,\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        data[1],\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory,\n",
    "        pin_memory_device=device_name,\n",
    "    )\n",
    "\n",
    "    features_size = data[0].ticks_data_X[0].shape[1]\n",
    "\n",
    "    model = StockPCTLabelPredictLSTM(input_size=features_size, config=config)\n",
    "    model = model.to(device)\n",
    "\n",
    "    optimizer = (\n",
    "        torch.optim.Adam(model.parameters(), lr=lr)\n",
    "        if optim_type == 1\n",
    "        else torch.optim.SGD(\n",
    "            model.parameters(),\n",
    "            lr=lr,\n",
    "            momentum=momentum,\n",
    "            weight_decay=config[\"weight decay\"],\n",
    "        )\n",
    "    )\n",
    "    loss_fn = torch.nn.CrossEntropyLoss(reduction=\"none\")\n",
    "\n",
    "    for epoch_ndx in range(epoch_num):\n",
    "        trnMetrics_t = doTraining(model, optimizer, loss_fn, epoch_ndx, train_loader)\n",
    "        loss, _ = logMetrics(\n",
    "            epoch_ndx,\n",
    "            \"trn\",\n",
    "            trnMetrics_t,\n",
    "            classificationThreshold,\n",
    "            config,\n",
    "            (epoch_ndx == epoch_num - 1),\n",
    "        )\n",
    "\n",
    "        valMetrics_t = doValidation(model, loss_fn, epoch_ndx, test_loader)\n",
    "        _, F1_metrics = logMetrics(\n",
    "            epoch_ndx,\n",
    "            \"val\",\n",
    "            valMetrics_t,\n",
    "            classificationThreshold,\n",
    "            config,\n",
    "            (epoch_ndx == epoch_num - 1),\n",
    "        )\n",
    "        if F1_metrics[0].F1 > best_f1:\n",
    "            best_f1 = F1_metrics[0].F1\n",
    "            save_model(model, config, model_name)\n",
    "\n",
    "        train.report(\n",
    "            {\n",
    "                \"loss\": loss,\n",
    "                \"f1_score\": F1_metrics[0].F1,\n",
    "                \"precision\": F1_metrics[0].precision,\n",
    "                \"recall\": F1_metrics[0].recall,\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lr', 'hidden_size', 'num_fc_layers']\n",
      "Total count of configs = 8\n"
     ]
    }
   ],
   "source": [
    "search_space = {\n",
    "    # \"return_period\": tune.grid_search([5]),  # [2,3,5,10]\n",
    "    # \"seq_len\": tune.grid_search([3]),  # 10]),\n",
    "    \"lr\": tune.grid_search([0.01, 0.1]),  # , 0.01, 0.1, 0.08, 0.12]\n",
    "    \"momentum\": tune.grid_search([0.14647]),  # tune.uniform(0.1, 0.9),\n",
    "    \"optim_type\": tune.grid_search([2]),  # 1: Adam, 2: SGD  => Adam bad result\n",
    "    \"weight decay\": tune.grid_search([0.00001]),  # best value\n",
    "    \"num_layers\": tune.grid_search([4]),  # [1, 2, 4, 8] best value = 3 or 4\n",
    "    \"hidden_size\": tune.grid_search([256, 128]),  # [8, 16, 32, 64, 128]\n",
    "    \"num_fc_layers\": tune.grid_search([2, 1]),  # 1, 2, 3]),\n",
    "    \"activation_type\": tune.grid_search(\n",
    "        [2]\n",
    "    ),  # 1: ReLU(),  2: Sigmoid(),  3: Tanh()  => meaningless num_fc_layers == 1\n",
    "}\n",
    "\n",
    "turning_parameters = []\n",
    "total_configs = 1\n",
    "for k, v in search_space.items():\n",
    "    if (\n",
    "        type(v).__name__ == \"dict\"\n",
    "        and list(v.keys())[0] == \"grid_search\"\n",
    "        and len(list(v.values())[0]) > 1\n",
    "    ):\n",
    "        turning_parameters.append(k)\n",
    "        total_configs *= len(list(v.values())[0])\n",
    "print(turning_parameters)\n",
    "print(f\"Total count of configs = {total_configs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-02-07 21:40:04</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:10.27        </td></tr>\n",
       "<tr><td>Memory:      </td><td>11.6/31.1 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 0.33/32 CPUs, 0.33/1 GPUs (0.0/1.0 accelerator_type:G)\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "<div class=\"messages\">\n",
       "  <h3>Messages</h3>\n",
       "  \n",
       "  \n",
       "  Number of errored trials: 8<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                                                                                                                                  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>ray_train_task_7c902_00000</td><td style=\"text-align: right;\">           1</td><td>/home/skchen/ray_results/ray_train_task_2024-02-07_21-39-54/ray_train_task_7c902_00000_0_activation_type=2,hidden_size=256,lr=0.0100,momentum=0.1465,num_fc_layers=2,num_layers=4,optim_type=2_2024-02-07_21-39-54/error.txt</td></tr>\n",
       "<tr><td>ray_train_task_7c902_00001</td><td style=\"text-align: right;\">           1</td><td>/home/skchen/ray_results/ray_train_task_2024-02-07_21-39-54/ray_train_task_7c902_00001_1_activation_type=2,hidden_size=128,lr=0.0100,momentum=0.1465,num_fc_layers=2,num_layers=4,optim_type=2_2024-02-07_21-39-54/error.txt</td></tr>\n",
       "<tr><td>ray_train_task_7c902_00002</td><td style=\"text-align: right;\">           1</td><td>/home/skchen/ray_results/ray_train_task_2024-02-07_21-39-54/ray_train_task_7c902_00002_2_activation_type=2,hidden_size=256,lr=0.1000,momentum=0.1465,num_fc_layers=2,num_layers=4,optim_type=2_2024-02-07_21-39-54/error.txt</td></tr>\n",
       "<tr><td>ray_train_task_7c902_00003</td><td style=\"text-align: right;\">           1</td><td>/home/skchen/ray_results/ray_train_task_2024-02-07_21-39-54/ray_train_task_7c902_00003_3_activation_type=2,hidden_size=128,lr=0.1000,momentum=0.1465,num_fc_layers=2,num_layers=4,optim_type=2_2024-02-07_21-39-54/error.txt</td></tr>\n",
       "<tr><td>ray_train_task_7c902_00004</td><td style=\"text-align: right;\">           1</td><td>/home/skchen/ray_results/ray_train_task_2024-02-07_21-39-54/ray_train_task_7c902_00004_4_activation_type=2,hidden_size=256,lr=0.0100,momentum=0.1465,num_fc_layers=1,num_layers=4,optim_type=2_2024-02-07_21-39-54/error.txt</td></tr>\n",
       "<tr><td>ray_train_task_7c902_00005</td><td style=\"text-align: right;\">           1</td><td>/home/skchen/ray_results/ray_train_task_2024-02-07_21-39-54/ray_train_task_7c902_00005_5_activation_type=2,hidden_size=128,lr=0.0100,momentum=0.1465,num_fc_layers=1,num_layers=4,optim_type=2_2024-02-07_21-39-54/error.txt</td></tr>\n",
       "<tr><td>ray_train_task_7c902_00006</td><td style=\"text-align: right;\">           1</td><td>/home/skchen/ray_results/ray_train_task_2024-02-07_21-39-54/ray_train_task_7c902_00006_6_activation_type=2,hidden_size=256,lr=0.1000,momentum=0.1465,num_fc_layers=1,num_layers=4,optim_type=2_2024-02-07_21-39-54/error.txt</td></tr>\n",
       "<tr><td>ray_train_task_7c902_00007</td><td style=\"text-align: right;\">           1</td><td>/home/skchen/ray_results/ray_train_task_2024-02-07_21-39-54/ray_train_task_7c902_00007_7_activation_type=2,hidden_size=128,lr=0.1000,momentum=0.1465,num_fc_layers=1,num_layers=4,optim_type=2_2024-02-07_21-39-54/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".messages {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  padding-left: 1em;\n",
       "  overflow-y: auto;\n",
       "}\n",
       ".messages h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n",
       "\n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  activation_type</th><th style=\"text-align: right;\">  hidden_size</th><th style=\"text-align: right;\">  lr</th><th style=\"text-align: right;\">  momentum</th><th style=\"text-align: right;\">  num_fc_layers</th><th style=\"text-align: right;\">  num_layers</th><th style=\"text-align: right;\">  optim_type</th><th style=\"text-align: right;\">  weight decay</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>ray_train_task_7c902_00000</td><td>ERROR   </td><td>192.168.0.125:23541</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">0.01</td><td style=\"text-align: right;\">   0.14647</td><td style=\"text-align: right;\">              2</td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">         1e-05</td></tr>\n",
       "<tr><td>ray_train_task_7c902_00001</td><td>ERROR   </td><td>192.168.0.125:23542</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">0.01</td><td style=\"text-align: right;\">   0.14647</td><td style=\"text-align: right;\">              2</td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">         1e-05</td></tr>\n",
       "<tr><td>ray_train_task_7c902_00002</td><td>ERROR   </td><td>192.168.0.125:23543</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">0.1 </td><td style=\"text-align: right;\">   0.14647</td><td style=\"text-align: right;\">              2</td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">         1e-05</td></tr>\n",
       "<tr><td>ray_train_task_7c902_00003</td><td>ERROR   </td><td>192.168.0.125:24161</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">0.1 </td><td style=\"text-align: right;\">   0.14647</td><td style=\"text-align: right;\">              2</td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">         1e-05</td></tr>\n",
       "<tr><td>ray_train_task_7c902_00004</td><td>ERROR   </td><td>192.168.0.125:24162</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">0.01</td><td style=\"text-align: right;\">   0.14647</td><td style=\"text-align: right;\">              1</td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">         1e-05</td></tr>\n",
       "<tr><td>ray_train_task_7c902_00005</td><td>ERROR   </td><td>192.168.0.125:24163</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">0.01</td><td style=\"text-align: right;\">   0.14647</td><td style=\"text-align: right;\">              1</td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">         1e-05</td></tr>\n",
       "<tr><td>ray_train_task_7c902_00006</td><td>ERROR   </td><td>192.168.0.125:24775</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">0.1 </td><td style=\"text-align: right;\">   0.14647</td><td style=\"text-align: right;\">              1</td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">         1e-05</td></tr>\n",
       "<tr><td>ray_train_task_7c902_00007</td><td>ERROR   </td><td>192.168.0.125:24776</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">0.1 </td><td style=\"text-align: right;\">   0.14647</td><td style=\"text-align: right;\">              1</td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">         1e-05</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-07 21:39:57,505\tERROR tune_controller.py:1374 -- Trial task failed for trial ray_train_task_7c902_00000\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/skchen/venv/ml4t/lib/python3.8/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/skchen/venv/ml4t/lib/python3.8/site-packages/ray/_private/auto_init_hook.py\", line 22, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/skchen/venv/ml4t/lib/python3.8/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/skchen/venv/ml4t/lib/python3.8/site-packages/ray/_private/worker.py\", line 2624, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=23541, ip=192.168.0.125, actor_id=61078f874fa2d3d927b45e8301000000, repr=ray_train_task)\n",
      "  File \"/home/skchen/venv/ml4t/lib/python3.8/site-packages/ray/tune/trainable/trainable.py\", line 342, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/skchen/venv/ml4t/lib/python3.8/site-packages/ray/air/_internal/util.py\", line 88, in run\n",
      "    self._ret = self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/skchen/venv/ml4t/lib/python3.8/site-packages/ray/tune/trainable/function_trainable.py\", line 115, in <lambda>\n",
      "    training_func=lambda: self._trainable_func(self.config),\n",
      "  File \"/home/skchen/venv/ml4t/lib/python3.8/site-packages/ray/tune/trainable/function_trainable.py\", line 332, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/home/skchen/venv/ml4t/lib/python3.8/site-packages/ray/tune/trainable/util.py\", line 138, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "  File \"/tmp/ipykernel_21072/1012640050.py\", line 53, in ray_train_task\n",
      "  File \"/tmp/ipykernel_21072/1727838043.py\", line 33, in doTraining\n",
      "AttributeError: 'float' object has no attribute 'backward'\n",
      "2024-02-07 21:39:57,508\tERROR tune_controller.py:1374 -- Trial task failed for trial ray_train_task_7c902_00001\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/skchen/venv/ml4t/lib/python3.8/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/skchen/venv/ml4t/lib/python3.8/site-packages/ray/_private/auto_init_hook.py\", line 22, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/skchen/venv/ml4t/lib/python3.8/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/skchen/venv/ml4t/lib/python3.8/site-packages/ray/_private/worker.py\", line 2624, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=23542, ip=192.168.0.125, actor_id=002d159724c0efa0383290c801000000, repr=ray_train_task)\n",
      "  File \"/home/skchen/venv/ml4t/lib/python3.8/site-packages/ray/tune/trainable/trainable.py\", line 342, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/skchen/venv/ml4t/lib/python3.8/site-packages/ray/air/_internal/util.py\", line 88, in run\n",
      "    self._ret = self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/skchen/venv/ml4t/lib/python3.8/site-packages/ray/tune/trainable/function_trainable.py\", line 115, in <lambda>\n",
      "    training_func=lambda: self._trainable_func(self.config),\n",
      "  File \"/home/skchen/venv/ml4t/lib/python3.8/site-packages/ray/tune/trainable/function_trainable.py\", line 332, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/home/skchen/venv/ml4t/lib/python3.8/site-packages/ray/tune/trainable/util.py\", line 138, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "  File \"/tmp/ipykernel_21072/1012640050.py\", line 53, in ray_train_task\n",
      "  File \"/tmp/ipykernel_21072/1727838043.py\", line 33, in doTraining\n",
      "AttributeError: 'float' object has no attribute 'backward'\n",
      "2024-02-07 21:39:57,598\tERROR tune_controller.py:1374 -- Trial task failed for trial ray_train_task_7c902_00002\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/skchen/venv/ml4t/lib/python3.8/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/skchen/venv/ml4t/lib/python3.8/site-packages/ray/_private/auto_init_hook.py\", line 22, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/skchen/venv/ml4t/lib/python3.8/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/skchen/venv/ml4t/lib/python3.8/site-packages/ray/_private/worker.py\", line 2624, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=23543, ip=192.168.0.125, actor_id=5a7a3689463cfdd4ef742dfa01000000, repr=ray_train_task)\n",
      "  File \"/home/skchen/venv/ml4t/lib/python3.8/site-packages/ray/tune/trainable/trainable.py\", line 342, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/skchen/venv/ml4t/lib/python3.8/site-packages/ray/air/_internal/util.py\", line 88, in run\n",
      "    self._ret = self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/skchen/venv/ml4t/lib/python3.8/site-packages/ray/tune/trainable/function_trainable.py\", line 115, in <lambda>\n",
      "    training_func=lambda: self._trainable_func(self.config),\n",
      "  File \"/home/skchen/venv/ml4t/lib/python3.8/site-packages/ray/tune/trainable/function_trainable.py\", line 332, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/home/skchen/venv/ml4t/lib/python3.8/site-packages/ray/tune/trainable/util.py\", line 138, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "  File \"/tmp/ipykernel_21072/1012640050.py\", line 53, in ray_train_task\n",
      "  File \"/tmp/ipykernel_21072/1727838043.py\", line 33, in doTraining\n",
      "AttributeError: 'float' object has no attribute 'backward'\n",
      "2024-02-07 21:40:01,178\tERROR tune_controller.py:1374 -- Trial task failed for trial ray_train_task_7c902_00004\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/skchen/venv/ml4t/lib/python3.8/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/skchen/venv/ml4t/lib/python3.8/site-packages/ray/_private/auto_init_hook.py\", line 22, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/skchen/venv/ml4t/lib/python3.8/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/skchen/venv/ml4t/lib/python3.8/site-packages/ray/_private/worker.py\", line 2624, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=24162, ip=192.168.0.125, actor_id=41ae759dd4626b2cf3ee12ad01000000, repr=ray_train_task)\n",
      "  File \"/home/skchen/venv/ml4t/lib/python3.8/site-packages/ray/tune/trainable/trainable.py\", line 342, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/skchen/venv/ml4t/lib/python3.8/site-packages/ray/air/_internal/util.py\", line 88, in run\n",
      "    self._ret = self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/skchen/venv/ml4t/lib/python3.8/site-packages/ray/tune/trainable/function_trainable.py\", line 115, in <lambda>\n",
      "    training_func=lambda: self._trainable_func(self.config),\n",
      "  File \"/home/skchen/venv/ml4t/lib/python3.8/site-packages/ray/tune/trainable/function_trainable.py\", line 332, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/home/skchen/venv/ml4t/lib/python3.8/site-packages/ray/tune/trainable/util.py\", line 138, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "  File \"/tmp/ipykernel_21072/1012640050.py\", line 53, in ray_train_task\n",
      "  File \"/tmp/ipykernel_21072/1727838043.py\", line 33, in doTraining\n",
      "AttributeError: 'float' object has no attribute 'backward'\n",
      "2024-02-07 21:40:01,246\tERROR tune_controller.py:1374 -- Trial task failed for trial ray_train_task_7c902_00005\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/skchen/venv/ml4t/lib/python3.8/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/skchen/venv/ml4t/lib/python3.8/site-packages/ray/_private/auto_init_hook.py\", line 22, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/skchen/venv/ml4t/lib/python3.8/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/skchen/venv/ml4t/lib/python3.8/site-packages/ray/_private/worker.py\", line 2624, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=24163, ip=192.168.0.125, actor_id=5f395a677987cb88b65c31c701000000, repr=ray_train_task)\n",
      "  File \"/home/skchen/venv/ml4t/lib/python3.8/site-packages/ray/tune/trainable/trainable.py\", line 342, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/skchen/venv/ml4t/lib/python3.8/site-packages/ray/air/_internal/util.py\", line 88, in run\n",
      "    self._ret = self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/skchen/venv/ml4t/lib/python3.8/site-packages/ray/tune/trainable/function_trainable.py\", line 115, in <lambda>\n",
      "    training_func=lambda: self._trainable_func(self.config),\n",
      "  File \"/home/skchen/venv/ml4t/lib/python3.8/site-packages/ray/tune/trainable/function_trainable.py\", line 332, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/home/skchen/venv/ml4t/lib/python3.8/site-packages/ray/tune/trainable/util.py\", line 138, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "  File \"/tmp/ipykernel_21072/1012640050.py\", line 53, in ray_train_task\n",
      "  File \"/tmp/ipykernel_21072/1727838043.py\", line 33, in doTraining\n",
      "AttributeError: 'float' object has no attribute 'backward'\n",
      "2024-02-07 21:40:01,322\tERROR tune_controller.py:1374 -- Trial task failed for trial ray_train_task_7c902_00003\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/skchen/venv/ml4t/lib/python3.8/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/skchen/venv/ml4t/lib/python3.8/site-packages/ray/_private/auto_init_hook.py\", line 22, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/skchen/venv/ml4t/lib/python3.8/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/skchen/venv/ml4t/lib/python3.8/site-packages/ray/_private/worker.py\", line 2624, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=24161, ip=192.168.0.125, actor_id=599a21c32ccf693b7b3ec85301000000, repr=ray_train_task)\n",
      "  File \"/home/skchen/venv/ml4t/lib/python3.8/site-packages/ray/tune/trainable/trainable.py\", line 342, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/skchen/venv/ml4t/lib/python3.8/site-packages/ray/air/_internal/util.py\", line 88, in run\n",
      "    self._ret = self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/skchen/venv/ml4t/lib/python3.8/site-packages/ray/tune/trainable/function_trainable.py\", line 115, in <lambda>\n",
      "    training_func=lambda: self._trainable_func(self.config),\n",
      "  File \"/home/skchen/venv/ml4t/lib/python3.8/site-packages/ray/tune/trainable/function_trainable.py\", line 332, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/home/skchen/venv/ml4t/lib/python3.8/site-packages/ray/tune/trainable/util.py\", line 138, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "  File \"/tmp/ipykernel_21072/1012640050.py\", line 53, in ray_train_task\n",
      "  File \"/tmp/ipykernel_21072/1727838043.py\", line 33, in doTraining\n",
      "AttributeError: 'float' object has no attribute 'backward'\n",
      "2024-02-07 21:40:03,931\tERROR tune_controller.py:1374 -- Trial task failed for trial ray_train_task_7c902_00007\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/skchen/venv/ml4t/lib/python3.8/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/skchen/venv/ml4t/lib/python3.8/site-packages/ray/_private/auto_init_hook.py\", line 22, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/skchen/venv/ml4t/lib/python3.8/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/skchen/venv/ml4t/lib/python3.8/site-packages/ray/_private/worker.py\", line 2624, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=24776, ip=192.168.0.125, actor_id=d46b633631181f83328101c701000000, repr=ray_train_task)\n",
      "  File \"/home/skchen/venv/ml4t/lib/python3.8/site-packages/ray/tune/trainable/trainable.py\", line 342, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/skchen/venv/ml4t/lib/python3.8/site-packages/ray/air/_internal/util.py\", line 88, in run\n",
      "    self._ret = self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/skchen/venv/ml4t/lib/python3.8/site-packages/ray/tune/trainable/function_trainable.py\", line 115, in <lambda>\n",
      "    training_func=lambda: self._trainable_func(self.config),\n",
      "  File \"/home/skchen/venv/ml4t/lib/python3.8/site-packages/ray/tune/trainable/function_trainable.py\", line 332, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/home/skchen/venv/ml4t/lib/python3.8/site-packages/ray/tune/trainable/util.py\", line 138, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "  File \"/tmp/ipykernel_21072/1012640050.py\", line 53, in ray_train_task\n",
      "  File \"/tmp/ipykernel_21072/1727838043.py\", line 33, in doTraining\n",
      "AttributeError: 'float' object has no attribute 'backward'\n",
      "2024-02-07 21:40:04,776\tERROR tune_controller.py:1374 -- Trial task failed for trial ray_train_task_7c902_00006\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/skchen/venv/ml4t/lib/python3.8/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/skchen/venv/ml4t/lib/python3.8/site-packages/ray/_private/auto_init_hook.py\", line 22, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/skchen/venv/ml4t/lib/python3.8/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/skchen/venv/ml4t/lib/python3.8/site-packages/ray/_private/worker.py\", line 2624, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=24775, ip=192.168.0.125, actor_id=bf3809e017f64e27edcb0dfb01000000, repr=ray_train_task)\n",
      "  File \"/home/skchen/venv/ml4t/lib/python3.8/site-packages/ray/tune/trainable/trainable.py\", line 342, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/skchen/venv/ml4t/lib/python3.8/site-packages/ray/air/_internal/util.py\", line 88, in run\n",
      "    self._ret = self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/skchen/venv/ml4t/lib/python3.8/site-packages/ray/tune/trainable/function_trainable.py\", line 115, in <lambda>\n",
      "    training_func=lambda: self._trainable_func(self.config),\n",
      "  File \"/home/skchen/venv/ml4t/lib/python3.8/site-packages/ray/tune/trainable/function_trainable.py\", line 332, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/home/skchen/venv/ml4t/lib/python3.8/site-packages/ray/tune/trainable/util.py\", line 138, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "  File \"/tmp/ipykernel_21072/1012640050.py\", line 53, in ray_train_task\n",
      "  File \"/tmp/ipykernel_21072/1727838043.py\", line 33, in doTraining\n",
      "AttributeError: 'float' object has no attribute 'backward'\n",
      "2024-02-07 21:40:04,781\tERROR tune.py:1038 -- Trials did not complete: [ray_train_task_7c902_00000, ray_train_task_7c902_00001, ray_train_task_7c902_00002, ray_train_task_7c902_00003, ray_train_task_7c902_00004, ray_train_task_7c902_00005, ray_train_task_7c902_00006, ray_train_task_7c902_00007]\n",
      "2024-02-07 21:40:04,781\tINFO tune.py:1042 -- Total run time: 10.29 seconds (10.27 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=Warning)\n",
    "\n",
    "time_str = datetime.now().strftime(\"%Y-%m-%d_%H.%M.%S\")\n",
    "log_dir = f\"{log_dir_base}/{time_str}\"\n",
    "os.mkdir(log_dir)\n",
    "\n",
    "data = prepare_LSTMDataset(\n",
    "    return_period, seq_len, train_data_pattern=[0, 1, 0]\n",
    ")  # [0, 1, 0, 1, 0])\n",
    "# analysis = tune.run(\n",
    "#     train_LSTM,\n",
    "#     config=search_space,\n",
    "#     resources_per_trial={\"cpu\": 0.1, \"gpu\": 0.1},\n",
    "#     metric=\"f1_score\",\n",
    "#     mode=\"max\",\n",
    "# )\n",
    "tuner = tune.Tuner(\n",
    "    tune.with_resources(\n",
    "        tune.with_parameters(ray_train_task, data=data),\n",
    "        resources={\"cpu\": 0.33, \"gpu\": 0.33},\n",
    "    ),\n",
    "    tune_config=tune.TuneConfig(\n",
    "        metric=\"f1_score\",\n",
    "        mode=\"max\",\n",
    "    ),\n",
    "    param_space=search_space,\n",
    ")\n",
    "results = tuner.fit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml4t",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
