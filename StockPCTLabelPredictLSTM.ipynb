{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StockPCTLabelPredictLSTM\n",
      "/mnt/AIWorkSpace/work/fin-ml/data/\n",
      "/mnt/AIWorkSpace/work/fin-ml/runs/StockPCTLabelPredictLSTM\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas_datareader.data as web\n",
    "from matplotlib import pyplot\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "#Plotting \n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "#Libraries for Statistical Models\n",
    "import statsmodels.api as sm\n",
    "\n",
    "#logging\n",
    "from myutil.logconf import logging\n",
    "log = logging.getLogger(__name__)\n",
    "# log.setLevel(logging.ERROR)\n",
    "log.setLevel(logging.INFO)\n",
    "# log.setLevel(logging.WARN)\n",
    "# log.setLevel(logging.DEBUG)\n",
    "\n",
    "\n",
    "#Diable the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.expand_frame_repr = False\n",
    "pd.options.display.float_format = '{:.3f}'.format\n",
    "\n",
    "torch.seed = 42\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "%run 'nb_utils.ipynb'\n",
    "task_name = get_filename_of_ipynb()\n",
    "print(task_name)\n",
    "data_dir = f'{os.getcwd()}/data/'\n",
    "log_dir_base = f'{os.getcwd()}/runs/{task_name}'\n",
    "log_dir = log_dir_base\n",
    "print(f'{data_dir}\\n{log_dir}')\n",
    "\n",
    "return_period = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-02 21:32:38,538\tINFO worker.py:1715 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "384de034bb2844a39c51980ee38c2510",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<div class=\"lm-Widget p-Widget lm-Panel p-Panel jp-Cell-outputWrapper\">\n",
       "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
       "        <div class=\"jp-RenderedHTMLCommon\" style=\"display: flex; flex-direction: row;\">\n",
       "  <svg viewBox=\"0 0 567 224\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\" style=\"height: 3em;\">\n",
       "    <g clip-path=\"url(#clip0_4338_178347)\">\n",
       "        <path d=\"M341.29 165.561H355.29L330.13 129.051C345.63 123.991 354.21 112.051 354.21 94.2307C354.21 71.3707 338.72 58.1807 311.88 58.1807H271V165.561H283.27V131.661H311.8C314.25 131.661 316.71 131.501 319.01 131.351L341.25 165.561H341.29ZM283.29 119.851V70.0007H311.82C331.3 70.0007 342.34 78.2907 342.34 94.5507C342.34 111.271 331.34 119.861 311.82 119.861L283.29 119.851ZM451.4 138.411L463.4 165.561H476.74L428.74 58.1807H416L367.83 165.561H380.83L392.83 138.411H451.4ZM446.19 126.601H398L422 72.1407L446.24 126.601H446.19ZM526.11 128.741L566.91 58.1807H554.35L519.99 114.181L485.17 58.1807H472.44L514.01 129.181V165.541H526.13V128.741H526.11Z\" fill=\"var(--jp-ui-font-color0)\"/>\n",
       "        <path d=\"M82.35 104.44C84.0187 97.8827 87.8248 92.0678 93.1671 87.9146C98.5094 83.7614 105.083 81.5067 111.85 81.5067C118.617 81.5067 125.191 83.7614 130.533 87.9146C135.875 92.0678 139.681 97.8827 141.35 104.44H163.75C164.476 101.562 165.622 98.8057 167.15 96.2605L127.45 56.5605C121.071 60.3522 113.526 61.6823 106.235 60.3005C98.9443 58.9187 92.4094 54.9203 87.8602 49.0574C83.3109 43.1946 81.0609 35.8714 81.5332 28.4656C82.0056 21.0599 85.1679 14.0819 90.4252 8.8446C95.6824 3.60726 102.672 0.471508 110.08 0.0272655C117.487 -0.416977 124.802 1.86091 130.647 6.4324C136.493 11.0039 140.467 17.5539 141.821 24.8501C143.175 32.1463 141.816 39.6859 138 46.0505L177.69 85.7505C182.31 82.9877 187.58 81.4995 192.962 81.4375C198.345 81.3755 203.648 82.742 208.33 85.3976C213.012 88.0532 216.907 91.9029 219.616 96.5544C222.326 101.206 223.753 106.492 223.753 111.875C223.753 117.258 222.326 122.545 219.616 127.197C216.907 131.848 213.012 135.698 208.33 138.353C203.648 141.009 198.345 142.375 192.962 142.313C187.58 142.251 182.31 140.763 177.69 138L138 177.7C141.808 184.071 143.155 191.614 141.79 198.91C140.424 206.205 136.44 212.75 130.585 217.313C124.731 221.875 117.412 224.141 110.004 223.683C102.596 223.226 95.6103 220.077 90.3621 214.828C85.1139 209.58 81.9647 202.595 81.5072 195.187C81.0497 187.779 83.3154 180.459 87.878 174.605C92.4405 168.751 98.9853 164.766 106.281 163.401C113.576 162.035 121.119 163.383 127.49 167.19L167.19 127.49C165.664 124.941 164.518 122.182 163.79 119.3H141.39C139.721 125.858 135.915 131.673 130.573 135.826C125.231 139.98 118.657 142.234 111.89 142.234C105.123 142.234 98.5494 139.98 93.2071 135.826C87.8648 131.673 84.0587 125.858 82.39 119.3H60C58.1878 126.495 53.8086 132.78 47.6863 136.971C41.5641 141.163 34.1211 142.972 26.7579 142.059C19.3947 141.146 12.6191 137.574 7.70605 132.014C2.79302 126.454 0.0813599 119.29 0.0813599 111.87C0.0813599 104.451 2.79302 97.2871 7.70605 91.7272C12.6191 86.1673 19.3947 82.5947 26.7579 81.6817C34.1211 80.7686 41.5641 82.5781 47.6863 86.7696C53.8086 90.9611 58.1878 97.2456 60 104.44H82.35ZM100.86 204.32C103.407 206.868 106.759 208.453 110.345 208.806C113.93 209.159 117.527 208.258 120.522 206.256C123.517 204.254 125.725 201.276 126.771 197.828C127.816 194.38 127.633 190.677 126.253 187.349C124.874 184.021 122.383 181.274 119.205 179.577C116.027 177.88 112.359 177.337 108.826 178.042C105.293 178.746 102.113 180.654 99.8291 183.44C97.5451 186.226 96.2979 189.718 96.3 193.32C96.2985 195.364 96.7006 197.388 97.4831 199.275C98.2656 201.163 99.4132 202.877 100.86 204.32ZM204.32 122.88C206.868 120.333 208.453 116.981 208.806 113.396C209.159 109.811 208.258 106.214 206.256 103.219C204.254 100.223 201.275 98.0151 197.827 96.97C194.38 95.9249 190.676 96.1077 187.348 97.4873C184.02 98.8669 181.274 101.358 179.577 104.536C177.879 107.714 177.337 111.382 178.041 114.915C178.746 118.448 180.653 121.627 183.439 123.911C186.226 126.195 189.717 127.443 193.32 127.44C195.364 127.443 197.388 127.042 199.275 126.259C201.163 125.476 202.878 124.328 204.32 122.88ZM122.88 19.4205C120.333 16.8729 116.981 15.2876 113.395 14.9347C109.81 14.5817 106.213 15.483 103.218 17.4849C100.223 19.4868 98.0146 22.4654 96.9696 25.9131C95.9245 29.3608 96.1073 33.0642 97.4869 36.3922C98.8665 39.7202 101.358 42.4668 104.535 44.1639C107.713 45.861 111.381 46.4036 114.914 45.6992C118.447 44.9949 121.627 43.0871 123.911 40.301C126.195 37.515 127.442 34.0231 127.44 30.4205C127.44 28.3772 127.038 26.3539 126.255 24.4664C125.473 22.5788 124.326 20.8642 122.88 19.4205ZM19.42 100.86C16.8725 103.408 15.2872 106.76 14.9342 110.345C14.5813 113.93 15.4826 117.527 17.4844 120.522C19.4863 123.518 22.4649 125.726 25.9127 126.771C29.3604 127.816 33.0638 127.633 36.3918 126.254C39.7198 124.874 42.4664 122.383 44.1635 119.205C45.8606 116.027 46.4032 112.359 45.6988 108.826C44.9944 105.293 43.0866 102.114 40.3006 99.8296C37.5145 97.5455 34.0227 96.2983 30.42 96.3005C26.2938 96.3018 22.337 97.9421 19.42 100.86ZM100.86 100.86C98.3125 103.408 96.7272 106.76 96.3742 110.345C96.0213 113.93 96.9226 117.527 98.9244 120.522C100.926 123.518 103.905 125.726 107.353 126.771C110.8 127.816 114.504 127.633 117.832 126.254C121.16 124.874 123.906 122.383 125.604 119.205C127.301 116.027 127.843 112.359 127.139 108.826C126.434 105.293 124.527 102.114 121.741 99.8296C118.955 97.5455 115.463 96.2983 111.86 96.3005C109.817 96.299 107.793 96.701 105.905 97.4835C104.018 98.2661 102.303 99.4136 100.86 100.86Z\" fill=\"#00AEEF\"/>\n",
       "    </g>\n",
       "    <defs>\n",
       "        <clipPath id=\"clip0_4338_178347\">\n",
       "            <rect width=\"566.93\" height=\"223.75\" fill=\"white\"/>\n",
       "        </clipPath>\n",
       "    </defs>\n",
       "  </svg>\n",
       "</div>\n",
       "\n",
       "        <table class=\"jp-RenderedHTMLCommon\" style=\"border-collapse: collapse;color: var(--jp-ui-font-color1);font-size: var(--jp-ui-font-size1);\">\n",
       "    <tr>\n",
       "        <td style=\"text-align: left\"><b>Python version:</b></td>\n",
       "        <td style=\"text-align: left\"><b>3.8.18</b></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
       "        <td style=\"text-align: left\"><b>2.9.1</b></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "    <td style=\"text-align: left\"><b>Dashboard:</b></td>\n",
       "    <td style=\"text-align: left\"><b><a href=\"http://127.0.0.1:8265\" target=\"_blank\">http://127.0.0.1:8265</a></b></td>\n",
       "</tr>\n",
       "\n",
       "</table>\n",
       "\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "RayContext(dashboard_url='127.0.0.1:8265', python_version='3.8.18', ray_version='2.9.1', ray_commit='cfbf98c315cfb2710c56039a3c96477d196de049', protocol_version=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hyperparameters turning\n",
    "from ray import tune, train, ray\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "\n",
    "ray.init(log_to_driver=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read /mnt/AIWorkSpace/work/fin-ml/data/AAPL.csv completely!\n",
      "AAPL, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/MSFT.csv completely!\n",
      "MSFT, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/AMZN.csv completely!\n",
      "AMZN, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/NVDA.csv completely!\n",
      "NVDA, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/GOOGL.csv completely!\n",
      "GOOGL, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/GOOG.csv completely!\n",
      "GOOG, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/META.csv completely!\n",
      "META, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/TSLA.csv completely!\n",
      "TSLA, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/UNH.csv completely!\n",
      "UNH, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/LLY.csv completely!\n",
      "LLY, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/JPM.csv completely!\n",
      "JPM, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/XOM.csv completely!\n",
      "XOM, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/JNJ.csv completely!\n",
      "JNJ, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/V.csv completely!\n",
      "V, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/PG.csv completely!\n",
      "PG, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/AVGO.csv completely!\n",
      "AVGO, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/MA.csv completely!\n",
      "MA, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/HD.csv completely!\n",
      "HD, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CVX.csv completely!\n",
      "CVX, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/MRK.csv completely!\n",
      "MRK, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/ABBV.csv completely!\n",
      "ABBV, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/PEP.csv completely!\n",
      "PEP, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/COST.csv completely!\n",
      "COST, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/ADBE.csv completely!\n",
      "ADBE, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/KO.csv completely!\n",
      "KO, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CSCO.csv completely!\n",
      "CSCO, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/WMT.csv completely!\n",
      "WMT, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/TMO.csv completely!\n",
      "TMO, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/MCD.csv completely!\n",
      "MCD, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/PFE.csv completely!\n",
      "PFE, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CRM.csv completely!\n",
      "CRM, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/BAC.csv completely!\n",
      "BAC, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/ACN.csv completely!\n",
      "ACN, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CMCSA.csv completely!\n",
      "CMCSA, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/LIN.csv completely!\n",
      "LIN, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/NFLX.csv completely!\n",
      "NFLX, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/ABT.csv completely!\n",
      "ABT, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/ORCL.csv completely!\n",
      "ORCL, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/DHR.csv completely!\n",
      "DHR, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/AMD.csv completely!\n",
      "AMD, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/WFC.csv completely!\n",
      "WFC, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/DIS.csv completely!\n",
      "DIS, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/TXN.csv completely!\n",
      "TXN, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/PM.csv completely!\n",
      "PM, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/VZ.csv completely!\n",
      "VZ, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/INTU.csv completely!\n",
      "INTU, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/COP.csv completely!\n",
      "COP, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CAT.csv completely!\n",
      "CAT, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/AMGN.csv completely!\n",
      "AMGN, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/NEE.csv completely!\n",
      "NEE, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/INTC.csv completely!\n",
      "INTC, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/UNP.csv completely!\n",
      "UNP, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/LOW.csv completely!\n",
      "LOW, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/IBM.csv completely!\n",
      "IBM, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/BMY.csv completely!\n",
      "BMY, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/SPGI.csv completely!\n",
      "SPGI, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/RTX.csv completely!\n",
      "RTX, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/HON.csv completely!\n",
      "HON, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/BA.csv completely!\n",
      "BA, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/UPS.csv completely!\n",
      "UPS, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/GE.csv completely!\n",
      "GE, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/QCOM.csv completely!\n",
      "QCOM, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/AMAT.csv completely!\n",
      "AMAT, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/NKE.csv completely!\n",
      "NKE, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/PLD.csv completely!\n",
      "PLD, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/NOW.csv completely!\n",
      "NOW, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/BKNG.csv completely!\n",
      "BKNG, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/SBUX.csv completely!\n",
      "SBUX, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/MS.csv completely!\n",
      "MS, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/ELV.csv completely!\n",
      "ELV, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/MDT.csv completely!\n",
      "MDT, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/GS.csv completely!\n",
      "GS, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/DE.csv completely!\n",
      "DE, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/ADP.csv completely!\n",
      "ADP, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/LMT.csv completely!\n",
      "LMT, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/TJX.csv completely!\n",
      "TJX, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/T.csv completely!\n",
      "T, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/BLK.csv completely!\n",
      "BLK, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/ISRG.csv completely!\n",
      "ISRG, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/MDLZ.csv completely!\n",
      "MDLZ, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/GILD.csv completely!\n",
      "GILD, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/MMC.csv completely!\n",
      "MMC, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/AXP.csv completely!\n",
      "AXP, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/SYK.csv completely!\n",
      "SYK, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/REGN.csv completely!\n",
      "REGN, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/VRTX.csv completely!\n",
      "VRTX, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/ETN.csv completely!\n",
      "ETN, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/LRCX.csv completely!\n",
      "LRCX, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/ADI.csv completely!\n",
      "ADI, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/SCHW.csv completely!\n",
      "SCHW, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CVS.csv completely!\n",
      "CVS, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/ZTS.csv completely!\n",
      "ZTS, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CI.csv completely!\n",
      "CI, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CB.csv completely!\n",
      "CB, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/AMT.csv completely!\n",
      "AMT, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/SLB.csv completely!\n",
      "SLB, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/C.csv completely!\n",
      "C, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/BDX.csv completely!\n",
      "BDX, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/MO.csv completely!\n",
      "MO, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/PGR.csv completely!\n",
      "PGR, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/TMUS.csv completely!\n",
      "TMUS, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/FI.csv completely!\n",
      "FI, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/SO.csv completely!\n",
      "SO, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/EOG.csv completely!\n",
      "EOG, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/BSX.csv completely!\n",
      "BSX, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CME.csv completely!\n",
      "CME, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/EQIX.csv completely!\n",
      "EQIX, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/MU.csv completely!\n",
      "MU, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/DUK.csv completely!\n",
      "DUK, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/PANW.csv completely!\n",
      "PANW, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/PYPL.csv completely!\n",
      "PYPL, size:2138\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/AON.csv completely!\n",
      "AON, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/SNPS.csv completely!\n",
      "SNPS, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/ITW.csv completely!\n",
      "ITW, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/KLAC.csv completely!\n",
      "KLAC, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/LULU.csv completely!\n",
      "LULU, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/ICE.csv completely!\n",
      "ICE, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/APD.csv completely!\n",
      "APD, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/SHW.csv completely!\n",
      "SHW, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CDNS.csv completely!\n",
      "CDNS, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CSX.csv completely!\n",
      "CSX, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/NOC.csv completely!\n",
      "NOC, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CL.csv completely!\n",
      "CL, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/MPC.csv completely!\n",
      "MPC, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/HUM.csv completely!\n",
      "HUM, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/FDX.csv completely!\n",
      "FDX, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/WM.csv completely!\n",
      "WM, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/MCK.csv completely!\n",
      "MCK, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/TGT.csv completely!\n",
      "TGT, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/ORLY.csv completely!\n",
      "ORLY, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/HCA.csv completely!\n",
      "HCA, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/FCX.csv completely!\n",
      "FCX, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/EMR.csv completely!\n",
      "EMR, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/PXD.csv completely!\n",
      "PXD, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/MMM.csv completely!\n",
      "MMM, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/MCO.csv completely!\n",
      "MCO, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/ROP.csv completely!\n",
      "ROP, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CMG.csv completely!\n",
      "CMG, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/PSX.csv completely!\n",
      "PSX, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/MAR.csv completely!\n",
      "MAR, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/PH.csv completely!\n",
      "PH, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/APH.csv completely!\n",
      "APH, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/GD.csv completely!\n",
      "GD, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/USB.csv completely!\n",
      "USB, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/NXPI.csv completely!\n",
      "NXPI, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/AJG.csv completely!\n",
      "AJG, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/NSC.csv completely!\n",
      "NSC, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/PNC.csv completely!\n",
      "PNC, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/VLO.csv completely!\n",
      "VLO, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/GBP.csv completely!\n",
      "GBP, size:1895\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/F.csv completely!\n",
      "F, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/MSI.csv completely!\n",
      "MSI, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/GM.csv completely!\n",
      "GM, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/TT.csv completely!\n",
      "TT, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/EW.csv completely!\n",
      "EW, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CARR.csv completely!\n",
      "CARR, size:953\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/AZO.csv completely!\n",
      "AZO, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/ADSK.csv completely!\n",
      "ADSK, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/TDG.csv completely!\n",
      "TDG, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/ANET.csv completely!\n",
      "ANET, size:2409\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/SRE.csv completely!\n",
      "SRE, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/ECL.csv completely!\n",
      "ECL, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/OXY.csv completely!\n",
      "OXY, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/PCAR.csv completely!\n",
      "PCAR, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/ADM.csv completely!\n",
      "ADM, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/MNST.csv completely!\n",
      "MNST, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/KMB.csv completely!\n",
      "KMB, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/PSA.csv completely!\n",
      "PSA, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CCI.csv completely!\n",
      "CCI, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CHTR.csv completely!\n",
      "CHTR, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/MCHP.csv completely!\n",
      "MCHP, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/MSCI.csv completely!\n",
      "MSCI, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CTAS.csv completely!\n",
      "CTAS, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/WMB.csv completely!\n",
      "WMB, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/AIG.csv completely!\n",
      "AIG, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/STZ.csv completely!\n",
      "STZ, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/HES.csv completely!\n",
      "HES, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/NUE.csv completely!\n",
      "NUE, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/ROST.csv completely!\n",
      "ROST, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/AFL.csv completely!\n",
      "AFL, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/AEP.csv completely!\n",
      "AEP, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/IDXX.csv completely!\n",
      "IDXX, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/D.csv completely!\n",
      "D, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/TEL.csv completely!\n",
      "TEL, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/JCI.csv completely!\n",
      "JCI, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/MET.csv completely!\n",
      "MET, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/GIS.csv completely!\n",
      "GIS, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/IQV.csv completely!\n",
      "IQV, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/EXC.csv completely!\n",
      "EXC, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/WELL.csv completely!\n",
      "WELL, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/DXCM.csv completely!\n",
      "DXCM, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/HLT.csv completely!\n",
      "HLT, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/ON.csv completely!\n",
      "ON, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/COF.csv completely!\n",
      "COF, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/PAYX.csv completely!\n",
      "PAYX, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/TFC.csv completely!\n",
      "TFC, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/USD.csv completely!\n",
      "USD, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/BIIB.csv completely!\n",
      "BIIB, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/O.csv completely!\n",
      "O, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/FTNT.csv completely!\n",
      "FTNT, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/DOW.csv completely!\n",
      "DOW, size:1205\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/TRV.csv completely!\n",
      "TRV, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/DLR.csv completely!\n",
      "DLR, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/MRNA.csv completely!\n",
      "MRNA, size:1274\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CPRT.csv completely!\n",
      "CPRT, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/ODFL.csv completely!\n",
      "ODFL, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/DHI.csv completely!\n",
      "DHI, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/YUM.csv completely!\n",
      "YUM, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/SPG.csv completely!\n",
      "SPG, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CTSH.csv completely!\n",
      "CTSH, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/AME.csv completely!\n",
      "AME, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/BKR.csv completely!\n",
      "BKR, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/SYY.csv completely!\n",
      "SYY, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/A.csv completely!\n",
      "A, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CTVA.csv completely!\n",
      "CTVA, size:1159\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CNC.csv completely!\n",
      "CNC, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/EL.csv completely!\n",
      "EL, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/AMP.csv completely!\n",
      "AMP, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CEG.csv completely!\n",
      "CEG, size:490\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/HAL.csv completely!\n",
      "HAL, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/OTIS.csv completely!\n",
      "OTIS, size:953\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/ROK.csv completely!\n",
      "ROK, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/PRU.csv completely!\n",
      "PRU, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/DD.csv completely!\n",
      "DD, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/KMI.csv completely!\n",
      "KMI, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/VRSK.csv completely!\n",
      "VRSK, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/LHX.csv completely!\n",
      "LHX, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/DG.csv completely!\n",
      "DG, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/FIS.csv completely!\n",
      "FIS, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CMI.csv completely!\n",
      "CMI, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CSGP.csv completely!\n",
      "CSGP, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/FAST.csv completely!\n",
      "FAST, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/PPG.csv completely!\n",
      "PPG, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/GPN.csv completely!\n",
      "GPN, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/GWW.csv completely!\n",
      "GWW, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/HSY.csv completely!\n",
      "HSY, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/BK.csv completely!\n",
      "BK, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/XEL.csv completely!\n",
      "XEL, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/DVN.csv completely!\n",
      "DVN, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/EA.csv completely!\n",
      "EA, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/NEM.csv completely!\n",
      "NEM, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/ED.csv completely!\n",
      "ED, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/URI.csv completely!\n",
      "URI, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/VICI.csv completely!\n",
      "VICI, size:1509\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/PEG.csv completely!\n",
      "PEG, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/KR.csv completely!\n",
      "KR, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/RSG.csv completely!\n",
      "RSG, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/LEN.csv completely!\n",
      "LEN, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/PWR.csv completely!\n",
      "PWR, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/WST.csv completely!\n",
      "WST, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/COR.csv completely!\n",
      "COR, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/OKE.csv completely!\n",
      "OKE, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/VMC.csv completely!\n",
      "VMC, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/KDP.csv completely!\n",
      "KDP, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/WBD.csv completely!\n",
      "WBD, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/ACGL.csv completely!\n",
      "ACGL, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/ALL.csv completely!\n",
      "ALL, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/IR.csv completely!\n",
      "IR, size:1670\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CDW.csv completely!\n",
      "CDW, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/FANG.csv completely!\n",
      "FANG, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/MLM.csv completely!\n",
      "MLM, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/PCG.csv completely!\n",
      "PCG, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/DAL.csv completely!\n",
      "DAL, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/EXR.csv completely!\n",
      "EXR, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/FTV.csv completely!\n",
      "FTV, size:1886\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/AWK.csv completely!\n",
      "AWK, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/IT.csv completely!\n",
      "IT, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/KHC.csv completely!\n",
      "KHC, size:2138\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/GEHC.csv completely!\n",
      "GEHC, size:261\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/WEC.csv completely!\n",
      "WEC, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/HPQ.csv completely!\n",
      "HPQ, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/EIX.csv completely!\n",
      "EIX, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CBRE.csv completely!\n",
      "CBRE, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/APTV.csv completely!\n",
      "APTV, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/ANSS.csv completely!\n",
      "ANSS, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/MTD.csv completely!\n",
      "MTD, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/DLTR.csv completely!\n",
      "DLTR, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/AVB.csv completely!\n",
      "AVB, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/ILMN.csv completely!\n",
      "ILMN, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/ALGN.csv completely!\n",
      "ALGN, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/LYB.csv completely!\n",
      "LYB, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/TROW.csv completely!\n",
      "TROW, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/GLW.csv completely!\n",
      "GLW, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/EFX.csv completely!\n",
      "EFX, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/WY.csv completely!\n",
      "WY, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/ZBH.csv completely!\n",
      "ZBH, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/XYL.csv completely!\n",
      "XYL, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/SBAC.csv completely!\n",
      "SBAC, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/RMD.csv completely!\n",
      "RMD, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/TSCO.csv completely!\n",
      "TSCO, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/EBAY.csv completely!\n",
      "EBAY, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/KEYS.csv completely!\n",
      "KEYS, size:2315\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CHD.csv completely!\n",
      "CHD, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/STT.csv completely!\n",
      "STT, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/DFS.csv completely!\n",
      "DFS, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/HIG.csv completely!\n",
      "HIG, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/ALB.csv completely!\n",
      "ALB, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/STE.csv completely!\n",
      "STE, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/ES.csv completely!\n",
      "ES, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/TTWO.csv completely!\n",
      "TTWO, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/MPWR.csv completely!\n",
      "MPWR, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CAH.csv completely!\n",
      "CAH, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/EQR.csv completely!\n",
      "EQR, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/RCL.csv completely!\n",
      "RCL, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/WTW.csv completely!\n",
      "WTW, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/HPE.csv completely!\n",
      "HPE, size:2064\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/DTE.csv completely!\n",
      "DTE, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/GPC.csv completely!\n",
      "GPC, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/BR.csv completely!\n",
      "BR, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/ULTA.csv completely!\n",
      "ULTA, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/FICO.csv completely!\n",
      "FICO, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CTRA.csv completely!\n",
      "CTRA, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/BAX.csv completely!\n",
      "BAX, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/AEE.csv completely!\n",
      "AEE, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/MTB.csv completely!\n",
      "MTB, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/MKC.csv completely!\n",
      "MKC, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/ETR.csv completely!\n",
      "ETR, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/WAB.csv completely!\n",
      "WAB, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/DOV.csv completely!\n",
      "DOV, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/FE.csv completely!\n",
      "FE, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/RJF.csv completely!\n",
      "RJF, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/INVH.csv completely!\n",
      "INVH, size:1740\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/FLT.csv completely!\n",
      "FLT, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CLX.csv completely!\n",
      "CLX, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/TDY.csv completely!\n",
      "TDY, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/TRGP.csv completely!\n",
      "TRGP, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/DRI.csv completely!\n",
      "DRI, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/LH.csv completely!\n",
      "LH, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/HOLX.csv completely!\n",
      "HOLX, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/VRSN.csv completely!\n",
      "VRSN, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/MOH.csv completely!\n",
      "MOH, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/LUV.csv completely!\n",
      "LUV, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/PPL.csv completely!\n",
      "PPL, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/ARE.csv completely!\n",
      "ARE, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/NVR.csv completely!\n",
      "NVR, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/COO.csv completely!\n",
      "COO, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/WBA.csv completely!\n",
      "WBA, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/PHM.csv completely!\n",
      "PHM, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/NDAQ.csv completely!\n",
      "NDAQ, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/HWM.csv completely!\n",
      "HWM, size:1802\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/RF.csv completely!\n",
      "RF, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CNP.csv completely!\n",
      "CNP, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/IRM.csv completely!\n",
      "IRM, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/LVS.csv completely!\n",
      "LVS, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/FITB.csv completely!\n",
      "FITB, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/EXPD.csv completely!\n",
      "EXPD, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/VTR.csv completely!\n",
      "VTR, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/FSLR.csv completely!\n",
      "FSLR, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/PFG.csv completely!\n",
      "PFG, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/BRO.csv completely!\n",
      "BRO, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/J.csv completely!\n",
      "J, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/IEX.csv completely!\n",
      "IEX, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/BG.csv completely!\n",
      "BG, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/ATO.csv completely!\n",
      "ATO, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/FDS.csv completely!\n",
      "FDS, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/ENPH.csv completely!\n",
      "ENPH, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/MAA.csv completely!\n",
      "MAA, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CMS.csv completely!\n",
      "CMS, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/IFF.csv completely!\n",
      "IFF, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/BALL.csv completely!\n",
      "BALL, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/SWKS.csv completely!\n",
      "SWKS, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CINF.csv completely!\n",
      "CINF, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/NTAP.csv completely!\n",
      "NTAP, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/STLD.csv completely!\n",
      "STLD, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/UAL.csv completely!\n",
      "UAL, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/WAT.csv completely!\n",
      "WAT, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/OMC.csv completely!\n",
      "OMC, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/TER.csv completely!\n",
      "TER, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CCL.csv completely!\n",
      "CCL, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/JBHT.csv completely!\n",
      "JBHT, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/MRO.csv completely!\n",
      "MRO, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/TYL.csv completely!\n",
      "TYL, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/HBAN.csv completely!\n",
      "HBAN, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/K.csv completely!\n",
      "K, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/GRMN.csv completely!\n",
      "GRMN, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CBOE.csv completely!\n",
      "CBOE, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/NTRS.csv completely!\n",
      "NTRS, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/TSN.csv completely!\n",
      "TSN, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/AKAM.csv completely!\n",
      "AKAM, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/EG.csv completely!\n",
      "EG, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/ESS.csv completely!\n",
      "ESS, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/EQT.csv completely!\n",
      "EQT, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/TXT.csv completely!\n",
      "TXT, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/EXPE.csv completely!\n",
      "EXPE, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/SJM.csv completely!\n",
      "SJM, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/PTC.csv completely!\n",
      "PTC, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/DGX.csv completely!\n",
      "DGX, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/AVY.csv completely!\n",
      "AVY, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/RVTY.csv completely!\n",
      "RVTY, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/BBY.csv completely!\n",
      "BBY, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CF.csv completely!\n",
      "CF, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CAG.csv completely!\n",
      "CAG, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/EPAM.csv completely!\n",
      "EPAM, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/AMCR.csv completely!\n",
      "AMCR, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/LW.csv completely!\n",
      "LW, size:1795\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/PAYC.csv completely!\n",
      "PAYC, size:2445\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/SNA.csv completely!\n",
      "SNA, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/AXON.csv completely!\n",
      "AXON, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/POOL.csv completely!\n",
      "POOL, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/SYF.csv completely!\n",
      "SYF, size:2371\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/SWK.csv completely!\n",
      "SWK, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/ZBRA.csv completely!\n",
      "ZBRA, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/DPZ.csv completely!\n",
      "DPZ, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/PKG.csv completely!\n",
      "PKG, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CFG.csv completely!\n",
      "CFG, size:2333\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/LDOS.csv completely!\n",
      "LDOS, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/VTRS.csv completely!\n",
      "VTRS, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/PODD.csv completely!\n",
      "PODD, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/LKQ.csv completely!\n",
      "LKQ, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/MOS.csv completely!\n",
      "MOS, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/APA.csv completely!\n",
      "APA, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/EVRG.csv completely!\n",
      "EVRG, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/TRMB.csv completely!\n",
      "TRMB, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/MGM.csv completely!\n",
      "MGM, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/NDSN.csv completely!\n",
      "NDSN, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/WDC.csv completely!\n",
      "WDC, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/MAS.csv completely!\n",
      "MAS, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/LNT.csv completely!\n",
      "LNT, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/IPG.csv completely!\n",
      "IPG, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/MTCH.csv completely!\n",
      "MTCH, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/STX.csv completely!\n",
      "STX, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/KMX.csv completely!\n",
      "KMX, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/TECH.csv completely!\n",
      "TECH, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/WRB.csv completely!\n",
      "WRB, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/LYV.csv completely!\n",
      "LYV, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/IP.csv completely!\n",
      "IP, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/UDR.csv completely!\n",
      "UDR, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/AES.csv completely!\n",
      "AES, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CE.csv completely!\n",
      "CE, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/INCY.csv completely!\n",
      "INCY, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/L.csv completely!\n",
      "L, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/TAP.csv completely!\n",
      "TAP, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/GEN.csv completely!\n",
      "GEN, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CPT.csv completely!\n",
      "CPT, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/KIM.csv completely!\n",
      "KIM, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/JKHY.csv completely!\n",
      "JKHY, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/HRL.csv completely!\n",
      "HRL, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/HST.csv completely!\n",
      "HST, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/FMC.csv completely!\n",
      "FMC, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CZR.csv completely!\n",
      "CZR, size:2335\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/PEAK.csv completely!\n",
      "PEAK, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CDAY.csv completely!\n",
      "CDAY, size:1430\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/PNR.csv completely!\n",
      "PNR, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/NI.csv completely!\n",
      "NI, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CHRW.csv completely!\n",
      "CHRW, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/HSIC.csv completely!\n",
      "HSIC, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CRL.csv completely!\n",
      "CRL, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/REG.csv completely!\n",
      "REG, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/QRVO.csv completely!\n",
      "QRVO, size:2264\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/TFX.csv completely!\n",
      "TFX, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/KEY.csv completely!\n",
      "KEY, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/GL.csv completely!\n",
      "GL, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/EMN.csv completely!\n",
      "EMN, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/WYNN.csv completely!\n",
      "WYNN, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/ALLE.csv completely!\n",
      "ALLE, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/AAL.csv completely!\n",
      "AAL, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/FFIV.csv completely!\n",
      "FFIV, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/BWA.csv completely!\n",
      "BWA, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/BXP.csv completely!\n",
      "BXP, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/MKTX.csv completely!\n",
      "MKTX, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/ROL.csv completely!\n",
      "ROL, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/JNPR.csv completely!\n",
      "JNPR, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/PNW.csv completely!\n",
      "PNW, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/ETSY.csv completely!\n",
      "ETSY, size:2193\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/BLDR.csv completely!\n",
      "BLDR, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/FOXA.csv completely!\n",
      "FOXA, size:1211\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/AOS.csv completely!\n",
      "AOS, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/HAS.csv completely!\n",
      "HAS, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/HII.csv completely!\n",
      "HII, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/NRG.csv completely!\n",
      "NRG, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CPB.csv completely!\n",
      "CPB, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/UHS.csv completely!\n",
      "UHS, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/BIO.csv completely!\n",
      "BIO, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/WRK.csv completely!\n",
      "WRK, size:2145\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/RHI.csv completely!\n",
      "RHI, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CTLT.csv completely!\n",
      "CTLT, size:2371\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/XRAY.csv completely!\n",
      "XRAY, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/BBWI.csv completely!\n",
      "BBWI, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/NWSA.csv completely!\n",
      "NWSA, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/TPR.csv completely!\n",
      "TPR, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/PARA.csv completely!\n",
      "PARA, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/WHR.csv completely!\n",
      "WHR, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/BEN.csv completely!\n",
      "BEN, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/AIZ.csv completely!\n",
      "AIZ, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/NCLH.csv completely!\n",
      "NCLH, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/GNRC.csv completely!\n",
      "GNRC, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/FRT.csv completely!\n",
      "FRT, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/IVZ.csv completely!\n",
      "IVZ, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/VFC.csv completely!\n",
      "VFC, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/CMA.csv completely!\n",
      "CMA, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/DVA.csv completely!\n",
      "DVA, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/JBL.csv completely!\n",
      "JBL, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/HUBB.csv completely!\n",
      "HUBB, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/ZION.csv completely!\n",
      "ZION, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/UBER.csv completely!\n",
      "UBER, size:1169\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/MHK.csv completely!\n",
      "MHK, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/RL.csv completely!\n",
      "RL, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/FOX.csv completely!\n",
      "FOX, size:1210\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/BX.csv completely!\n",
      "BX, size:2516\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/ABNB.csv completely!\n",
      "ABNB, size:768\n",
      "read /mnt/AIWorkSpace/work/fin-ml/data/NWS.csv completely!\n",
      "NWS, size:2516\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import yfinance as yfin\n",
    "\n",
    "# Loading the data\n",
    "stk_symbols = [\n",
    "    \"AAPL\",\n",
    "    \"MSFT\",\n",
    "    \"AMZN\",\n",
    "    \"NVDA\",\n",
    "    \"GOOGL\",\n",
    "    \"GOOG\",\n",
    "    \"META\",\n",
    "    \"TSLA\",\n",
    "    \"UNH\",\n",
    "    \"LLY\",\n",
    "    \"JPM\",\n",
    "    \"XOM\",\n",
    "    \"JNJ\",\n",
    "    \"V\",\n",
    "    \"PG\",\n",
    "    \"AVGO\",\n",
    "    \"MA\",\n",
    "    \"HD\",\n",
    "    \"CVX\",\n",
    "    \"MRK\",\n",
    "    \"ABBV\",\n",
    "    \"PEP\",\n",
    "    \"COST\",\n",
    "    \"ADBE\",\n",
    "    \"KO\",\n",
    "    \"CSCO\",\n",
    "    \"WMT\",\n",
    "    \"TMO\",\n",
    "    \"MCD\",\n",
    "    \"PFE\",\n",
    "    \"CRM\",\n",
    "    \"BAC\",\n",
    "    \"ACN\",\n",
    "    \"CMCSA\",\n",
    "    \"LIN\",\n",
    "    \"NFLX\",\n",
    "    \"ABT\",\n",
    "    \"ORCL\",\n",
    "    \"DHR\",\n",
    "    \"AMD\",\n",
    "    \"WFC\",\n",
    "    \"DIS\",\n",
    "    \"TXN\",\n",
    "    \"PM\",\n",
    "    \"VZ\",\n",
    "    \"INTU\",\n",
    "    \"COP\",\n",
    "    \"CAT\",\n",
    "    \"AMGN\",\n",
    "    \"NEE\",\n",
    "    \"INTC\",\n",
    "    \"UNP\",\n",
    "    \"LOW\",\n",
    "    \"IBM\",\n",
    "    \"BMY\",\n",
    "    \"SPGI\",\n",
    "    \"RTX\",\n",
    "    \"HON\",\n",
    "    \"BA\",\n",
    "    \"UPS\",\n",
    "    \"GE\",\n",
    "    \"QCOM\",\n",
    "    \"AMAT\",\n",
    "    \"NKE\",\n",
    "    \"PLD\",\n",
    "    \"NOW\",\n",
    "    \"BKNG\",\n",
    "    \"SBUX\",\n",
    "    \"MS\",\n",
    "    \"ELV\",\n",
    "    \"MDT\",\n",
    "    \"GS\",\n",
    "    \"DE\",\n",
    "    \"ADP\",\n",
    "    \"LMT\",\n",
    "    \"TJX\",\n",
    "    \"T\",\n",
    "    \"BLK\",\n",
    "    \"ISRG\",\n",
    "    \"MDLZ\",\n",
    "    \"GILD\",\n",
    "    \"MMC\",\n",
    "    \"AXP\",\n",
    "    \"SYK\",\n",
    "    \"REGN\",\n",
    "    \"VRTX\",\n",
    "    \"ETN\",\n",
    "    \"LRCX\",\n",
    "    \"ADI\",\n",
    "    \"SCHW\",\n",
    "    \"CVS\",\n",
    "    \"ZTS\",\n",
    "    \"CI\",\n",
    "    \"CB\",\n",
    "    \"AMT\",\n",
    "    \"SLB\",\n",
    "    \"C\",\n",
    "    \"BDX\",\n",
    "    \"MO\",\n",
    "    \"PGR\",\n",
    "    \"TMUS\",\n",
    "    \"FI\",\n",
    "    \"SO\",\n",
    "    \"EOG\",\n",
    "    \"BSX\",\n",
    "    \"CME\",\n",
    "    \"EQIX\",\n",
    "    \"MU\",\n",
    "    \"DUK\",\n",
    "    \"PANW\",\n",
    "    \"PYPL\",\n",
    "    \"AON\",\n",
    "    \"SNPS\",\n",
    "    \"ITW\",\n",
    "    \"KLAC\",\n",
    "    \"LULU\",\n",
    "    \"ICE\",\n",
    "    \"APD\",\n",
    "    \"SHW\",\n",
    "    \"CDNS\",\n",
    "    \"CSX\",\n",
    "    \"NOC\",\n",
    "    \"CL\",\n",
    "    \"MPC\",\n",
    "    \"HUM\",\n",
    "    \"FDX\",\n",
    "    \"WM\",\n",
    "    \"MCK\",\n",
    "    \"TGT\",\n",
    "    \"ORLY\",\n",
    "    \"HCA\",\n",
    "    \"FCX\",\n",
    "    \"EMR\",\n",
    "    \"PXD\",\n",
    "    \"MMM\",\n",
    "    \"MCO\",\n",
    "    \"ROP\",\n",
    "    \"CMG\",\n",
    "    \"PSX\",\n",
    "    \"MAR\",\n",
    "    \"PH\",\n",
    "    \"APH\",\n",
    "    \"GD\",\n",
    "    \"USB\",\n",
    "    \"NXPI\",\n",
    "    \"AJG\",\n",
    "    \"NSC\",\n",
    "    \"PNC\",\n",
    "    \"VLO\",\n",
    "    \"GBP\",\n",
    "    \"F\",\n",
    "    \"MSI\",\n",
    "    \"GM\",\n",
    "    \"TT\",\n",
    "    \"EW\",\n",
    "    \"CARR\",\n",
    "    \"AZO\",\n",
    "    \"ADSK\",\n",
    "    \"TDG\",\n",
    "    \"ANET\",\n",
    "    \"SRE\",\n",
    "    \"ECL\",\n",
    "    \"OXY\",\n",
    "    \"PCAR\",\n",
    "    \"ADM\",\n",
    "    \"MNST\",\n",
    "    \"KMB\",\n",
    "    \"PSA\",\n",
    "    \"CCI\",\n",
    "    \"CHTR\",\n",
    "    \"MCHP\",\n",
    "    \"MSCI\",\n",
    "    \"CTAS\",\n",
    "    \"WMB\",\n",
    "    \"AIG\",\n",
    "    \"STZ\",\n",
    "    \"HES\",\n",
    "    \"NUE\",\n",
    "    \"ROST\",\n",
    "    \"AFL\",\n",
    "    \"AEP\",\n",
    "    \"IDXX\",\n",
    "    \"D\",\n",
    "    \"TEL\",\n",
    "    \"JCI\",\n",
    "    \"MET\",\n",
    "    \"GIS\",\n",
    "    \"IQV\",\n",
    "    \"EXC\",\n",
    "    \"WELL\",\n",
    "    \"DXCM\",\n",
    "    \"HLT\",\n",
    "    \"ON\",\n",
    "    \"COF\",\n",
    "    \"PAYX\",\n",
    "    \"TFC\",\n",
    "    \"USD\",\n",
    "    \"BIIB\",\n",
    "    \"O\",\n",
    "    \"FTNT\",\n",
    "    \"DOW\",\n",
    "    \"TRV\",\n",
    "    \"DLR\",\n",
    "    \"MRNA\",\n",
    "    \"CPRT\",\n",
    "    \"ODFL\",\n",
    "    \"DHI\",\n",
    "    \"YUM\",\n",
    "    \"SPG\",\n",
    "    \"CTSH\",\n",
    "    \"AME\",\n",
    "    \"BKR\",\n",
    "    \"SYY\",\n",
    "    \"A\",\n",
    "    \"CTVA\",\n",
    "    \"CNC\",\n",
    "    \"EL\",\n",
    "    \"AMP\",\n",
    "    \"CEG\",  # PCT <= -0.05,  size = 0\n",
    "    \"HAL\",\n",
    "    \"OTIS\",  # PCT <= -0.05,  size = 0\n",
    "    \"ROK\",\n",
    "    \"PRU\",\n",
    "    \"DD\",\n",
    "    \"KMI\",\n",
    "    \"VRSK\",\n",
    "    \"LHX\",\n",
    "    \"DG\",\n",
    "    \"FIS\",\n",
    "    \"CMI\",\n",
    "    \"CSGP\",\n",
    "    \"FAST\",\n",
    "    \"PPG\",\n",
    "    \"GPN\",\n",
    "    \"GWW\",\n",
    "    \"HSY\",\n",
    "    \"BK\",\n",
    "    \"XEL\",\n",
    "    \"DVN\",\n",
    "    \"EA\",\n",
    "    \"NEM\",\n",
    "    \"ED\",\n",
    "    \"URI\",\n",
    "    \"VICI\",\n",
    "    \"PEG\",\n",
    "    \"KR\",\n",
    "    \"RSG\",\n",
    "    \"LEN\",\n",
    "    \"PWR\",\n",
    "    \"WST\",\n",
    "    \"COR\",\n",
    "    \"OKE\",\n",
    "    \"VMC\",\n",
    "    \"KDP\",\n",
    "    \"WBD\",\n",
    "    \"ACGL\",\n",
    "    \"ALL\",\n",
    "    \"IR\",\n",
    "    \"CDW\",\n",
    "    \"FANG\",\n",
    "    \"MLM\",\n",
    "    \"PCG\",\n",
    "    \"DAL\",\n",
    "    \"EXR\",\n",
    "    \"FTV\",\n",
    "    \"AWK\",\n",
    "    \"IT\",\n",
    "    \"KHC\",\n",
    "    \"GEHC\",  # PCT <= -0.05,  size = 0\n",
    "    \"WEC\",\n",
    "    \"HPQ\",\n",
    "    \"EIX\",\n",
    "    \"CBRE\",\n",
    "    \"APTV\",\n",
    "    \"ANSS\",\n",
    "    \"MTD\",\n",
    "    \"DLTR\",\n",
    "    \"AVB\",\n",
    "    \"ILMN\",\n",
    "    \"ALGN\",\n",
    "    \"LYB\",\n",
    "    \"TROW\",\n",
    "    \"GLW\",\n",
    "    \"EFX\",\n",
    "    \"WY\",\n",
    "    \"ZBH\",\n",
    "    \"XYL\",\n",
    "    \"SBAC\",\n",
    "    \"RMD\",\n",
    "    \"TSCO\",\n",
    "    \"EBAY\",\n",
    "    \"KEYS\",\n",
    "    \"CHD\",\n",
    "    \"STT\",\n",
    "    \"DFS\",\n",
    "    \"HIG\",\n",
    "    \"ALB\",\n",
    "    \"STE\",\n",
    "    \"ES\",\n",
    "    \"TTWO\",\n",
    "    \"MPWR\",\n",
    "    \"CAH\",\n",
    "    \"EQR\",\n",
    "    \"RCL\",\n",
    "    \"WTW\",\n",
    "    \"HPE\",\n",
    "    \"DTE\",\n",
    "    \"GPC\",\n",
    "    \"BR\",\n",
    "    \"ULTA\",\n",
    "    \"FICO\",\n",
    "    \"CTRA\",\n",
    "    \"BAX\",\n",
    "    \"AEE\",\n",
    "    \"MTB\",\n",
    "    \"MKC\",\n",
    "    \"ETR\",\n",
    "    \"WAB\",\n",
    "    \"DOV\",\n",
    "    \"FE\",\n",
    "    \"RJF\",\n",
    "    \"INVH\",\n",
    "    \"FLT\",\n",
    "    \"CLX\",\n",
    "    \"TDY\",\n",
    "    \"TRGP\",\n",
    "    \"DRI\",\n",
    "    \"LH\",\n",
    "    \"HOLX\",\n",
    "    \"VRSN\",\n",
    "    \"MOH\",\n",
    "    \"LUV\",\n",
    "    \"PPL\",\n",
    "    \"ARE\",\n",
    "    \"NVR\",\n",
    "    \"COO\",\n",
    "    \"WBA\",\n",
    "    \"PHM\",\n",
    "    \"NDAQ\",\n",
    "    \"HWM\",\n",
    "    \"RF\",\n",
    "    \"CNP\",\n",
    "    \"IRM\",\n",
    "    \"LVS\",\n",
    "    \"FITB\",\n",
    "    \"EXPD\",\n",
    "    \"VTR\",\n",
    "    \"FSLR\",\n",
    "    \"PFG\",\n",
    "    \"BRO\",\n",
    "    \"J\",\n",
    "    \"IEX\",\n",
    "    \"BG\",\n",
    "    \"ATO\",\n",
    "    \"FDS\",\n",
    "    \"ENPH\",\n",
    "    \"MAA\",\n",
    "    \"CMS\",\n",
    "    \"IFF\",\n",
    "    \"BALL\",\n",
    "    \"SWKS\",\n",
    "    \"CINF\",\n",
    "    \"NTAP\",\n",
    "    \"STLD\",\n",
    "    \"UAL\",\n",
    "    \"WAT\",\n",
    "    \"OMC\",\n",
    "    \"TER\",\n",
    "    \"CCL\",\n",
    "    \"JBHT\",\n",
    "    \"MRO\",\n",
    "    \"TYL\",\n",
    "    \"HBAN\",\n",
    "    \"K\",\n",
    "    \"GRMN\",\n",
    "    \"CBOE\",\n",
    "    \"NTRS\",\n",
    "    \"TSN\",\n",
    "    \"AKAM\",\n",
    "    \"EG\",\n",
    "    \"ESS\",\n",
    "    \"EQT\",\n",
    "    \"TXT\",\n",
    "    \"EXPE\",\n",
    "    \"SJM\",\n",
    "    \"PTC\",\n",
    "    \"DGX\",\n",
    "    \"AVY\",\n",
    "    \"RVTY\",\n",
    "    \"BBY\",\n",
    "    \"CF\",\n",
    "    \"CAG\",\n",
    "    \"EPAM\",\n",
    "    \"AMCR\",\n",
    "    \"LW\",\n",
    "    \"PAYC\",\n",
    "    \"SNA\",\n",
    "    \"AXON\",\n",
    "    \"POOL\",\n",
    "    \"SYF\",\n",
    "    \"SWK\",\n",
    "    \"ZBRA\",\n",
    "    \"DPZ\",\n",
    "    \"PKG\",\n",
    "    \"CFG\",\n",
    "    \"LDOS\",\n",
    "    \"VTRS\",\n",
    "    \"PODD\",\n",
    "    \"LKQ\",\n",
    "    \"MOS\",\n",
    "    \"APA\",\n",
    "    \"EVRG\",\n",
    "    \"TRMB\",\n",
    "    \"MGM\",\n",
    "    \"NDSN\",\n",
    "    \"WDC\",\n",
    "    \"MAS\",\n",
    "    \"LNT\",\n",
    "    \"IPG\",\n",
    "    \"MTCH\",\n",
    "    \"STX\",\n",
    "    \"KMX\",\n",
    "    \"TECH\",\n",
    "    \"WRB\",\n",
    "    \"LYV\",\n",
    "    \"IP\",\n",
    "    \"UDR\",\n",
    "    \"AES\",\n",
    "    \"CE\",\n",
    "    \"INCY\",\n",
    "    \"L\",\n",
    "    \"TAP\",\n",
    "    \"GEN\",\n",
    "    \"CPT\",\n",
    "    \"KIM\",\n",
    "    \"JKHY\",\n",
    "    \"HRL\",\n",
    "    \"HST\",\n",
    "    \"FMC\",\n",
    "    \"CZR\",\n",
    "    \"PEAK\",\n",
    "    \"CDAY\",\n",
    "    \"PNR\",\n",
    "    \"NI\",\n",
    "    \"CHRW\",\n",
    "    \"HSIC\",\n",
    "    \"CRL\",\n",
    "    \"REG\",\n",
    "    \"QRVO\",\n",
    "    \"TFX\",\n",
    "    \"KEY\",\n",
    "    \"GL\",\n",
    "    \"EMN\",\n",
    "    \"WYNN\",\n",
    "    \"ALLE\",\n",
    "    \"AAL\",\n",
    "    \"FFIV\",\n",
    "    \"BWA\",\n",
    "    \"BXP\",\n",
    "    \"MKTX\",\n",
    "    \"ROL\",\n",
    "    \"JNPR\",\n",
    "    \"PNW\",\n",
    "    \"ETSY\",\n",
    "    \"BLDR\",\n",
    "    \"FOXA\",\n",
    "    \"AOS\",\n",
    "    \"HAS\",\n",
    "    \"HII\",\n",
    "    \"NRG\",\n",
    "    \"CPB\",\n",
    "    \"UHS\",\n",
    "    \"BIO\",\n",
    "    \"WRK\",\n",
    "    \"RHI\",\n",
    "    \"CTLT\",\n",
    "    \"XRAY\",\n",
    "    \"BBWI\",\n",
    "    \"NWSA\",\n",
    "    \"TPR\",\n",
    "    \"PARA\",\n",
    "    \"WHR\",\n",
    "    \"BEN\",\n",
    "    \"AIZ\",\n",
    "    \"NCLH\",\n",
    "    \"GNRC\",\n",
    "    \"FRT\",\n",
    "    \"IVZ\",\n",
    "    \"VFC\",\n",
    "    \"CMA\",\n",
    "    \"DVA\",\n",
    "    \"JBL\",\n",
    "    \"HUBB\",\n",
    "    \"ZION\",\n",
    "    \"UBER\",\n",
    "    \"MHK\",\n",
    "    \"RL\",\n",
    "    \"FOX\",\n",
    "    \"BX\",\n",
    "    \"ABNB\",\n",
    "    \"NWS\",\n",
    "]\n",
    "# stk_tickers = [\n",
    "#     \"AAPL\",\n",
    "#     \"MSFT\",\n",
    "#     \"AMZN\",\n",
    "#     \"NVDA\",\n",
    "#     \"GOOGL\",\n",
    "#     \"TSLA\",\n",
    "#     \"META\",\n",
    "#     \"GOOG\",\n",
    "#     \"ADBE\",\n",
    "#     \"NFLX\",\n",
    "#     \"CSCO\",\n",
    "#     \"INTC\",\n",
    "#     \"INTU\",\n",
    "#     \"CMCSA\",\n",
    "#     \"TXN\",\n",
    "#     \"AMAT\",\n",
    "#     \"ADSK\",\n",
    "#     \"AMD\",\n",
    "#     \"QCOM\",\n",
    "#     \"MU\",\n",
    "# ]\n",
    "start = datetime(2014, 1, 1)\n",
    "end = datetime(2023, 12, 31)\n",
    "\n",
    "ticks_data = []\n",
    "for symbol in stk_symbols:\n",
    "    stk_file = f\"{data_dir}{symbol}.csv\"\n",
    "    bLoad = False\n",
    "    if os.path.isfile(stk_file):\n",
    "        try:\n",
    "            _stk_data = pd.read_csv(stk_file).set_index(\"Date\")\n",
    "            bLoad = True\n",
    "            print(f\"read {stk_file} completely!\")\n",
    "        except:\n",
    "            None\n",
    "    if bLoad == False:\n",
    "        # _stk_data = web.get_data_yahoo(stk_tickers, start, end)\n",
    "        _stk_data = yfin.download([symbol], start, end).dropna()\n",
    "        _stk_data.to_csv(stk_file)\n",
    "        print(f\"download {symbol} from yfin and write to {stk_file} completely!\")\n",
    "    ticks_data.append(_stk_data)\n",
    "    print(f\"{symbol}, size:{len(_stk_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device_name:cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device_name = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    ")\n",
    "device = torch.device(device_name)\n",
    "seq_len = 5\n",
    "validation_size = 0.2\n",
    "epoch_num = 100\n",
    "batch_size = 32\n",
    "num_workers = 3\n",
    "pin_memory = True\n",
    "shuffle = True\n",
    "print(f\"device_name:{device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pct_threshold = 0.05\n",
    "class_percentage_threshold = 0.08  # percentage threshold for class size\n",
    "classificationThreshold = 0.5\n",
    "\n",
    "\n",
    "# number of classes = 3\n",
    "# 0: PCT <= -0.05\n",
    "# 1: 0.05 < PCT < -0.05\n",
    "# 2: PCT >= -0.05\n",
    "# num_classes = 3\n",
    "\n",
    "# def gen_pct_label(stk_data, _return_period):\n",
    "#     max_price_period = (\n",
    "#         stk_data[\"Adj Close\"].rolling(_return_period).max().shift(-_return_period)\n",
    "#     )\n",
    "#     max_pct_period = (max_price_period - stk_data[\"Adj Close\"]) / stk_data[\"Adj Close\"]\n",
    "#     pct_label = max_pct_period.apply(\n",
    "#         lambda x: 2 if x >= pct_threshold else 0 if x <= -pct_threshold else 1\n",
    "#     ).astype(\"int8\")\n",
    "#     pct_label.name = \"label\"\n",
    "#     return pct_label\n",
    "\n",
    "\n",
    "# number of classes = 2\n",
    "# 0: PCT < 0.05\n",
    "# 1: PCT >= -0.05\n",
    "num_classes = 2\n",
    "\n",
    "\n",
    "def gen_pct_label(stk_data, _return_period):\n",
    "    max_price_period = (\n",
    "        stk_data[\"Adj Close\"].rolling(_return_period).max().shift(-_return_period)\n",
    "    )\n",
    "    max_pct_period = (max_price_period - stk_data[\"Adj Close\"]) / stk_data[\"Adj Close\"]\n",
    "    pct_label = max_pct_period.apply(lambda x: 1 if x >= pct_threshold else 0).astype(\n",
    "        \"int8\"\n",
    "    )\n",
    "    pct_label.name = \"label\"\n",
    "    return pct_label\n",
    "\n",
    "\n",
    "def class_percentage(analysis_data):\n",
    "    stat = analysis_data.groupby(\"label\").size()\n",
    "    total = len(analysis_data)\n",
    "    p = []\n",
    "    for i in range(num_classes):\n",
    "        p.append(stat[i] / total if i in stat.index else 0.0)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_buy_sell_signal(stk_data):\n",
    "    import pandas_ta as ta\n",
    "\n",
    "    sma = pd.concat(\n",
    "        [\n",
    "            stk_data.ta.sma(close=\"Adj Close\", length=10),\n",
    "            stk_data.ta.sma(close=\"Adj Close\", length=60),\n",
    "        ],\n",
    "        axis=1,\n",
    "    ).dropna()\n",
    "    buy_signal = sma[\"SMA_10\"] > sma[\"SMA_60\"]\n",
    "\n",
    "    buy_sell_signal = stk_data[[]].copy()\n",
    "    buy_sell_signal[\"Signal\"] = (buy_signal).astype(\"int\")\n",
    "\n",
    "    return buy_sell_signal\n",
    "\n",
    "\n",
    "def gen_analysis_data(stk_data, _return_period):\n",
    "    import pandas_ta as ta\n",
    "\n",
    "    data = pd.concat(\n",
    "        [\n",
    "            stk_data.ta.adosc(),\n",
    "            stk_data.ta.kvo(),\n",
    "            stk_data.ta.rsi(close=\"Adj Close\", length=10) / 100,\n",
    "            stk_data.ta.rsi(close=\"Adj Close\", length=30) / 100,\n",
    "            stk_data.ta.rsi(close=\"Adj Close\", length=200) / 100,\n",
    "            stk_data.ta.stoch(k=10) / 100,\n",
    "            stk_data.ta.stoch(k=30) / 100,\n",
    "            stk_data.ta.stoch(k=200) / 100,\n",
    "            gen_buy_sell_signal(stk_data),\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    data = pd.concat(\n",
    "        [data.astype(\"float32\"), gen_pct_label(stk_data, _return_period)],\n",
    "        axis=1,\n",
    "    ).dropna()\n",
    "    return data\n",
    "\n",
    "\n",
    "def prepare_dataset(_return_period, verbose=False):\n",
    "    from tqdm import tqdm\n",
    "\n",
    "    ticks_dataset = []\n",
    "    ignore_ticks_data_count = 0\n",
    "    for i, tick_data in enumerate(tqdm(ticks_data)):\n",
    "        analysis_data = gen_analysis_data(tick_data, _return_period)\n",
    "        classes_percentage = class_percentage(analysis_data)\n",
    "        if 0 in classes_percentage:\n",
    "            if verbose:\n",
    "                print(\n",
    "                    f\"Some classes don't have any data  : {stk_symbols[i]}, {classes_percentage}\"\n",
    "                )\n",
    "            ignore_ticks_data_count += 1\n",
    "        elif any(p < class_percentage_threshold for p in classes_percentage):\n",
    "            if verbose:\n",
    "                print(\n",
    "                    f\"Some classes are too small  : {stk_symbols[i]}, {classes_percentage}\"\n",
    "                )\n",
    "            ignore_ticks_data_count += 1\n",
    "        else:\n",
    "            ticks_dataset.append(analysis_data)\n",
    "    if ignore_ticks_data_count > 0:\n",
    "        print(\n",
    "            f\"There are {ignore_ticks_data_count} stocks in total, some classes have no data or are too small\"\n",
    "        )\n",
    "    return ticks_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some classes are too small  : JNJ, [0.975789018590575, 0.02421098140942499]\n",
      "Some classes are too small  : V, [0.9295287505404237, 0.07047124945957631]\n",
      "Some classes are too small  : PG, [0.9775183744055339, 0.02248162559446606]\n",
      "Some classes are too small  : HD, [0.9303934284479032, 0.06960657155209685]\n",
      "Some classes are too small  : MRK, [0.9463899697362732, 0.05361003026372676]\n",
      "Some classes are too small  : PEP, [0.9818417639429312, 0.018158236057068743]\n",
      "Some classes are too small  : COST, [0.9364461738002594, 0.06355382619974059]\n",
      "Some classes are too small  : KO, [0.9783830523130134, 0.021616947686986597]\n",
      "Some classes are too small  : CSCO, [0.9286640726329443, 0.07133592736705577]\n",
      "Some classes are too small  : WMT, [0.9485516645049719, 0.0514483354950281]\n",
      "Some classes are too small  : MCD, [0.958063121487246, 0.041936878512753996]\n",
      "Some classes are too small  : PFE, [0.9217466493731085, 0.07825335062689148]\n",
      "Some classes are too small  : ACN, [0.9286640726329443, 0.07133592736705577]\n",
      "Some classes are too small  : CMCSA, [0.9381755296152183, 0.06182447038478167]\n",
      "Some classes are too small  : LIN, [0.9347168179853005, 0.06528318201469953]\n",
      "Some classes are too small  : ABT, [0.9334198011240813, 0.06658019887591872]\n",
      "Some classes are too small  : DHR, [0.9217466493731085, 0.07825335062689148]\n",
      "Some classes are too small  : PM, [0.9442282749675746, 0.055771725032425425]\n",
      "Some classes are too small  : VZ, [0.9619541720709036, 0.03804582792909641]\n",
      "Some classes are too small  : NEE, [0.9407695633376567, 0.059230436662343275]\n",
      "Some classes are too small  : IBM, [0.9386078685689581, 0.061392131431041934]\n",
      "Some classes are too small  : BMY, [0.9342844790315608, 0.06571552096843926]\n",
      "Some classes are too small  : SPGI, [0.9200172935581495, 0.0799827064418504]\n",
      "Some classes are too small  : RTX, [0.929096411586684, 0.07090358841331604]\n",
      "Some classes are too small  : HON, [0.9424989191526156, 0.057501080847384346]\n",
      "Some classes are too small  : UPS, [0.9273670557717251, 0.07263294422827497]\n",
      "Some classes are too small  : SBUX, [0.9200172935581495, 0.0799827064418504]\n",
      "Some classes are too small  : MDT, [0.9386078685689581, 0.061392131431041934]\n",
      "Some classes are too small  : ADP, [0.9446606139213143, 0.05533938607868569]\n",
      "Some classes are too small  : LMT, [0.9420665801988759, 0.057933419801124084]\n",
      "Some classes are too small  : T, [0.9351491569390402, 0.0648508430609598]\n",
      "Some classes are too small  : MDLZ, [0.9546044098573282, 0.04539559014267185]\n",
      "Some classes are too small  : MMC, [0.9641158668396023, 0.03588413316039775]\n",
      "Some classes are too small  : SYK, [0.9234760051880675, 0.07652399481193256]\n",
      "Some classes are too small  : CB, [0.9433635970600951, 0.056636402939904885]\n",
      "Some classes are too small  : AMT, [0.9247730220492867, 0.07522697795071336]\n",
      "Some classes are too small  : BDX, [0.9420665801988759, 0.057933419801124084]\n",
      "Some classes are too small  : MO, [0.9489840034587116, 0.05101599654128837]\n",
      "Some classes are too small  : PGR, [0.924340683095547, 0.07565931690445309]\n",
      "Some classes are too small  : FI, [0.9239083441418072, 0.07609165585819282]\n",
      "Some classes are too small  : SO, [0.9680069174232598, 0.03199308257674016]\n",
      "Some classes are too small  : CME, [0.9295287505404237, 0.07047124945957631]\n",
      "Some classes are too small  : DUK, [0.9723303069606571, 0.027669693039342844]\n",
      "Some classes are too small  : AON, [0.9455252918287937, 0.054474708171206226]\n",
      "Some classes are too small  : ITW, [0.9299610894941635, 0.07003891050583658]\n",
      "Some classes are too small  : ICE, [0.93558149589278, 0.06441850410722005]\n",
      "Some classes are too small  : NOC, [0.9247730220492867, 0.07522697795071336]\n",
      "Some classes are too small  : CL, [0.9680069174232598, 0.03199308257674016]\n",
      "Some classes are too small  : WM, [0.9593601383484652, 0.040639861651534805]\n",
      "Some classes are too small  : MMM, [0.9360138348465197, 0.06398616515348032]\n",
      "Some classes are too small  : ROP, [0.9442282749675746, 0.055771725032425425]\n",
      "Some classes are too small  : APH, [0.9265023778642456, 0.07349762213575443]\n",
      "Some classes are too small  : GD, [0.9433635970600951, 0.056636402939904885]\n",
      "Some classes are too small  : AJG, [0.9502810203199308, 0.04971897968006917]\n",
      "Some classes are too small  : GBP, [0.9970449172576832, 0.002955082742316785]\n",
      "Some classes are too small  : SRE, [0.9537397319498487, 0.04626026805015132]\n",
      "Some classes are too small  : ECL, [0.9381755296152183, 0.06182447038478167]\n",
      "Some classes are too small  : KMB, [0.9623865110246433, 0.03761348897535668]\n",
      "Some classes are too small  : PSA, [0.9299610894941635, 0.07003891050583658]\n",
      "Some classes are too small  : CCI, [0.9265023778642456, 0.07349762213575443]\n",
      "Some classes are too small  : STZ, [0.922611327280588, 0.07738867271941202]\n",
      "Some classes are too small  : AFL, [0.9364461738002594, 0.06355382619974059]\n",
      "Some classes are too small  : AEP, [0.9623865110246433, 0.03761348897535668]\n",
      "Some classes are too small  : D, [0.9628188499783831, 0.03718115002161695]\n",
      "Some classes are too small  : GIS, [0.9468223086900129, 0.05317769130998703]\n",
      "Some classes are too small  : EXC, [0.9373108517077389, 0.06268914829226113]\n",
      "Some classes are too small  : PAYX, [0.9399048854301773, 0.06009511456982274]\n",
      "Some classes are too small  : O, [0.9407695633376567, 0.059230436662343275]\n",
      "Some classes are too small  : TRV, [0.9459576307825335, 0.054042369217466496]\n",
      "Some classes are too small  : YUM, [0.9412019022913964, 0.058798097708603544]\n",
      "Some classes are too small  : AME, [0.9329874621703416, 0.06701253782965845]\n",
      "Some classes are too small  : OTIS, [0.9413333333333334, 0.058666666666666666]\n",
      "Some classes are too small  : VRSK, [0.9420665801988759, 0.057933419801124084]\n",
      "Some classes are too small  : HSY, [0.9559014267185474, 0.04409857328145266]\n",
      "Some classes are too small  : XEL, [0.9632511889321228, 0.03674881106787722]\n",
      "Some classes are too small  : ED, [0.9649805447470817, 0.03501945525291829]\n",
      "Some classes are too small  : PEG, [0.9476869865974924, 0.05231301340250757]\n",
      "Some classes are too small  : RSG, [0.9680069174232598, 0.03199308257674016]\n",
      "Some classes are too small  : KDP, [0.9424989191526156, 0.057501080847384346]\n",
      "Some classes are too small  : ACGL, [0.9265023778642456, 0.07349762213575443]\n",
      "Some classes are too small  : ALL, [0.9407695633376567, 0.059230436662343275]\n",
      "Some classes are too small  : AWK, [0.9463899697362732, 0.05361003026372676]\n",
      "Some classes are too small  : KHC, [0.9229974160206719, 0.07700258397932816]\n",
      "Some classes are too small  : WEC, [0.9636835278858625, 0.03631647211413749]\n",
      "Some classes are too small  : EIX, [0.9286640726329443, 0.07133592736705577]\n",
      "Some classes are too small  : AVB, [0.9507133592736705, 0.04928664072632944]\n",
      "Some classes are too small  : CHD, [0.9610894941634242, 0.038910505836575876]\n",
      "Some classes are too small  : HIG, [0.9325551232166018, 0.06744487678339818]\n",
      "Some classes are too small  : ES, [0.949848681366191, 0.05015131863380891]\n",
      "Some classes are too small  : EQR, [0.9386078685689581, 0.061392131431041934]\n",
      "Some classes are too small  : WTW, [0.9412019022913964, 0.058798097708603544]\n",
      "Some classes are too small  : DTE, [0.959792477302205, 0.040207522697795074]\n",
      "Some classes are too small  : GPC, [0.9247730220492867, 0.07522697795071336]\n",
      "Some classes are too small  : BR, [0.9364461738002594, 0.06355382619974059]\n",
      "Some classes are too small  : BAX, [0.9381755296152183, 0.06182447038478167]\n",
      "Some classes are too small  : AEE, [0.9563337656722871, 0.043666234327712924]\n",
      "Some classes are too small  : MKC, [0.949848681366191, 0.05015131863380891]\n",
      "Some classes are too small  : ETR, [0.958063121487246, 0.041936878512753996]\n",
      "Some classes are too small  : FE, [0.9373108517077389, 0.06268914829226113]\n",
      "Some classes are too small  : CLX, [0.9407695633376567, 0.059230436662343275]\n",
      "Some classes are too small  : LH, [0.9213143104193687, 0.07868568958063121]\n",
      "Some classes are too small  : VRSN, [0.9213143104193687, 0.07868568958063121]\n",
      "Some classes are too small  : PPL, [0.9463899697362732, 0.05361003026372676]\n",
      "Some classes are too small  : ARE, [0.9299610894941635, 0.07003891050583658]\n",
      "Some classes are too small  : NDAQ, [0.9312581063553826, 0.06874189364461739]\n",
      "Some classes are too small  : CNP, [0.9342844790315608, 0.06571552096843926]\n",
      "Some classes are too small  : EXPD, [0.9247730220492867, 0.07522697795071336]\n",
      "Some classes are too small  : BRO, [0.9442282749675746, 0.055771725032425425]\n",
      "Some classes are too small  : IEX, [0.9390402075226978, 0.0609597924773022]\n",
      "Some classes are too small  : ATO, [0.9554690877648077, 0.04453091223519239]\n",
      "Some classes are too small  : FDS, [0.9299610894941635, 0.07003891050583658]\n",
      "Some classes are too small  : MAA, [0.9316904453091224, 0.06830955469087764]\n",
      "Some classes are too small  : CMS, [0.9662775616083009, 0.03372243839169909]\n",
      "Some classes are too small  : K, [0.958063121487246, 0.041936878512753996]\n",
      "Some classes are too small  : CBOE, [0.9308257674016429, 0.06917423259835712]\n",
      "Some classes are too small  : EG, [0.9308257674016429, 0.06917423259835712]\n",
      "Some classes are too small  : ESS, [0.9329874621703416, 0.06701253782965845]\n",
      "Some classes are too small  : SJM, [0.9416342412451362, 0.058365758754863814]\n",
      "Some classes are too small  : DGX, [0.933852140077821, 0.06614785992217899]\n",
      "Some classes are too small  : CAG, [0.933852140077821, 0.06614785992217899]\n",
      "Some classes are too small  : AMCR, [0.9295287505404237, 0.07047124945957631]\n",
      "Some classes are too small  : EVRG, [0.95157803718115, 0.04842196281884998]\n",
      "Some classes are too small  : LNT, [0.9589277993947255, 0.041072200605274535]\n",
      "Some classes are too small  : WRB, [0.9407695633376567, 0.059230436662343275]\n",
      "Some classes are too small  : UDR, [0.9273670557717251, 0.07263294422827497]\n",
      "Some classes are too small  : L, [0.9377431906614786, 0.0622568093385214]\n",
      "Some classes are too small  : CPT, [0.9407695633376567, 0.059230436662343275]\n",
      "Some classes are too small  : JKHY, [0.9489840034587116, 0.05101599654128837]\n",
      "Some classes are too small  : HRL, [0.9524427150886294, 0.04755728491137051]\n",
      "Some classes are too small  : NI, [0.9494163424124513, 0.05058365758754864]\n",
      "Some classes are too small  : CHRW, [0.9213143104193687, 0.07868568958063121]\n",
      "Some classes are too small  : GL, [0.9472546476437527, 0.0527453523562473]\n",
      "Some classes are too small  : PNW, [0.9502810203199308, 0.04971897968006917]\n",
      "Some classes are too small  : CPB, [0.9334198011240813, 0.06658019887591872]\n",
      "Some classes are too small  : AIZ, [0.9247730220492867, 0.07522697795071336]\n"
     ]
    }
   ],
   "source": [
    "ttt = prepare_dataset(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8767833981841764, 0.12321660181582361]\n"
     ]
    }
   ],
   "source": [
    "def class_percentage(stk_data):\n",
    "    stat = stk_data.groupby(\"label\").size()\n",
    "    total = len(stk_data)\n",
    "    p = []\n",
    "    for i in range(num_classes):\n",
    "        p.append(stat[i] / total if i in stat.index else 0.0)\n",
    "    return p\n",
    "\n",
    "\n",
    "r = class_percentage(gen_analysis_data(ticks_data[0], return_period))\n",
    "\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   AAPL  MSFT  AMZN  NVDA  GOOGL  GOOG  META  TSLA   UNH   LLY   JPM   XOM   JNJ     V    PG  AVGO    MA    HD   CVX   MRK  ABBV   PEP  COST  ADBE    KO  CSCO   WMT   TMO   MCD   PFE   CRM   BAC   ACN  CMCSA   LIN  NFLX   ABT  ORCL   DHR   AMD   WFC   DIS   TXN    PM    VZ  INTU   COP   CAT  AMGN   NEE  INTC   UNP   LOW   IBM   BMY  SPGI   RTX   HON    BA   UPS    GE  QCOM  AMAT   NKE   PLD   NOW  BKNG  SBUX    MS   ELV   MDT    GS    DE   ADP   LMT   TJX     T   BLK  ISRG  MDLZ  GILD   MMC   AXP   SYK  REGN  VRTX   ETN  LRCX   ADI  SCHW   CVS   ZTS    CI    CB   AMT   SLB     C   BDX    MO   PGR  TMUS    FI    SO   EOG   BSX   CME  EQIX    MU   DUK  PANW  PYPL   AON  SNPS   ITW  KLAC  LULU   ICE   APD   SHW  CDNS   CSX   NOC    CL   MPC   HUM   FDX    WM   MCK   TGT  ORLY   HCA   FCX   EMR   PXD   MMM   MCO   ROP   CMG   PSX   MAR    PH   APH    GD   USB  NXPI   AJG   NSC   PNC   VLO   GBP     F   MSI    GM    TT    EW  CARR   AZO  ADSK   TDG  ANET   SRE   ECL   OXY  PCAR   ADM  MNST   KMB   PSA   CCI  CHTR  MCHP  MSCI  CTAS   WMB   AIG   STZ   HES   NUE  ROST   AFL   AEP  IDXX     D   TEL   JCI   MET   GIS   IQV   EXC  WELL  DXCM   HLT    ON   COF  PAYX   TFC   USD  BIIB     O  FTNT  DOW   TRV   DLR  MRNA  CPRT  ODFL   DHI   YUM   SPG  CTSH   AME   BKR   SYY     A  CTVA   CNC    EL   AMP  CEG   HAL  OTIS   ROK   PRU    DD   KMI  VRSK   LHX    DG   FIS   CMI  CSGP  FAST   PPG   GPN   GWW   HSY    BK   XEL   DVN    EA   NEM    ED   URI  VICI   PEG    KR   RSG   LEN   PWR   WST   COR   OKE   VMC   KDP   WBD  ACGL   ALL    IR   CDW  FANG   MLM   PCG   DAL   EXR   FTV   AWK    IT   KHC  GEHC   WEC   HPQ   EIX  CBRE  APTV  ANSS   MTD  DLTR   AVB  ILMN  ALGN   LYB  TROW   GLW   EFX    WY   ZBH   XYL  SBAC   RMD  TSCO  EBAY  KEYS   CHD   STT   DFS   HIG   ALB   STE    ES  TTWO  MPWR   CAH   EQR   RCL   WTW   HPE   DTE   GPC    BR  ULTA  FICO  CTRA   BAX   AEE   MTB   MKC   ETR   WAB   DOV    FE   RJF  INVH   FLT   CLX   TDY  TRGP   DRI    LH  HOLX  VRSN   MOH   LUV   PPL   ARE   NVR   COO   WBA   PHM  NDAQ   HWM    RF   CNP   IRM   LVS  FITB  EXPD   VTR  FSLR   PFG   BRO     J   IEX    BG   ATO   FDS  ENPH   MAA   CMS   IFF  BALL  SWKS  CINF  NTAP  STLD   UAL   WAT   OMC   TER   CCL  JBHT   MRO   TYL  HBAN     K  GRMN  CBOE  NTRS   TSN  AKAM    EG   ESS   EQT   TXT  EXPE   SJM   PTC   DGX   AVY  RVTY   BBY    CF   CAG  EPAM  AMCR    LW  PAYC   SNA  AXON  POOL   SYF   SWK  ZBRA   DPZ   PKG   CFG  LDOS  VTRS  PODD   LKQ   MOS   APA  EVRG  TRMB   MGM  NDSN   WDC   MAS   LNT   IPG  MTCH   STX   KMX  TECH   WRB   LYV    IP   UDR   AES    CE  INCY     L   TAP   GEN   CPT   KIM  JKHY   HRL   HST   FMC   CZR  PEAK  CDAY   PNR    NI  CHRW  HSIC   CRL   REG  QRVO   TFX   KEY    GL   EMN  WYNN  ALLE   AAL  FFIV   BWA   BXP  MKTX   ROL  JNPR   PNW  ETSY  BLDR  FOXA   AOS   HAS   HII   NRG   CPB   UHS   BIO   WRK   RHI  CTLT  XRAY  BBWI  NWSA   TPR  PARA   WHR   BEN   AIZ  NCLH  GNRC   FRT   IVZ   VFC   CMA   DVA   JBL  HUBB  ZION  UBER   MHK    RL  FOX    BX  ABNB   NWS\n",
      "0  2028  2099  1943  1606   2078  2066  1932  1530  2100  2052  2113  2058  2257  2150  2261  1898  2111  2152  2082  2189  2091  2271  2166  1970  2263  2148  2194  2111  2216  2132  1968  2001  2148   2170  2162  1761  2159  2121  2132  1424  2051  2112  2093  2184  2225  1991  1855  1954  2109  2176  1992  2088  2038  2171  2161  2128  2149  2180  1920  2145  1957  1953  1804  2059  2109  1826  1944  2128  1982  2054  2171  2038  1991  2185  2179  2105  2163  2076  1997  2208  2116  2230  2068  2136  1918  1930  2075  1769  1998  1929  2081  2106  2051  2182  2139  1874  2018  2179  2195  2138  2079  2137  2239  1798  2085  2150  2071  1631  2249  1869  1592  2187  2024  2151  1867  1816  2164  2127  2113  1985  2070  2139  2239  1820  2027  2024  2219  2059  2040  2105  2004  1557  2097  1804  2165  2117  2184  1951  1952  1997  2023  2143  2182  2102  1848  2198  2066  2066  1851  1687  1925  2119  1896  2051  2000   616  2111  1890  2032  1694  2206  2170  1889  2073  2125  2082  2226  2151  2143  2011  1861  2007  2100  1976  2065  2134  1696  1867  2059  2166  2226  1975  2227  2078  2103  2075  2190  2033  2168  2090  1699  1994  1657  1974  2174  2033  1391  2009  2176  1864  816  2188  2069   623  2071  1971  1931  2177  2051  2087  2158  1808  2125  2084   804  1931  2049  2031  248  1763   706  2039  2075  2043  2065  2179  2126  2126  2105  2080  2009  2097  2096  1982  2064  2211  2089  2228  1652  2033  1878  2232  1736  1167  2192  2069  2239  1924  1959  2034  2073  1869  1994  2180  1803  2143  2176  1202  2045  1716  1960  1949  1862  2084  1523  2189  2084  1786    45  2229  1973  2148  2002  1875  2027  2076  2034  2199  1850  1743  1949  2090  2059  2053  2021  2120  2102  2103  2079  2013  1997  1830  2223  1989  1985  2157  1734  2111  2197  1894  1804  2076  2171  1774  2177  1553  2220  2139  2166  1959  1974  1850  2170  2212  2048  2197  2216  1982  2075  2168  2000  1411  2012  2176  2099  1751  2033  2131  2085  2131  1884  1942  2189  2151  2062  2094  2045  1920  2154  1283  1935  2161  2069  1845  1956  2139  2060  1667  2041  2184  2040  2172  2038  2210  2151  1281  2155  2235  2094  2084  1842  2117  1950  1766  1764  2087  2110  1840  1830  2069  1637  2055  1982  2216  2112  2153  2027  2090  2060  2153  2158  1703  2016  1897  2178  1981  2160  2094  2039  1897  1746  2160  1831  2150  1385  1680  2101  1688  2022  1809  2022  1871  2044  2079  1744  2070  1916  1772  2059  1745  1635  2201  2000  1821  2103  1734  2047  2218  2012  1664  1845  1899  2022  2176  1934  2058  2145  1979  1988  1855  2169  2061  2018  2176  2021  2195  2203  1983  2003  1468  2097   904  2051  2196  2131  2116  1983  2111  1637  2044  1935  2191  2007  1700  2099  1712  2079  1898  2072  1919  2089  2065  2198  1300  1647   840  2067  2022  2073  1875  2159  2021  2037  1608  2028  1728  2067  1773  2021  1874  1868  1963  2010  2139  1732  1770  2124  1917  2003  1881  2007  1911  2081  1892   653  1952  1871  853  1883   385  2026\n",
      "1   285   214   370   707    235   247   381   783   213   261   200   255    56   163    52   415   202   161   231   124   222    42   147   343    50   165   119   202    97   181   345   312   165    143   151   552   154   192   181   889   262   201   220   129    88   322   458   359   204   137   321   225   275   142   152   185   164   133   393   168   356   360   509   254   204   487   369   185   331   259   142   275   322   128   134   208   150   237   316   105   197    83   245   177   395   383   238   544   315   384   232   207   262   131   174   439   295   134   118   175   234   176    74   515   228   163   242   682    64   444   343   126   289   162   446   497   149   186   200   328   243   174    74   493   286   289    94   254   273   208   309   756   216   509   148   196   129   362   361   316   290   170   131   211   465   115   247   247   462     5   388   194   417   262   313   134   202   423   281   512   107   143   424   240   188   231    87   162   170   302   452   306   213   337   248   179   617   446   254   147    87   338    86   235   210   238   123   280   145   223   614   319   656   339   139   280   922   304   137   449  186   125   244   448   242   342   382   136   262   226   155   505   188   229   152   382   264   282   39   550    44   274   238   270   248   134   187   187   208   233   304   216   217   331   249   102   224    85   661   280   435    81   577   139   121   244    74   389   354   279   240   444   319   133   510   170   137   265   268   597   353   364   451   229   160   124   229   149    13    84   340   165   311   438   286   237   279   114   463   570   364   223   254   260   292   193   211   210   234   300   316   282    90   324   328   156   579   202   116   419   509   237   142   539   136   308    93   174   147   354   339   463   143   101   265   116    97   331   238   145   313   126   301   137   214   562   280   182   228   182   429   371   124   162   251   219   268   393   159   316   378   152   244   468   357   174   253   646   272   129   273   141   275   103   162  1032   158    78   219   229   471   196   363   547   549   226   203   473   483   244   676   258   331    97   201   160   286   223   253   160   155   610   297   416   135   332   153   219   274   416   567   153   482   163   207   562   212   625   291   359   291   442   269   234   386   243   397   541   254   568   678   112   313   492   210   579   266    95   301   649   468   414   291   137   379   255   168   334   325   458   144   252   295   137   292   118   110   330   310   664   216   323   262   117   182   197   330   202   424   269   378   122   306   613   214   601   234   415   241   394   224   248   115   690   666   168   246   291   240   438   154   292   276   334   285   440   246   540   292   439   445   350   303   174   581   543   189   396   310   432   306   402   232   421   313   361   442  154   430   180   287\n",
      "class 0: 87.477%, 990414\n",
      "class 1: 12.523%, 141788\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classes_df = pd.DataFrame()\n",
    "for i, stk_data in enumerate(ticks_data):\n",
    "    label_stat = gen_analysis_data(stk_data, return_period).groupby(\"label\").size()\n",
    "    label_stat.name = stk_symbols[i]\n",
    "    classes_df = pd.concat([classes_df, label_stat], axis=1)\n",
    "print(classes_df)\n",
    "classes_count = [classes_df.iloc[i].sum() for i in range(num_classes)]\n",
    "total_recs = sum(classes_count)\n",
    "for i, v in enumerate(classes_count):\n",
    "    print(f\"class {i}: {v*100/total_recs:.3f}%, {v}\")\n",
    "pyplot.bar([\"< 0.05% \", \">= 0.05%\"], classes_count)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   AAPL  MSFT  AMZN  NVDA  GOOGL  GOOG  META  TSLA   UNH   LLY   JPM   XOM   JNJ     V    PG  AVGO    MA    HD   CVX   MRK  ABBV   PEP  COST  ADBE    KO  CSCO   WMT   TMO   MCD   PFE   CRM   BAC   ACN  CMCSA   LIN  NFLX   ABT  ORCL   DHR   AMD   WFC   DIS   TXN    PM    VZ  INTU   COP   CAT  AMGN   NEE  INTC   UNP   LOW   IBM   BMY  SPGI   RTX   HON    BA   UPS    GE  QCOM  AMAT   NKE   PLD   NOW  BKNG  SBUX    MS   ELV   MDT    GS    DE   ADP   LMT   TJX     T   BLK  ISRG  MDLZ  GILD   MMC   AXP   SYK  REGN  VRTX   ETN  LRCX   ADI  SCHW   CVS   ZTS    CI    CB   AMT   SLB     C   BDX    MO   PGR  TMUS    FI    SO   EOG   BSX   CME  EQIX    MU   DUK  PANW  PYPL   AON  SNPS   ITW  KLAC  LULU   ICE   APD   SHW  CDNS   CSX   NOC    CL   MPC   HUM   FDX    WM   MCK   TGT  ORLY   HCA   FCX   EMR   PXD   MMM   MCO   ROP   CMG   PSX   MAR    PH   APH    GD   USB  NXPI   AJG   NSC   PNC   VLO   GBP     F   MSI    GM    TT    EW  CARR   AZO  ADSK   TDG  ANET   SRE   ECL   OXY  PCAR   ADM  MNST   KMB   PSA   CCI  CHTR  MCHP  MSCI  CTAS   WMB   AIG   STZ   HES   NUE  ROST   AFL   AEP  IDXX     D   TEL   JCI   MET   GIS   IQV   EXC  WELL  DXCM   HLT    ON   COF  PAYX   TFC   USD  BIIB     O  FTNT  DOW   TRV   DLR  MRNA  CPRT  ODFL   DHI   YUM   SPG  CTSH   AME   BKR   SYY     A  CTVA   CNC    EL   AMP  CEG   HAL  OTIS   ROK   PRU    DD   KMI  VRSK   LHX    DG   FIS   CMI  CSGP  FAST   PPG   GPN   GWW   HSY    BK   XEL   DVN    EA   NEM    ED   URI  VICI   PEG    KR   RSG   LEN   PWR   WST   COR   OKE   VMC   KDP   WBD  ACGL   ALL    IR   CDW  FANG   MLM   PCG   DAL   EXR   FTV   AWK    IT   KHC  GEHC   WEC   HPQ   EIX  CBRE  APTV  ANSS   MTD  DLTR   AVB  ILMN  ALGN   LYB  TROW   GLW   EFX    WY   ZBH   XYL  SBAC   RMD  TSCO  EBAY  KEYS   CHD   STT   DFS   HIG   ALB   STE    ES  TTWO  MPWR   CAH   EQR   RCL   WTW   HPE   DTE   GPC    BR  ULTA  FICO  CTRA   BAX   AEE   MTB   MKC   ETR   WAB   DOV    FE   RJF  INVH   FLT   CLX   TDY  TRGP   DRI    LH  HOLX  VRSN   MOH   LUV   PPL   ARE   NVR   COO   WBA   PHM  NDAQ   HWM    RF   CNP   IRM   LVS  FITB  EXPD   VTR  FSLR   PFG   BRO     J   IEX    BG   ATO   FDS  ENPH   MAA   CMS   IFF  BALL  SWKS  CINF  NTAP  STLD   UAL   WAT   OMC   TER   CCL  JBHT   MRO   TYL  HBAN     K  GRMN  CBOE  NTRS   TSN  AKAM    EG   ESS   EQT   TXT  EXPE   SJM   PTC   DGX   AVY  RVTY   BBY    CF   CAG  EPAM  AMCR    LW  PAYC   SNA  AXON  POOL   SYF   SWK  ZBRA   DPZ   PKG   CFG  LDOS  VTRS  PODD   LKQ   MOS   APA  EVRG  TRMB   MGM  NDSN   WDC   MAS   LNT   IPG  MTCH   STX   KMX  TECH   WRB   LYV    IP   UDR   AES    CE  INCY     L   TAP   GEN   CPT   KIM  JKHY   HRL   HST   FMC   CZR  PEAK  CDAY   PNR    NI  CHRW  HSIC   CRL   REG  QRVO   TFX   KEY    GL   EMN  WYNN  ALLE   AAL  FFIV   BWA   BXP  MKTX   ROL  JNPR   PNW  ETSY  BLDR  FOXA   AOS   HAS   HII   NRG   CPB   UHS   BIO   WRK   RHI  CTLT  XRAY  BBWI  NWSA   TPR  PARA   WHR   BEN   AIZ  NCLH  GNRC   FRT   IVZ   VFC   CMA   DVA   JBL  HUBB  ZION  UBER   MHK    RL  FOX    BX  ABNB   NWS\n",
      "0  2028  2099  1943  1606   2078  2066  1932  1530  2100  2052  2113  2058  2257  2150  2261  1898  2111  2152  2082  2189  2091  2271  2166  1970  2263  2148  2194  2111  2216  2132  1968  2001  2148   2170  2162  1761  2159  2121  2132  1424  2051  2112  2093  2184  2225  1991  1855  1954  2109  2176  1992  2088  2038  2171  2161  2128  2149  2180  1920  2145  1957  1953  1804  2059  2109  1826  1944  2128  1982  2054  2171  2038  1991  2185  2179  2105  2163  2076  1997  2208  2116  2230  2068  2136  1918  1930  2075  1769  1998  1929  2081  2106  2051  2182  2139  1874  2018  2179  2195  2138  2079  2137  2239  1798  2085  2150  2071  1631  2249  1869  1592  2187  2024  2151  1867  1816  2164  2127  2113  1985  2070  2139  2239  1820  2027  2024  2219  2059  2040  2105  2004  1557  2097  1804  2165  2117  2184  1951  1952  1997  2023  2143  2182  2102  1848  2198  2066  2066  1851  1687  1925  2119  1896  2051  2000   616  2111  1890  2032  1694  2206  2170  1889  2073  2125  2082  2226  2151  2143  2011  1861  2007  2100  1976  2065  2134  1696  1867  2059  2166  2226  1975  2227  2078  2103  2075  2190  2033  2168  2090  1699  1994  1657  1974  2174  2033  1391  2009  2176  1864  816  2188  2069   623  2071  1971  1931  2177  2051  2087  2158  1808  2125  2084   804  1931  2049  2031  248  1763   706  2039  2075  2043  2065  2179  2126  2126  2105  2080  2009  2097  2096  1982  2064  2211  2089  2228  1652  2033  1878  2232  1736  1167  2192  2069  2239  1924  1959  2034  2073  1869  1994  2180  1803  2143  2176  1202  2045  1716  1960  1949  1862  2084  1523  2189  2084  1786    45  2229  1973  2148  2002  1875  2027  2076  2034  2199  1850  1743  1949  2090  2059  2053  2021  2120  2102  2103  2079  2013  1997  1830  2223  1989  1985  2157  1734  2111  2197  1894  1804  2076  2171  1774  2177  1553  2220  2139  2166  1959  1974  1850  2170  2212  2048  2197  2216  1982  2075  2168  2000  1411  2012  2176  2099  1751  2033  2131  2085  2131  1884  1942  2189  2151  2062  2094  2045  1920  2154  1283  1935  2161  2069  1845  1956  2139  2060  1667  2041  2184  2040  2172  2038  2210  2151  1281  2155  2235  2094  2084  1842  2117  1950  1766  1764  2087  2110  1840  1830  2069  1637  2055  1982  2216  2112  2153  2027  2090  2060  2153  2158  1703  2016  1897  2178  1981  2160  2094  2039  1897  1746  2160  1831  2150  1385  1680  2101  1688  2022  1809  2022  1871  2044  2079  1744  2070  1916  1772  2059  1745  1635  2201  2000  1821  2103  1734  2047  2218  2012  1664  1845  1899  2022  2176  1934  2058  2145  1979  1988  1855  2169  2061  2018  2176  2021  2195  2203  1983  2003  1468  2097   904  2051  2196  2131  2116  1983  2111  1637  2044  1935  2191  2007  1700  2099  1712  2079  1898  2072  1919  2089  2065  2198  1300  1647   840  2067  2022  2073  1875  2159  2021  2037  1608  2028  1728  2067  1773  2021  1874  1868  1963  2010  2139  1732  1770  2124  1917  2003  1881  2007  1911  2081  1892   653  1952  1871  853  1883   385  2026\n",
      "1   285   214   370   707    235   247   381   783   213   261   200   255    56   163    52   415   202   161   231   124   222    42   147   343    50   165   119   202    97   181   345   312   165    143   151   552   154   192   181   889   262   201   220   129    88   322   458   359   204   137   321   225   275   142   152   185   164   133   393   168   356   360   509   254   204   487   369   185   331   259   142   275   322   128   134   208   150   237   316   105   197    83   245   177   395   383   238   544   315   384   232   207   262   131   174   439   295   134   118   175   234   176    74   515   228   163   242   682    64   444   343   126   289   162   446   497   149   186   200   328   243   174    74   493   286   289    94   254   273   208   309   756   216   509   148   196   129   362   361   316   290   170   131   211   465   115   247   247   462     5   388   194   417   262   313   134   202   423   281   512   107   143   424   240   188   231    87   162   170   302   452   306   213   337   248   179   617   446   254   147    87   338    86   235   210   238   123   280   145   223   614   319   656   339   139   280   922   304   137   449  186   125   244   448   242   342   382   136   262   226   155   505   188   229   152   382   264   282   39   550    44   274   238   270   248   134   187   187   208   233   304   216   217   331   249   102   224    85   661   280   435    81   577   139   121   244    74   389   354   279   240   444   319   133   510   170   137   265   268   597   353   364   451   229   160   124   229   149    13    84   340   165   311   438   286   237   279   114   463   570   364   223   254   260   292   193   211   210   234   300   316   282    90   324   328   156   579   202   116   419   509   237   142   539   136   308    93   174   147   354   339   463   143   101   265   116    97   331   238   145   313   126   301   137   214   562   280   182   228   182   429   371   124   162   251   219   268   393   159   316   378   152   244   468   357   174   253   646   272   129   273   141   275   103   162  1032   158    78   219   229   471   196   363   547   549   226   203   473   483   244   676   258   331    97   201   160   286   223   253   160   155   610   297   416   135   332   153   219   274   416   567   153   482   163   207   562   212   625   291   359   291   442   269   234   386   243   397   541   254   568   678   112   313   492   210   579   266    95   301   649   468   414   291   137   379   255   168   334   325   458   144   252   295   137   292   118   110   330   310   664   216   323   262   117   182   197   330   202   424   269   378   122   306   613   214   601   234   415   241   394   224   248   115   690   666   168   246   291   240   438   154   292   276   334   285   440   246   540   292   439   445   350   303   174   581   543   189   396   310   432   306   402   232   421   313   361   442  154   430   180   287\n"
     ]
    }
   ],
   "source": [
    "classes_df = pd.DataFrame()\n",
    "for i, stk_data in enumerate(ticks_data):\n",
    "    label_stat = gen_analysis_data(stk_data, return_period).groupby(\"label\").size()\n",
    "    label_stat.name = stk_symbols[i]\n",
    "    classes_df = pd.concat([classes_df, label_stat], axis=1)\n",
    "print(classes_df)\n",
    "# classes_count = [classes_df.iloc[i].sum() for i in range(num_classes)]\n",
    "# total_recs = sum(classes_count)\n",
    "# for i, v in enumerate(classes_count):\n",
    "#     print(f\"class {i}: {v*100/total_recs:.3f}%, {v}\")\n",
    "# pyplot.bar([\"<= -0.5%\", \" between \", \">= 0.05%\"], classes_count)\n",
    "# pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0     1  pos_%\n",
      "GBP   1687     5  0.003\n",
      "PEP   2271    42  0.018\n",
      "KO    2263    50  0.022\n",
      "PG    2261    52  0.022\n",
      "JNJ   2257    56  0.024\n",
      "...    ...   ...    ...\n",
      "ETSY  1300   690  0.347\n",
      "AMD   1424   889  0.384\n",
      "USD   1391   922  0.399\n",
      "MRNA   623   448  0.418\n",
      "ENPH  1281  1032  0.446\n",
      "\n",
      "[501 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "classes_df_t = classes_df.T\n",
    "classes_df_t[\"pos_%\"] = classes_df_t[1] / (classes_df_t[0] + classes_df_t[1])\n",
    "sorted = classes_df_t.sort_values(\"pos_%\")\n",
    "print(sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0    1  pos_%\n",
      "JNJ   2257   56  0.024\n",
      "V     2150  163  0.070\n",
      "PG    2261   52  0.022\n",
      "HD    2152  161  0.070\n",
      "MRK   2189  124  0.054\n",
      "...    ...  ...    ...\n",
      "CHRW  2131  182  0.079\n",
      "GL    2191  122  0.053\n",
      "PNW   2198  115  0.050\n",
      "CPB   2159  154  0.067\n",
      "AIZ   2139  174  0.075\n",
      "\n",
      "[135 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "too_small = classes_df_t[classes_df_t[\"pos_%\"] < stk_pos_threshold]  # 0.08\n",
    "print(too_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0    1\n",
      "AAPL   2028  285\n",
      "MSFT   2099  214\n",
      "AMZN   1943  370\n",
      "NVDA   1606  707\n",
      "GOOGL  2078  235\n",
      "...     ...  ...\n",
      "RL     1871  442\n",
      "FOX     853  154\n",
      "BX     1883  430\n",
      "ABNB    385  180\n",
      "NWS    2026  287\n",
      "\n",
      "[501 rows x 2 columns]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x20000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classes_df_t = classes_df.T\n",
    "print(classes_df_t)\n",
    "fig, ax = pyplot.subplots(figsize=(10, 200))\n",
    "# pyplot.tight_layout()\n",
    "labels = classes_df_t.index\n",
    "width = 0.4  # the width of the bars\n",
    "y = np.arange(len(labels))\n",
    "ax.barh(y + width, classes_df_t[0], width, label=\"< 0.5%\")\n",
    "ax.barh(y - width, classes_df_t[1], width, label=\">= 0.05%\")\n",
    "\n",
    "ax.legend()\n",
    "\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stk_symbols.index(\"CEG\"))\n",
    "print(stk_symbols.index(\"OTIS\"))\n",
    "print(stk_symbols.index(\"GEHC\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [0, 1, 2]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "with pd.option_context(\"display.max_rows\", None):\n",
    "    classes_df_t = classes_df.T\n",
    "    print(classes_df_t[classes_df_t.isna().any(axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "class LSTMDataSet(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        ticks_data_X,\n",
    "        ticks_data_Y,\n",
    "        _seq_len,\n",
    "    ):\n",
    "        self.ticks_data_X = ticks_data_X\n",
    "        self.ticks_data_Y = ticks_data_Y\n",
    "        self.seq_len = _seq_len\n",
    "        len_array = [len(d) - self.seq_len + 1 for d in ticks_data_X]\n",
    "        self.idx_boundary = [len_array[0]]\n",
    "\n",
    "        for i in range(1, len(len_array)):\n",
    "            self.idx_boundary.append(len_array[i] + self.idx_boundary[i - 1])\n",
    "\n",
    "        self.build_class_indices()\n",
    "        self.max_class_size = max(\n",
    "            [len(class_index) for class_index in self.class_indices]\n",
    "        )\n",
    "        # print(self.idx_boundary[-1])\n",
    "        # print(self.__len__())\n",
    "\n",
    "    def build_class_indices(self):\n",
    "        total_y = pd.concat(\n",
    "            [t[self.seq_len - 1 :][\"label\"] for t in self.ticks_data_Y]\n",
    "        ).reset_index()\n",
    "        self.class_indices = []\n",
    "        for i in range(num_classes):\n",
    "            class_idx_list = total_y.index[total_y[\"label\"] == i].tolist()\n",
    "            random.shuffle(class_idx_list)\n",
    "            self.class_indices.append(class_idx_list)\n",
    "\n",
    "    def __len__(self):\n",
    "        # print(f\"len of dataset:{self.idx_boundary[-1]}\")\n",
    "        # return self.idx_boundary[-1]  # len(self.X) - self.seq_len + 1\n",
    "        return self.max_class_size * num_classes\n",
    "\n",
    "    def idx_of_balanced_data_to_original_idx(self, idx_of_balanced_data):\n",
    "        selected_class = idx_of_balanced_data % num_classes\n",
    "        idx_of_balanced_class = idx_of_balanced_data // num_classes\n",
    "        offset_balanced_class = idx_of_balanced_class % len(\n",
    "            self.class_indices[selected_class]\n",
    "        )\n",
    "        return self.class_indices[selected_class][offset_balanced_class]\n",
    "\n",
    "    def __getitem__(self, idx_of_balanced_data):\n",
    "        idx = self.idx_of_balanced_data_to_original_idx(idx_of_balanced_data)\n",
    "\n",
    "        # print(f\"getitem, idx_of_balanced_data:{idx_of_balanced_data}, idx:{idx}\")\n",
    "        for ticks_data_idx in range(len(self.ticks_data_X)):\n",
    "            if self.idx_boundary[ticks_data_idx] > idx:\n",
    "                break\n",
    "        offset = (\n",
    "            idx if ticks_data_idx == 0 else idx - self.idx_boundary[ticks_data_idx - 1]\n",
    "        )\n",
    "        # print(f\"{ticks_data_idx}, {offset}\")\n",
    "        # print(f\"{len(self.ticks_data_Y[ticks_data_idx])}, {offset + self.seq_len - 1}\")\n",
    "        x = np.array(self.ticks_data_X[ticks_data_idx][offset : offset + self.seq_len])\n",
    "        y = int(self.ticks_data_Y[ticks_data_idx].iloc[offset + self.seq_len - 1, :])\n",
    "        # if x.shape[1] == 34:\n",
    "        #     print(f\"sssssssssssssssssssssssssss {ticks_data_idx}, {idx}\")\n",
    "        return (x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-01 17:36:30,709 INFO     pid:15618 sklearn_pandas:343:_transform [FIT_TRANSFORM] ['ADOSC_3_10']: 0.000918 secs\n",
      "2024-02-01 17:36:30,710 INFO     pid:15618 sklearn_pandas:343:_transform [FIT_TRANSFORM] ['KVO_34_55_13']: 0.000967 secs\n",
      "2024-02-01 17:36:30,712 INFO     pid:15618 sklearn_pandas:343:_transform [FIT_TRANSFORM] ['KVOs_34_55_13']: 0.000737 secs\n",
      "2024-02-01 17:36:30,715 INFO     pid:15618 sklearn_pandas:353:_transform [TRANSFORM] ['ADOSC_3_10']: 0.000341 secs\n",
      "2024-02-01 17:36:30,716 INFO     pid:15618 sklearn_pandas:353:_transform [TRANSFORM] ['KVO_34_55_13']: 0.000327 secs\n",
      "2024-02-01 17:36:30,716 INFO     pid:15618 sklearn_pandas:353:_transform [TRANSFORM] ['KVOs_34_55_13']: 0.000328 secs\n",
      "2024-02-01 17:36:30,720 INFO     pid:15618 sklearn_pandas:343:_transform [FIT_TRANSFORM] ['ADOSC_3_10']: 0.000834 secs\n",
      "2024-02-01 17:36:30,721 INFO     pid:15618 sklearn_pandas:343:_transform [FIT_TRANSFORM] ['KVO_34_55_13']: 0.000821 secs\n",
      "2024-02-01 17:36:30,723 INFO     pid:15618 sklearn_pandas:343:_transform [FIT_TRANSFORM] ['KVOs_34_55_13']: 0.00073 secs\n",
      "2024-02-01 17:36:30,726 INFO     pid:15618 sklearn_pandas:353:_transform [TRANSFORM] ['ADOSC_3_10']: 0.00038 secs\n",
      "2024-02-01 17:36:30,727 INFO     pid:15618 sklearn_pandas:353:_transform [TRANSFORM] ['KVO_34_55_13']: 0.000341 secs\n",
      "2024-02-01 17:36:30,728 INFO     pid:15618 sklearn_pandas:353:_transform [TRANSFORM] ['KVOs_34_55_13']: 0.00034 secs\n",
      "2024-02-01 17:36:30,732 INFO     pid:15618 sklearn_pandas:343:_transform [FIT_TRANSFORM] ['ADOSC_3_10']: 0.000804 secs\n",
      "2024-02-01 17:36:30,733 INFO     pid:15618 sklearn_pandas:343:_transform [FIT_TRANSFORM] ['KVO_34_55_13']: 0.000865 secs\n",
      "2024-02-01 17:36:30,734 INFO     pid:15618 sklearn_pandas:343:_transform [FIT_TRANSFORM] ['KVOs_34_55_13']: 0.000809 secs\n",
      "2024-02-01 17:36:30,737 INFO     pid:15618 sklearn_pandas:353:_transform [TRANSFORM] ['ADOSC_3_10']: 0.00036 secs\n",
      "2024-02-01 17:36:30,738 INFO     pid:15618 sklearn_pandas:353:_transform [TRANSFORM] ['KVO_34_55_13']: 0.000357 secs\n",
      "2024-02-01 17:36:30,739 INFO     pid:15618 sklearn_pandas:353:_transform [TRANSFORM] ['KVOs_34_55_13']: 0.000325 secs\n",
      "2024-02-01 17:36:30,743 INFO     pid:15618 sklearn_pandas:343:_transform [FIT_TRANSFORM] ['ADOSC_3_10']: 0.000818 secs\n",
      "2024-02-01 17:36:30,744 INFO     pid:15618 sklearn_pandas:343:_transform [FIT_TRANSFORM] ['KVO_34_55_13']: 0.00084 secs\n",
      "2024-02-01 17:36:30,745 INFO     pid:15618 sklearn_pandas:343:_transform [FIT_TRANSFORM] ['KVOs_34_55_13']: 0.000847 secs\n",
      "2024-02-01 17:36:30,748 INFO     pid:15618 sklearn_pandas:353:_transform [TRANSFORM] ['ADOSC_3_10']: 0.000364 secs\n",
      "2024-02-01 17:36:30,749 INFO     pid:15618 sklearn_pandas:353:_transform [TRANSFORM] ['KVO_34_55_13']: 0.000335 secs\n",
      "2024-02-01 17:36:30,750 INFO     pid:15618 sklearn_pandas:353:_transform [TRANSFORM] ['KVOs_34_55_13']: 0.000343 secs\n",
      "2024-02-01 17:36:30,754 INFO     pid:15618 sklearn_pandas:343:_transform [FIT_TRANSFORM] ['ADOSC_3_10']: 0.000874 secs\n",
      "2024-02-01 17:36:30,755 INFO     pid:15618 sklearn_pandas:343:_transform [FIT_TRANSFORM] ['KVO_34_55_13']: 0.000829 secs\n",
      "2024-02-01 17:36:30,756 INFO     pid:15618 sklearn_pandas:343:_transform [FIT_TRANSFORM] ['KVOs_34_55_13']: 0.000837 secs\n",
      "2024-02-01 17:36:30,760 INFO     pid:15618 sklearn_pandas:353:_transform [TRANSFORM] ['ADOSC_3_10']: 0.000353 secs\n",
      "2024-02-01 17:36:30,760 INFO     pid:15618 sklearn_pandas:353:_transform [TRANSFORM] ['KVO_34_55_13']: 0.000344 secs\n",
      "2024-02-01 17:36:30,761 INFO     pid:15618 sklearn_pandas:353:_transform [TRANSFORM] ['KVOs_34_55_13']: 0.000323 secs\n",
      "2024-02-01 17:36:30,765 INFO     pid:15618 sklearn_pandas:343:_transform [FIT_TRANSFORM] ['ADOSC_3_10']: 0.000815 secs\n",
      "2024-02-01 17:36:30,766 INFO     pid:15618 sklearn_pandas:343:_transform [FIT_TRANSFORM] ['KVO_34_55_13']: 0.000769 secs\n",
      "2024-02-01 17:36:30,767 INFO     pid:15618 sklearn_pandas:343:_transform [FIT_TRANSFORM] ['KVOs_34_55_13']: 0.000832 secs\n",
      "2024-02-01 17:36:30,770 INFO     pid:15618 sklearn_pandas:353:_transform [TRANSFORM] ['ADOSC_3_10']: 0.000344 secs\n",
      "2024-02-01 17:36:30,771 INFO     pid:15618 sklearn_pandas:353:_transform [TRANSFORM] ['KVO_34_55_13']: 0.000326 secs\n",
      "2024-02-01 17:36:30,772 INFO     pid:15618 sklearn_pandas:353:_transform [TRANSFORM] ['KVOs_34_55_13']: 0.000328 secs\n",
      "2024-02-01 17:36:30,776 INFO     pid:15618 sklearn_pandas:343:_transform [FIT_TRANSFORM] ['ADOSC_3_10']: 0.00081 secs\n",
      "2024-02-01 17:36:30,777 INFO     pid:15618 sklearn_pandas:343:_transform [FIT_TRANSFORM] ['KVO_34_55_13']: 0.000764 secs\n",
      "2024-02-01 17:36:30,778 INFO     pid:15618 sklearn_pandas:343:_transform [FIT_TRANSFORM] ['KVOs_34_55_13']: 0.000875 secs\n",
      "2024-02-01 17:36:30,781 INFO     pid:15618 sklearn_pandas:353:_transform [TRANSFORM] ['ADOSC_3_10']: 0.000362 secs\n",
      "2024-02-01 17:36:30,782 INFO     pid:15618 sklearn_pandas:353:_transform [TRANSFORM] ['KVO_34_55_13']: 0.000505 secs\n",
      "2024-02-01 17:36:30,784 INFO     pid:15618 sklearn_pandas:353:_transform [TRANSFORM] ['KVOs_34_55_13']: 0.000765 secs\n",
      "2024-02-01 17:36:30,792 INFO     pid:15618 sklearn_pandas:343:_transform [FIT_TRANSFORM] ['ADOSC_3_10']: 0.001011 secs\n",
      "2024-02-01 17:36:30,794 INFO     pid:15618 sklearn_pandas:343:_transform [FIT_TRANSFORM] ['KVO_34_55_13']: 0.000836 secs\n",
      "2024-02-01 17:36:30,795 INFO     pid:15618 sklearn_pandas:343:_transform [FIT_TRANSFORM] ['KVOs_34_55_13']: 0.000772 secs\n",
      "2024-02-01 17:36:30,800 INFO     pid:15618 sklearn_pandas:353:_transform [TRANSFORM] ['ADOSC_3_10']: 0.000397 secs\n",
      "2024-02-01 17:36:30,800 INFO     pid:15618 sklearn_pandas:353:_transform [TRANSFORM] ['KVO_34_55_13']: 0.000373 secs\n",
      "2024-02-01 17:36:30,801 INFO     pid:15618 sklearn_pandas:353:_transform [TRANSFORM] ['KVOs_34_55_13']: 0.000403 secs\n",
      "2024-02-01 17:36:30,806 INFO     pid:15618 sklearn_pandas:343:_transform [FIT_TRANSFORM] ['ADOSC_3_10']: 0.000905 secs\n",
      "2024-02-01 17:36:30,807 INFO     pid:15618 sklearn_pandas:343:_transform [FIT_TRANSFORM] ['KVO_34_55_13']: 0.000768 secs\n",
      "2024-02-01 17:36:30,808 INFO     pid:15618 sklearn_pandas:343:_transform [FIT_TRANSFORM] ['KVOs_34_55_13']: 0.000747 secs\n",
      "2024-02-01 17:36:30,811 INFO     pid:15618 sklearn_pandas:353:_transform [TRANSFORM] ['ADOSC_3_10']: 0.000357 secs\n",
      "2024-02-01 17:36:30,812 INFO     pid:15618 sklearn_pandas:353:_transform [TRANSFORM] ['KVO_34_55_13']: 0.000376 secs\n",
      "2024-02-01 17:36:30,813 INFO     pid:15618 sklearn_pandas:353:_transform [TRANSFORM] ['KVOs_34_55_13']: 0.000328 secs\n",
      "2024-02-01 17:36:30,816 INFO     pid:15618 sklearn_pandas:343:_transform [FIT_TRANSFORM] ['ADOSC_3_10']: 0.000787 secs\n",
      "2024-02-01 17:36:30,818 INFO     pid:15618 sklearn_pandas:343:_transform [FIT_TRANSFORM] ['KVO_34_55_13']: 0.000802 secs\n",
      "2024-02-01 17:36:30,819 INFO     pid:15618 sklearn_pandas:343:_transform [FIT_TRANSFORM] ['KVOs_34_55_13']: 0.000836 secs\n",
      "2024-02-01 17:36:30,822 INFO     pid:15618 sklearn_pandas:353:_transform [TRANSFORM] ['ADOSC_3_10']: 0.000352 secs\n",
      "2024-02-01 17:36:30,823 INFO     pid:15618 sklearn_pandas:353:_transform [TRANSFORM] ['KVO_34_55_13']: 0.00034 secs\n",
      "2024-02-01 17:36:30,824 INFO     pid:15618 sklearn_pandas:353:_transform [TRANSFORM] ['KVOs_34_55_13']: 0.000345 secs\n",
      "2024-02-01 17:36:30,828 INFO     pid:15618 sklearn_pandas:343:_transform [FIT_TRANSFORM] ['ADOSC_3_10']: 0.000811 secs\n",
      "2024-02-01 17:36:30,829 INFO     pid:15618 sklearn_pandas:343:_transform [FIT_TRANSFORM] ['KVO_34_55_13']: 0.000985 secs\n",
      "2024-02-01 17:36:30,830 INFO     pid:15618 sklearn_pandas:343:_transform [FIT_TRANSFORM] ['KVOs_34_55_13']: 0.000814 secs\n",
      "2024-02-01 17:36:30,833 INFO     pid:15618 sklearn_pandas:353:_transform [TRANSFORM] ['ADOSC_3_10']: 0.000363 secs\n",
      "2024-02-01 17:36:30,834 INFO     pid:15618 sklearn_pandas:353:_transform [TRANSFORM] ['KVO_34_55_13']: 0.000352 secs\n",
      "2024-02-01 17:36:30,835 INFO     pid:15618 sklearn_pandas:353:_transform [TRANSFORM] ['KVOs_34_55_13']: 0.000339 secs\n",
      "2024-02-01 17:36:30,839 INFO     pid:15618 sklearn_pandas:343:_transform [FIT_TRANSFORM] ['ADOSC_3_10']: 0.000795 secs\n",
      "2024-02-01 17:36:30,840 INFO     pid:15618 sklearn_pandas:343:_transform [FIT_TRANSFORM] ['KVO_34_55_13']: 0.000756 secs\n",
      "2024-02-01 17:36:30,841 INFO     pid:15618 sklearn_pandas:343:_transform [FIT_TRANSFORM] ['KVOs_34_55_13']: 0.000845 secs\n",
      "2024-02-01 17:36:30,844 INFO     pid:15618 sklearn_pandas:353:_transform [TRANSFORM] ['ADOSC_3_10']: 0.000365 secs\n",
      "2024-02-01 17:36:30,845 INFO     pid:15618 sklearn_pandas:353:_transform [TRANSFORM] ['KVO_34_55_13']: 0.000323 secs\n",
      "2024-02-01 17:36:30,846 INFO     pid:15618 sklearn_pandas:353:_transform [TRANSFORM] ['KVOs_34_55_13']: 0.000328 secs\n",
      "2024-02-01 17:36:30,850 INFO     pid:15618 sklearn_pandas:343:_transform [FIT_TRANSFORM] ['ADOSC_3_10']: 0.000793 secs\n",
      "2024-02-01 17:36:30,851 INFO     pid:15618 sklearn_pandas:343:_transform [FIT_TRANSFORM] ['KVO_34_55_13']: 0.000758 secs\n",
      "2024-02-01 17:36:30,852 INFO     pid:15618 sklearn_pandas:343:_transform [FIT_TRANSFORM] ['KVOs_34_55_13']: 0.000785 secs\n",
      "2024-02-01 17:36:30,855 INFO     pid:15618 sklearn_pandas:353:_transform [TRANSFORM] ['ADOSC_3_10']: 0.000356 secs\n",
      "2024-02-01 17:36:30,856 INFO     pid:15618 sklearn_pandas:353:_transform [TRANSFORM] ['KVO_34_55_13']: 0.000327 secs\n",
      "2024-02-01 17:36:30,856 INFO     pid:15618 sklearn_pandas:353:_transform [TRANSFORM] ['KVOs_34_55_13']: 0.000352 secs\n",
      "2024-02-01 17:36:30,861 INFO     pid:15618 sklearn_pandas:343:_transform [FIT_TRANSFORM] ['ADOSC_3_10']: 0.000921 secs\n",
      "2024-02-01 17:36:30,862 INFO     pid:15618 sklearn_pandas:343:_transform [FIT_TRANSFORM] ['KVO_34_55_13']: 0.000813 secs\n",
      "2024-02-01 17:36:30,863 INFO     pid:15618 sklearn_pandas:343:_transform [FIT_TRANSFORM] ['KVOs_34_55_13']: 0.000781 secs\n",
      "2024-02-01 17:36:30,866 INFO     pid:15618 sklearn_pandas:353:_transform [TRANSFORM] ['ADOSC_3_10']: 0.000338 secs\n",
      "2024-02-01 17:36:30,867 INFO     pid:15618 sklearn_pandas:353:_transform [TRANSFORM] ['KVO_34_55_13']: 0.000325 secs\n",
      "2024-02-01 17:36:30,867 INFO     pid:15618 sklearn_pandas:353:_transform [TRANSFORM] ['KVOs_34_55_13']: 0.000349 secs\n",
      "2024-02-01 17:36:30,871 INFO     pid:15618 sklearn_pandas:343:_transform [FIT_TRANSFORM] ['ADOSC_3_10']: 0.000809 secs\n",
      "2024-02-01 17:36:30,872 INFO     pid:15618 sklearn_pandas:343:_transform [FIT_TRANSFORM] ['KVO_34_55_13']: 0.000749 secs\n",
      "2024-02-01 17:36:30,873 INFO     pid:15618 sklearn_pandas:343:_transform [FIT_TRANSFORM] ['KVOs_34_55_13']: 0.000749 secs\n",
      "2024-02-01 17:36:30,877 INFO     pid:15618 sklearn_pandas:353:_transform [TRANSFORM] ['ADOSC_3_10']: 0.000351 secs\n",
      "2024-02-01 17:36:30,877 INFO     pid:15618 sklearn_pandas:353:_transform [TRANSFORM] ['KVO_34_55_13']: 0.000324 secs\n",
      "2024-02-01 17:36:30,878 INFO     pid:15618 sklearn_pandas:353:_transform [TRANSFORM] ['KVOs_34_55_13']: 0.000333 secs\n",
      "2024-02-01 17:36:30,882 INFO     pid:15618 sklearn_pandas:343:_transform [FIT_TRANSFORM] ['ADOSC_3_10']: 0.000792 secs\n",
      "2024-02-01 17:36:30,883 INFO     pid:15618 sklearn_pandas:343:_transform [FIT_TRANSFORM] ['KVO_34_55_13']: 0.000753 secs\n",
      "2024-02-01 17:36:30,884 INFO     pid:15618 sklearn_pandas:343:_transform [FIT_TRANSFORM] ['KVOs_34_55_13']: 0.000743 secs\n",
      "2024-02-01 17:36:30,887 INFO     pid:15618 sklearn_pandas:353:_transform [TRANSFORM] ['ADOSC_3_10']: 0.000361 secs\n",
      "2024-02-01 17:36:30,888 INFO     pid:15618 sklearn_pandas:353:_transform [TRANSFORM] ['KVO_34_55_13']: 0.000332 secs\n",
      "2024-02-01 17:36:30,889 INFO     pid:15618 sklearn_pandas:353:_transform [TRANSFORM] ['KVOs_34_55_13']: 0.000328 secs\n",
      "2024-02-01 17:36:30,892 INFO     pid:15618 sklearn_pandas:343:_transform [FIT_TRANSFORM] ['ADOSC_3_10']: 0.000823 secs\n",
      "2024-02-01 17:36:30,894 INFO     pid:15618 sklearn_pandas:343:_transform [FIT_TRANSFORM] ['KVO_34_55_13']: 0.000794 secs\n",
      "2024-02-01 17:36:30,895 INFO     pid:15618 sklearn_pandas:343:_transform [FIT_TRANSFORM] ['KVOs_34_55_13']: 0.000759 secs\n",
      "2024-02-01 17:36:30,898 INFO     pid:15618 sklearn_pandas:353:_transform [TRANSFORM] ['ADOSC_3_10']: 0.000331 secs\n",
      "2024-02-01 17:36:30,898 INFO     pid:15618 sklearn_pandas:353:_transform [TRANSFORM] ['KVO_34_55_13']: 0.000335 secs\n",
      "2024-02-01 17:36:30,899 INFO     pid:15618 sklearn_pandas:353:_transform [TRANSFORM] ['KVOs_34_55_13']: 0.000327 secs\n",
      "2024-02-01 17:36:30,903 INFO     pid:15618 sklearn_pandas:343:_transform [FIT_TRANSFORM] ['ADOSC_3_10']: 0.000819 secs\n",
      "2024-02-01 17:36:30,904 INFO     pid:15618 sklearn_pandas:343:_transform [FIT_TRANSFORM] ['KVO_34_55_13']: 0.000756 secs\n",
      "2024-02-01 17:36:30,905 INFO     pid:15618 sklearn_pandas:343:_transform [FIT_TRANSFORM] ['KVOs_34_55_13']: 0.000784 secs\n",
      "2024-02-01 17:36:30,909 INFO     pid:15618 sklearn_pandas:353:_transform [TRANSFORM] ['ADOSC_3_10']: 0.000358 secs\n",
      "2024-02-01 17:36:30,910 INFO     pid:15618 sklearn_pandas:353:_transform [TRANSFORM] ['KVO_34_55_13']: 0.000334 secs\n",
      "2024-02-01 17:36:30,910 INFO     pid:15618 sklearn_pandas:353:_transform [TRANSFORM] ['KVOs_34_55_13']: 0.000345 secs\n",
      "2024-02-01 17:36:30,914 INFO     pid:15618 sklearn_pandas:343:_transform [FIT_TRANSFORM] ['ADOSC_3_10']: 0.000802 secs\n",
      "2024-02-01 17:36:30,915 INFO     pid:15618 sklearn_pandas:343:_transform [FIT_TRANSFORM] ['KVO_34_55_13']: 0.000739 secs\n",
      "2024-02-01 17:36:30,917 INFO     pid:15618 sklearn_pandas:343:_transform [FIT_TRANSFORM] ['KVOs_34_55_13']: 0.001618 secs\n",
      "2024-02-01 17:36:30,925 INFO     pid:15618 sklearn_pandas:353:_transform [TRANSFORM] ['ADOSC_3_10']: 0.000752 secs\n",
      "2024-02-01 17:36:30,927 INFO     pid:15618 sklearn_pandas:353:_transform [TRANSFORM] ['KVO_34_55_13']: 0.000617 secs\n",
      "2024-02-01 17:36:30,928 INFO     pid:15618 sklearn_pandas:353:_transform [TRANSFORM] ['KVOs_34_55_13']: 0.000607 secs\n",
      "2024-02-01 17:36:30,933 INFO     pid:15618 sklearn_pandas:343:_transform [FIT_TRANSFORM] ['ADOSC_3_10']: 0.001026 secs\n",
      "2024-02-01 17:36:30,934 INFO     pid:15618 sklearn_pandas:343:_transform [FIT_TRANSFORM] ['KVO_34_55_13']: 0.000979 secs\n",
      "2024-02-01 17:36:30,936 INFO     pid:15618 sklearn_pandas:343:_transform [FIT_TRANSFORM] ['KVOs_34_55_13']: 0.000732 secs\n",
      "2024-02-01 17:36:30,939 INFO     pid:15618 sklearn_pandas:353:_transform [TRANSFORM] ['ADOSC_3_10']: 0.000376 secs\n",
      "2024-02-01 17:36:30,940 INFO     pid:15618 sklearn_pandas:353:_transform [TRANSFORM] ['KVO_34_55_13']: 0.000348 secs\n",
      "2024-02-01 17:36:30,941 INFO     pid:15618 sklearn_pandas:353:_transform [TRANSFORM] ['KVOs_34_55_13']: 0.000323 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36960\n",
      "92136\n",
      "9260\n",
      "20934\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import math\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "\n",
    "_return_period = return_period\n",
    "_seq_len = seq_len\n",
    "\n",
    "\n",
    "ticks_dataset = [gen_analysis_data(d, _return_period) for d in ticks_data]\n",
    "ticks_X_train_data = []\n",
    "ticks_Y_train_data = []\n",
    "ticks_X_test_data = []\n",
    "ticks_Y_test_data = []\n",
    "ticks_X_dfm = []\n",
    "for dataset in ticks_dataset:\n",
    "    # test_size = int(dataset.shape[0] * validation_size)\n",
    "    train_size = int(dataset.shape[0] * (1 - validation_size))\n",
    "    # random.seed(42)\n",
    "    train_data = dataset.iloc[0:train_size]\n",
    "    test_data = dataset.iloc[train_size - seq_len + 1 :]\n",
    "\n",
    "    X_train_data = train_data.iloc[:, :-1]\n",
    "    Y_train_data = train_data.iloc[:, -1:]\n",
    "\n",
    "    X_test_data = test_data.iloc[:, :-1]\n",
    "    Y_test_data = test_data.iloc[:, -1:]\n",
    "\n",
    "    features = [\n",
    "        ([column], StandardScaler()) for column in X_train_data.columns[:3].values\n",
    "    ]\n",
    "    features.extend([([column], None) for column in X_train_data.columns[3:].values])\n",
    "    # print(features)\n",
    "    X_dfm = DataFrameMapper(features, input_df=True, df_out=True)\n",
    "    X_train_data = X_dfm.fit_transform(X_train_data)\n",
    "    X_test_data = X_dfm.transform(X_test_data)\n",
    "\n",
    "    ticks_X_dfm.append(X_dfm)\n",
    "    ticks_X_train_data.append(X_train_data)\n",
    "    ticks_Y_train_data.append(Y_train_data)\n",
    "    ticks_X_test_data.append(X_test_data)\n",
    "    ticks_Y_test_data.append(Y_test_data)\n",
    "\n",
    "train_ds = LSTMDataSet(ticks_X_train_data, ticks_Y_train_data, _seq_len)\n",
    "test_ds = LSTMDataSet(ticks_X_test_data, ticks_Y_test_data, _seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KVUE, 23\n",
      "Date\n",
      "2023-05-04            NaN\n",
      "2023-05-05            NaN\n",
      "2023-05-08            NaN\n",
      "2023-05-09            NaN\n",
      "2023-05-10            NaN\n",
      "                 ...     \n",
      "2023-12-22   -3787221.485\n",
      "2023-12-26   -2217103.885\n",
      "2023-12-27    2079808.214\n",
      "2023-12-28    2651561.239\n",
      "2023-12-29    4845022.046\n",
      "Name: ADOSC_3_10, Length: 166, dtype: float64\n",
      "            KVO_34_55_13  KVOs_34_55_13\n",
      "Date                                   \n",
      "2023-05-04           NaN            NaN\n",
      "2023-05-05           NaN            NaN\n",
      "2023-05-08           NaN            NaN\n",
      "2023-05-09           NaN            NaN\n",
      "2023-05-10           NaN            NaN\n",
      "...                  ...            ...\n",
      "2023-12-22   2026460.159    2724407.594\n",
      "2023-12-26   1659098.235    2572220.543\n",
      "2023-12-27   1728448.571    2451681.690\n",
      "2023-12-28   1729998.318    2348584.065\n",
      "2023-12-29   1352791.000    2206327.913\n",
      "\n",
      "[166 rows x 2 columns]\n",
      "Date\n",
      "2023-05-04     NaN\n",
      "2023-05-05     NaN\n",
      "2023-05-08     NaN\n",
      "2023-05-09     NaN\n",
      "2023-05-10     NaN\n",
      "              ... \n",
      "2023-12-22   0.630\n",
      "2023-12-26   0.612\n",
      "2023-12-27   0.653\n",
      "2023-12-28   0.630\n",
      "2023-12-29   0.641\n",
      "Name: RSI_10, Length: 166, dtype: float64\n",
      "Date\n",
      "2023-05-04     NaN\n",
      "2023-05-05     NaN\n",
      "2023-05-08     NaN\n",
      "2023-05-09     NaN\n",
      "2023-05-10     NaN\n",
      "              ... \n",
      "2023-12-22   0.559\n",
      "2023-12-26   0.554\n",
      "2023-12-27   0.570\n",
      "2023-12-28   0.563\n",
      "2023-12-29   0.567\n",
      "Name: RSI_30, Length: 166, dtype: float64\n",
      "            Open  High   Low  Close  Adj Close     Volume\n",
      "Date                                                     \n",
      "2023-05-04 0.255 0.270 0.253  0.269      0.264 770042.000\n",
      "2023-05-05 0.267 0.270 0.262  0.265      0.260 112899.000\n",
      "2023-05-08 0.263 0.269 0.259  0.265      0.260  63083.000\n",
      "2023-05-09 0.265 0.268 0.261  0.263      0.258  46840.000\n",
      "2023-05-10 0.263 0.268 0.260  0.263      0.258  96024.000\n",
      "...          ...   ...   ...    ...        ...        ...\n",
      "2023-12-22 0.212 0.214 0.212  0.214      0.214  95768.000\n",
      "2023-12-26 0.212 0.214 0.211  0.213      0.213  81286.000\n",
      "2023-12-27 0.213 0.215 0.213  0.215      0.215 108524.000\n",
      "2023-12-28 0.215 0.216 0.214  0.215      0.215  81469.000\n",
      "2023-12-29 0.214 0.216 0.213  0.215      0.215  93571.000\n",
      "\n",
      "[166 rows x 6 columns]\n",
      "            STOCHk_10_3_3  STOCHd_10_3_3\n",
      "Date                                    \n",
      "2023-05-17            NaN            NaN\n",
      "2023-05-18            NaN            NaN\n",
      "2023-05-19          0.692            NaN\n",
      "2023-05-22          0.464            NaN\n",
      "2023-05-23          0.296          0.484\n",
      "...                   ...            ...\n",
      "2023-12-22          0.501          0.587\n",
      "2023-12-26          0.488          0.519\n",
      "2023-12-27          0.527          0.506\n",
      "2023-12-28          0.502          0.506\n",
      "2023-12-29          0.507          0.512\n",
      "\n",
      "[157 rows x 2 columns]\n",
      "            STOCHk_30_3_3  STOCHd_30_3_3\n",
      "Date                                    \n",
      "2023-06-15            NaN            NaN\n",
      "2023-06-16            NaN            NaN\n",
      "2023-06-20          0.417            NaN\n",
      "2023-06-21          0.466            NaN\n",
      "2023-06-22          0.499          0.461\n",
      "...                   ...            ...\n",
      "2023-12-22          0.659          0.685\n",
      "2023-12-26          0.693          0.674\n",
      "2023-12-27          0.724          0.692\n",
      "2023-12-28          0.729          0.715\n",
      "2023-12-29          0.747          0.733\n",
      "\n",
      "[137 rows x 2 columns]\n",
      "            Open  High   Low  Close  Adj Close     Volume\n",
      "Date                                                     \n",
      "2023-05-04 0.255 0.270 0.253  0.269      0.264 770042.000\n",
      "2023-05-05 0.267 0.270 0.262  0.265      0.260 112899.000\n",
      "2023-05-08 0.263 0.269 0.259  0.265      0.260  63083.000\n",
      "2023-05-09 0.265 0.268 0.261  0.263      0.258  46840.000\n",
      "2023-05-10 0.263 0.268 0.260  0.263      0.258  96024.000\n",
      "...          ...   ...   ...    ...        ...        ...\n",
      "2023-12-22 0.212 0.214 0.212  0.214      0.214  95768.000\n",
      "2023-12-26 0.212 0.214 0.211  0.213      0.213  81286.000\n",
      "2023-12-27 0.213 0.215 0.213  0.215      0.215 108524.000\n",
      "2023-12-28 0.215 0.216 0.214  0.215      0.215  81469.000\n",
      "2023-12-29 0.214 0.216 0.213  0.215      0.215  93571.000\n",
      "\n",
      "[166 rows x 6 columns]\n",
      "            Signal\n",
      "Date              \n",
      "2023-05-04     NaN\n",
      "2023-05-05     NaN\n",
      "2023-05-08     NaN\n",
      "2023-05-09     NaN\n",
      "2023-05-10     NaN\n",
      "...            ...\n",
      "2023-12-22   1.000\n",
      "2023-12-26   1.000\n",
      "2023-12-27   1.000\n",
      "2023-12-28   1.000\n",
      "2023-12-29   1.000\n",
      "\n",
      "[166 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "d = ticks_data[180]\n",
    "x = gen_analysis_data(d, return_period)\n",
    "print(f\"{stk_tickers[180]}, {len(x.columns)}\")\n",
    "# print(ticks_data[180])\n",
    "# print(x)\n",
    "\n",
    "print(d.ta.adosc())\n",
    "print(d.ta.kvo())\n",
    "print(d.ta.rsi(close=\"Adj Close\", length=10) / 100)\n",
    "print(d.ta.rsi(close=\"Adj Close\", length=30) / 100)\n",
    "print(d.ta.rsi(close=\"Adj Close\", length=200) / 100)\n",
    "print(d.ta.stoch(k=10) / 100)\n",
    "print(d.ta.stoch(k=30) / 100)\n",
    "print(d.ta.stoch(k=200) / 100)\n",
    "print(gen_buy_sell_signal(d))\n",
    "\n",
    "# data = pd.concat(\n",
    "#     [data.astype(\"float32\"), gen_pct_label(stk_data, _return_period)],\n",
    "#     axis=1,\n",
    "# ).dropna()\n",
    "# return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "\n",
    "\n",
    "def prepare_dataloader(_return_period, _seq_len):\n",
    "    ticks_dataset = prepare_dataset(_return_period)\n",
    "    ticks_X_train_data = []\n",
    "    ticks_Y_train_data = []\n",
    "    ticks_X_test_data = []\n",
    "    ticks_Y_test_data = []\n",
    "    ticks_X_dfm = []\n",
    "    for dataset in ticks_dataset:\n",
    "        # test_size = int(dataset.shape[0] * validation_size)\n",
    "        train_size = int(dataset.shape[0] * (1 - validation_size))\n",
    "        # random.seed(42)\n",
    "        train_data = dataset.iloc[0:train_size]\n",
    "        test_data = dataset.iloc[train_size - seq_len + 1 :]\n",
    "\n",
    "        X_train_data = train_data.iloc[:, :-1]\n",
    "        Y_train_data = train_data.iloc[:, -1:]\n",
    "\n",
    "        X_test_data = test_data.iloc[:, :-1]\n",
    "        Y_test_data = test_data.iloc[:, -1:]\n",
    "\n",
    "        features = [\n",
    "            ([column], StandardScaler()) for column in X_train_data.columns[:3].values\n",
    "        ]\n",
    "        features.extend(\n",
    "            [([column], None) for column in X_train_data.columns[3:].values]\n",
    "        )\n",
    "        # print(features)\n",
    "        X_dfm = DataFrameMapper(features, input_df=True, df_out=True)\n",
    "        X_train_data = X_dfm.fit_transform(X_train_data)\n",
    "        X_test_data = X_dfm.transform(X_test_data)\n",
    "\n",
    "        ticks_X_dfm.append(X_dfm)\n",
    "        ticks_X_train_data.append(X_train_data)\n",
    "        ticks_Y_train_data.append(Y_train_data)\n",
    "        ticks_X_test_data.append(X_test_data)\n",
    "        ticks_Y_test_data.append(Y_test_data)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        LSTMDataSet(ticks_X_train_data, ticks_Y_train_data, _seq_len),\n",
    "        batch_size,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory,\n",
    "        pin_memory_device=device_name,\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        LSTMDataSet(ticks_X_test_data, ticks_Y_test_data, _seq_len),\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory,\n",
    "        pin_memory_device=device_name,\n",
    "    )\n",
    "\n",
    "    return train_loader, test_loader, ticks_X_train_data[0].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12, 36, 48, 49, 56, 57, 59, 60, 61, 62, 63, 70, 71, 72, 73, 93, 176, 177, 178, 179]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20]\n",
      "(array([[2.528885  , 0.43020323, 0.41524336, 0.7508403 , 0.6468546 ,\n",
      "        0.5929855 , 0.75881785, 0.78068274, 0.90454125, 0.9036594 ,\n",
      "        0.9637288 , 0.9633937 , 1.        ],\n",
      "       [2.016737  , 0.03446712, 0.36264643, 0.7330403 , 0.64248574,\n",
      "        0.5923124 , 0.73179203, 0.7508734 , 0.9038799 , 0.9013078 ,\n",
      "        0.9634775 , 0.96250015, 1.        ],\n",
      "       [1.9672475 , 0.1624415 , 0.34040493, 0.76318556, 0.65416276,\n",
      "        0.5945477 , 0.77876943, 0.7564598 , 0.92592573, 0.91144896,\n",
      "        0.97185415, 0.9663535 , 1.        ]], dtype=float32), 1)\n",
      "            label\n",
      "Date             \n",
      "2014-10-22      0\n",
      "2014-10-23      0\n",
      "2014-10-24      0\n",
      "2014-10-27      0\n",
      "2014-10-28      0\n",
      "2014-10-29      0\n",
      "2014-10-30      0\n",
      "2014-10-31      0\n",
      "2014-11-03      0\n",
      "2014-11-04      0\n",
      "2014-11-05      0\n",
      "2014-11-06      0\n",
      "2014-11-07      0\n",
      "2014-11-10      0\n",
      "2014-11-11      1\n",
      "2014-11-12      0\n",
      "2014-11-13      0\n",
      "2014-11-14      0\n",
      "2014-11-17      0\n",
      "2014-11-18      0\n",
      "            ADOSC_3_10  KVO_34_55_13  KVOs_34_55_13  RSI_10  RSI_30  RSI_200  STOCHk_10_3_3  STOCHd_10_3_3  STOCHk_30_3_3  STOCHd_30_3_3  STOCHk_200_3_3  STOCHd_200_3_3  Signal\n",
      "Date                                                                                                                                                                            \n",
      "2014-10-22      -0.725        -0.316         -1.873   0.637   0.574    0.578          0.814          0.609          0.794          0.582           0.936           0.882   1.000\n",
      "2014-10-23       0.038         0.250         -1.560   0.690   0.599    0.582          0.927          0.793          0.926          0.776           0.974           0.932   1.000\n",
      "2014-10-24       0.621         0.550         -1.239   0.700   0.604    0.583          0.942          0.894          0.942          0.887           0.984           0.965   1.000\n",
      "2014-10-27       0.809         0.706         -0.935   0.693   0.602    0.583          0.972          0.947          0.972          0.947           0.992           0.983   1.000\n",
      "2014-10-28       1.478         0.971         -0.627   0.737   0.623    0.587          0.979          0.964          0.979          0.964           0.994           0.990   1.000\n",
      "2014-10-29       2.306         1.251         -0.314   0.751   0.631    0.589          0.987          0.979          0.987          0.979           0.996           0.994   1.000\n",
      "2014-10-30       2.700         0.670         -0.149   0.725   0.623    0.588          0.987          0.984          0.989          0.985           0.996           0.995   1.000\n",
      "2014-10-31       3.172         0.902          0.034   0.752   0.636    0.590          0.985          0.986          0.987          0.988           0.996           0.996   1.000\n",
      "2014-11-03       3.217         1.179          0.240   0.785   0.653    0.594          0.953          0.975          0.968          0.981           0.989           0.994   1.000\n",
      "2014-11-04       2.920         0.591          0.312   0.724   0.636    0.591          0.892          0.943          0.942          0.966           0.978           0.987   1.000\n",
      "2014-11-05       2.647         0.761          0.404   0.732   0.639    0.591          0.821          0.889          0.911          0.940           0.966           0.978   1.000\n",
      "2014-11-06       2.683         0.267          0.394   0.741   0.643    0.592          0.762          0.825          0.896          0.916           0.960           0.968   1.000\n",
      "2014-11-07       2.529         0.430          0.415   0.751   0.647    0.593          0.759          0.781          0.905          0.904           0.964           0.963   1.000\n",
      "2014-11-10       2.017         0.034          0.363   0.733   0.642    0.592          0.732          0.751          0.904          0.901           0.963           0.963   1.000\n",
      "2014-11-11       1.967         0.162          0.340   0.763   0.654    0.595          0.779          0.756          0.926          0.911           0.972           0.966   1.000\n",
      "2014-11-12       2.302         0.453          0.373   0.806   0.674    0.598          0.845          0.785          0.951          0.927           0.981           0.972   1.000\n",
      "2014-11-13       2.481         0.828          0.468   0.839   0.692    0.602          0.910          0.845          0.972          0.949           0.989           0.981   1.000\n",
      "2014-11-14       2.934         1.029          0.586   0.862   0.707    0.606          0.955          0.903          0.985          0.969           0.994           0.988   1.000\n",
      "2014-11-17       2.398         1.235          0.723   0.844   0.702    0.605          0.851          0.905          0.939          0.965           0.971           0.984   1.000\n",
      "2014-11-18       2.418         1.396          0.869   0.868   0.718    0.609          0.821          0.876          0.923          0.949           0.962           0.976   1.000\n",
      "            ADOSC_3_10  KVO_34_55_13  KVOs_34_55_13  RSI_10  RSI_30  RSI_200  STOCHk_10_3_3  STOCHd_10_3_3  STOCHk_30_3_3  STOCHd_30_3_3  STOCHk_200_3_3  STOCHd_200_3_3  Signal\n",
      "Date                                                                                                                                                                            \n",
      "2014-11-07       2.529         0.430          0.415   0.751   0.647    0.593          0.759          0.781          0.905          0.904           0.964           0.963   1.000\n",
      "2014-11-10       2.017         0.034          0.363   0.733   0.642    0.592          0.732          0.751          0.904          0.901           0.963           0.963   1.000\n",
      "2014-11-11       1.967         0.162          0.340   0.763   0.654    0.595          0.779          0.756          0.926          0.911           0.972           0.966   1.000\n"
     ]
    }
   ],
   "source": [
    "ds = t_r.dataset\n",
    "# print(ds.ticks_data_Y[0][2:39])\n",
    "print(ds.class_indices[1][:20])\n",
    "print(ds.class_indices[0][:20])\n",
    "print(ds.__getitem__(1))\n",
    "print(ds.ticks_data_Y[0].head(20))\n",
    "print(ds.ticks_data_X[0].head(20))\n",
    "print(ds.ticks_data_X[0][12:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "\n",
    "class StockPCTLabelPredictLSTM(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size,\n",
    "        hidden_size,\n",
    "        num_layers,\n",
    "        num_fc_layers,\n",
    "        activation_type,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.setup_model(\n",
    "            input_size,\n",
    "            hidden_size,\n",
    "            num_layers,\n",
    "            num_fc_layers,\n",
    "            activation_type,\n",
    "        )\n",
    "\n",
    "    def __init__(self, input_size, config):\n",
    "        super().__init__()\n",
    "        self.setup_model(\n",
    "            input_size=input_size,\n",
    "            hidden_size=config[\"hidden_size\"],\n",
    "            num_layers=config[\"num_layers\"],\n",
    "            num_fc_layers=config[\"num_fc_layers\"],\n",
    "            activation_type=config[\"activation_type\"],\n",
    "        )\n",
    "\n",
    "    def setup_model(\n",
    "        self,\n",
    "        input_size,\n",
    "        hidden_size,\n",
    "        num_layers,\n",
    "        num_fc_layers,\n",
    "        activation_type,\n",
    "    ):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \"\"\"\n",
    "            input_size    : The number of expected features in the input x\n",
    "            hidden_size   : The number of features in the hidden state h\n",
    "            num_layers    : Number of recurrent layers. E.g., setting num_layers=2 would mean stacking two LSTMs together to form a stacked LSTM, with the second LSTM taking in outputs of the first LSTM and computing the final results. Default: 1\n",
    "            bias          : If False, then the layer does not use bias weights b_ih and b_hh. Default: True\n",
    "            batch_first   : If True, then the input and output tensors are provided as (batch, seq, feature) instead of (seq, batch, feature). Note that this does not apply to hidden or cell states. See the Inputs/Outputs sections below for details. Default: False\n",
    "            dropout       : If non-zero, introduces a Dropout layer on the outputs of each LSTM layer except the last layer, with dropout probability equal to dropout. Default: 0\n",
    "            bidirectional : If True, becomes a bidirectional LSTM. Default: False\n",
    "            proj_size     : If > 0, will use LSTM with projections of corresponding size. Default: 0\n",
    "        \"\"\"\n",
    "        self.rnn = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "\n",
    "        layers = []\n",
    "        in_features = self.hidden_size\n",
    "        for i in range(1, num_fc_layers):\n",
    "            out_features = int(in_features / 2)\n",
    "            if out_features <= num_classes:\n",
    "                break\n",
    "            layers.append(nn.Linear(in_features, out_features))\n",
    "            (\n",
    "                layers.append(nn.ReLU() if activation_type == 1 else nn.Sigmoid())\n",
    "                if activation_type == 2\n",
    "                else nn.Tanh()\n",
    "            )\n",
    "            in_features = out_features\n",
    "\n",
    "        layers.append(nn.Linear(in_features, num_classes))\n",
    "        self.fc = nn.Sequential(*layers)\n",
    "        self.fc.apply(self.init_weights)\n",
    "\n",
    "    def init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            initrange = 0.5\n",
    "            nn.init.uniform_(m.weight, -initrange, initrange)\n",
    "            nn.init.zeros_(m.bias)\n",
    "            # print(f\"{m.in_features},{m.out_features}\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        h_0 = torch.zeros(self.num_layers, x.shape[0], self.hidden_size).to(device)\n",
    "        c_0 = torch.zeros(self.num_layers, x.shape[0], self.hidden_size).to(device)\n",
    "        out, (h_out, _) = self.rnn(x, (h_0, c_0))\n",
    "\n",
    "        fc_input = h_out[-1].view(-1, self.hidden_size)\n",
    "        return self.fc(fc_input)\n",
    "\n",
    "\n",
    "def save_model(model, hyper_parameters, file_path, epoch_num=None):\n",
    "    state = {\n",
    "        \"epoch_num\": epoch_num,\n",
    "        \"time\": str(datetime.now),\n",
    "        \"model_state\": model.state_dict(),\n",
    "        \"input_size\": model.input_size,\n",
    "        \"hyper_parameters\": hyper_parameters,\n",
    "    }\n",
    "    # print(f\"save model:{file_path}\")\n",
    "    torch.save(state, file_path)\n",
    "\n",
    "\n",
    "def load_model(file_path):\n",
    "    data_dict = torch.load(file_path)\n",
    "    hyper_parameters = data_dict[\"hyper_parameters\"]\n",
    "    model = StockPCTLabelPredictLSTM(\n",
    "        input_size=data_dict[\"input_size\"],\n",
    "        hidden_size=int(hyper_parameters[\"hidden_size\"]),\n",
    "        num_layers=int(hyper_parameters[\"num_layers\"]),\n",
    "        num_fc_layers=int(hyper_parameters[\"num_fc_layers\"]),\n",
    "        activation_type=int(hyper_parameters[\"activation_type\"]),\n",
    "    )\n",
    "    model.load_state_dict(data_dict[\"model_state\"])\n",
    "    return model, hyper_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "METRICS_LABEL_NDX = 0  # ground_truth\n",
    "METRICS_PBTY_NDX = 1  # Probability of predicition\n",
    "METRICS_PRED_NDX = 2  # class(label) of predicition\n",
    "METRICS_LOSS_NDX = 3\n",
    "METRICS_SIZE = 4\n",
    "softmax = nn.Softmax(dim=1)\n",
    "totalTrainingSamples_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-02 21:33:30.090165: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-02 21:33:30.091308: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-02-02 21:33:30.113161: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-02 21:33:30.456303: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from collections import namedtuple\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "def logMetrics(\n",
    "    epoch_ndx,\n",
    "    mode_str,\n",
    "    metrics_t,\n",
    "    classificationThreshold=0.5,\n",
    "):\n",
    "    log.info(\n",
    "        \"E{} {}\".format(\n",
    "            epoch_ndx,\n",
    "            task_name,\n",
    "        )\n",
    "    )\n",
    "    F1_rec = namedtuple(\n",
    "        \"f1_rec\",\n",
    "        \"target_class pos_correct neg_correct pos_count neg_count pos_loss neg_loss precision recall F1\",\n",
    "    )\n",
    "    F1_metrics = []\n",
    "    for target_class in reversed(range(num_classes)):\n",
    "        posLabel_mask = metrics_t[METRICS_LABEL_NDX] == target_class\n",
    "        pos_count = posLabel_mask.sum()\n",
    "        negLabel_mask = metrics_t[METRICS_LABEL_NDX] != target_class\n",
    "        neg_count = negLabel_mask.sum()\n",
    "\n",
    "        posPred_mask = metrics_t[METRICS_PRED_NDX] == target_class\n",
    "        threshold_mask = metrics_t[METRICS_PBTY_NDX] > classificationThreshold\n",
    "        # TP, truePos_count\n",
    "        TP = pos_correct = int((posLabel_mask & posPred_mask & threshold_mask).sum())\n",
    "\n",
    "        negPred_mask = metrics_t[METRICS_PRED_NDX] != target_class\n",
    "        # TN, trueNeg_count\n",
    "        TN = neg_correct = int((negLabel_mask & negPred_mask).sum())\n",
    "\n",
    "        # FP, falsePos_count\n",
    "        FP = neg_count - neg_correct\n",
    "        # FN, falseNeg_count\n",
    "        FN = pos_count - pos_correct\n",
    "\n",
    "        # precision = TP / (TP + FP)\n",
    "        precision = 0.0 if (TP + FP) == 0 else TP / np.float32(TP + FP)\n",
    "        # recall = TP / (TP + FN)\n",
    "        recall = 0.0 if (TP + FN) == 0 else TP / np.float32(TP + FN)\n",
    "        # F1 = 2 * precision * recall / (precision + recall)\n",
    "        F1 = (\n",
    "            0.0\n",
    "            if (precision + recall) == 0.0\n",
    "            else (2 * precision * recall) / np.float32(precision + recall)\n",
    "        )\n",
    "        F1_metrics.append(\n",
    "            F1_rec(\n",
    "                target_class,\n",
    "                pos_correct,\n",
    "                neg_correct,\n",
    "                pos_count,\n",
    "                neg_count,\n",
    "                metrics_t[METRICS_LOSS_NDX, posLabel_mask].mean(),\n",
    "                metrics_t[METRICS_LOSS_NDX, negLabel_mask].mean(),\n",
    "                precision,\n",
    "                recall,\n",
    "                F1,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        if num_classes == 2:\n",
    "            break\n",
    "\n",
    "    metrics_dict = {}\n",
    "    metrics_dict[\"loss/all\"] = metrics_t[METRICS_LOSS_NDX].mean()\n",
    "    log.info(\n",
    "        (\"E{} {:8} {loss/all:.4f} loss\").format(\n",
    "            epoch_ndx,\n",
    "            mode_str,\n",
    "            **metrics_dict,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    for target_class, rec in enumerate(F1_metrics):\n",
    "        target_class_str = f\"class {rec.target_class}\" if num_classes > 2 else \"\"\n",
    "        metrics_dict[f\"{target_class_str} loss/pos\"] = rec.pos_loss\n",
    "        metrics_dict[f\"{target_class_str} loss/neg\"] = rec.neg_loss\n",
    "        metrics_dict[f\"{target_class_str} correct/all\"] = (\n",
    "            (rec.pos_correct + rec.neg_correct) / metrics_t.shape[1] * 100\n",
    "        )\n",
    "        metrics_dict[f\"{target_class_str} correct/neg\"] = (\n",
    "            (rec.neg_correct) / rec.neg_count * 100\n",
    "        )\n",
    "        metrics_dict[f\"{target_class_str} correct/pos\"] = (\n",
    "            (rec.pos_correct) / rec.pos_count * 100\n",
    "        )\n",
    "        metrics_dict[f\"{target_class_str} pr/precision\"] = rec.precision\n",
    "        metrics_dict[f\"{target_class_str} pr/recall\"] = rec.recall\n",
    "        metrics_dict[f\"{target_class_str} pr/f1_score\"] = rec.F1\n",
    "\n",
    "        log.info(\n",
    "            (\n",
    "                \"E{} {:8} {} {\"\n",
    "                + \" correct/all:-5.1f}% correct, \"\n",
    "                + \"{\"\n",
    "                + f\"{target_class_str}\"\n",
    "                + \" pr/precision:.4f} precision, \"\n",
    "                + \"{\"\n",
    "                + f\"{target_class_str}\"\n",
    "                + \" pr/recall:.4f} recall, \"\n",
    "                + \"{\"\n",
    "                + f\"{target_class_str}\"\n",
    "                + \" pr/f1_score:.4f} f1 score\"\n",
    "            ).format(epoch_ndx, mode_str, target_class_str, **metrics_dict)\n",
    "        )\n",
    "        log.info(\n",
    "            (\n",
    "                \"E{} {:8} {} {\"\n",
    "                + \" loss/neg:.4f} loss, \"\n",
    "                + \"{\"\n",
    "                + f\"{target_class_str}\"\n",
    "                + \" correct/neg:-5.1f}% correct ({neg_correct:} of {neg_count:})\"\n",
    "            ).format(\n",
    "                epoch_ndx,\n",
    "                mode_str + \"_neg\",\n",
    "                target_class_str,\n",
    "                neg_correct=rec.neg_correct,\n",
    "                neg_count=rec.neg_count,\n",
    "                **metrics_dict,\n",
    "            )\n",
    "        )\n",
    "        log.info(\n",
    "            (\n",
    "                \"E{} {:8} {} {\"\n",
    "                + \" loss/pos:.4f} loss, \"\n",
    "                + \"{\"\n",
    "                + f\"{target_class_str}\"\n",
    "                + \" correct/pos:-5.1f}% correct ({pos_correct:} of {pos_count:})\"\n",
    "            ).format(\n",
    "                epoch_ndx,\n",
    "                mode_str + \"_pos\",\n",
    "                target_class_str,\n",
    "                pos_correct=rec.pos_correct,\n",
    "                pos_count=rec.pos_count,\n",
    "                **metrics_dict,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    writer = SummaryWriter(log_dir=log_dir + f\"/{mode_str}_cls\")\n",
    "    for key, value in metrics_dict.items():\n",
    "        writer.add_scalar(key, value, totalTrainingSamples_count)\n",
    "\n",
    "    writer.add_pr_curve(\n",
    "        \"pr\",\n",
    "        metrics_t[METRICS_LABEL_NDX],\n",
    "        metrics_t[METRICS_PRED_NDX],\n",
    "        totalTrainingSamples_count,\n",
    "    )\n",
    "\n",
    "    writer.close()\n",
    "    # bins = [x / 50.0 for x in range(51)]\n",
    "\n",
    "    # negHist_mask = negLabel_mask & (metrics_t[METRICS_PRED_NDX] > 0.01)\n",
    "    # posHist_mask = posLabel_mask & (metrics_t[METRICS_PRED_NDX] < 0.99)\n",
    "\n",
    "    # if negHist_mask.any():\n",
    "    #     writer.add_histogram(\n",
    "    #         \"is_neg\",\n",
    "    #         metrics_t[METRICS_PRED_NDX, negHist_mask],\n",
    "    #         self.totalTrainingSamples_count,\n",
    "    #         bins=bins,\n",
    "    #     )\n",
    "    # if posHist_mask.any():\n",
    "    #     writer.add_histogram(\n",
    "    #         \"is_pos\",\n",
    "    #         metrics_t[METRICS_PRED_NDX, posHist_mask],\n",
    "    #         self.totalTrainingSamples_count,\n",
    "    #         bins=bins,\n",
    "    #     )\n",
    "\n",
    "    return F1_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeBatchLoss(model, loss_fn, x, y, metrics_g, batch_idx):\n",
    "    x_g = x.to(device)\n",
    "    y_g = y.to(device)\n",
    "    outputs = model(x_g)\n",
    "    loss_g = loss_fn(outputs, y_g)\n",
    "    probability_g, predition_g = torch.max(softmax(outputs), dim=1)\n",
    "\n",
    "    start_ndx = batch_idx * batch_size\n",
    "    end_ndx = start_ndx + y.size(0)\n",
    "\n",
    "    metrics_g[METRICS_LABEL_NDX, start_ndx:end_ndx] = y_g\n",
    "    metrics_g[METRICS_PBTY_NDX, start_ndx:end_ndx] = probability_g\n",
    "    metrics_g[METRICS_PRED_NDX, start_ndx:end_ndx] = predition_g\n",
    "    metrics_g[METRICS_LOSS_NDX, start_ndx:end_ndx] = loss_g\n",
    "\n",
    "    return loss_g.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from myutil.util import enumerateWithEstimate\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def doTraining(model, optimizer, loss_fn, epoch_ndx, train_dl):\n",
    "    global totalTrainingSamples_count\n",
    "    model.train()\n",
    "    trnMetrics_g = torch.zeros(\n",
    "        METRICS_SIZE,\n",
    "        len(train_dl.dataset),\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    batch_iter = enumerateWithEstimate(\n",
    "        train_dl,\n",
    "        \"E{} Training\".format(epoch_ndx),\n",
    "        start_ndx=train_dl.num_workers,\n",
    "    )\n",
    "    for batch_ndx, (x, y) in batch_iter:\n",
    "        # for batch_ndx, (x, y) in enumerate(tqdm(train_dl)):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss = computeBatchLoss(\n",
    "            model,\n",
    "            loss_fn,\n",
    "            x,\n",
    "            y,\n",
    "            trnMetrics_g,\n",
    "            batch_ndx,\n",
    "        )\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    totalTrainingSamples_count += len(train_dl.dataset)\n",
    "    return trnMetrics_g.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doValidation(model, loss_fn, epoch_ndx, val_dl):\n",
    "    from sklearn.metrics import f1_score\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        valMetrics_g = torch.zeros(\n",
    "            METRICS_SIZE,\n",
    "            len(val_dl.dataset),\n",
    "            device=device,\n",
    "        )\n",
    "\n",
    "        batch_iter = enumerateWithEstimate(\n",
    "            val_dl,\n",
    "            \"E{} Validation \".format(epoch_ndx),\n",
    "            start_ndx=val_dl.num_workers,\n",
    "        )\n",
    "        for batch_ndx, (x, y) in batch_iter:\n",
    "            # for batch_ndx, (x, y) in enumerate(tqdm(val_dl)):\n",
    "            computeBatchLoss(model, loss_fn, x, y, valMetrics_g, batch_ndx)\n",
    "\n",
    "    return valMetrics_g.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_f1 = True\n",
    "\n",
    "\n",
    "def train_LSTM(config):\n",
    "    global totalTrainingSamples_count\n",
    "    best_f1 = 0\n",
    "\n",
    "    lr = config[\"lr\"]\n",
    "    momentum = config[\"momentum\"]\n",
    "    optim_type = config[\"optim_type\"]\n",
    "    totalTrainingSamples_count = 0\n",
    "\n",
    "    id_str = \"_\".join(str(v) if v < 1 else f\"{v:g}\" for v in config.values())\n",
    "    # print(id_str)\n",
    "    model_name = f\"{log_dir}/{id_str}.pt\"\n",
    "\n",
    "    train_loader, test_loader, features_size = prepare_dataloader(\n",
    "        config[\"return_period\"], config[\"seq_len\"]\n",
    "    )\n",
    "    train_loader = train.torch.prepare_data_loader(\n",
    "        data_loader=train_loader, move_to_device=True, auto_transfer=False\n",
    "    )\n",
    "    test_loader = train.torch.prepare_data_loader(\n",
    "        data_loader=test_loader, move_to_device=True, auto_transfer=False\n",
    "    )\n",
    "\n",
    "    model = StockPCTLabelPredictLSTM(input_size=features_size, config=config)\n",
    "    model = model.to(device)\n",
    "\n",
    "    optimizer = (\n",
    "        torch.optim.Adam(model.parameters(), lr=lr)\n",
    "        if optim_type == 1\n",
    "        else torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "    )\n",
    "    loss_fn = torch.nn.CrossEntropyLoss(reduction=\"none\")\n",
    "\n",
    "    for epoch_ndx in range(epoch_num):\n",
    "        trnMetrics_t = doTraining(model, optimizer, loss_fn, epoch_ndx, train_loader)\n",
    "        logMetrics(epoch_ndx, \"trn\", trnMetrics_t, classificationThreshold)\n",
    "\n",
    "        valMetrics_t = doValidation(model, loss_fn, epoch_ndx, test_loader)\n",
    "        F1_metrics = logMetrics(epoch_ndx, \"val\", valMetrics_t, classificationThreshold)\n",
    "        if F1_metrics[0].F1 > best_f1:\n",
    "            best_f1 = F1_metrics[0].F1\n",
    "            save_model(model, config, model_name)\n",
    "\n",
    "        if report_f1:\n",
    "            train.report({\"f1_score\": F1_metrics[0].F1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/AIWorkSpace/work/fin-ml/runs/StockPCTLabelPredictLSTM/2024-02-02_19.19.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 501/501 [00:05<00:00, 98.29it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 135 stocks in total, some classes have no data or are too small\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-02 19:19:48,337 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E0 Training ----/35181, starting\n",
      "2024-02-02 19:19:48,585 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E0 Training   32/35181, done at 2024-02-02 19:20:32, 0:00:44\n",
      "2024-02-02 19:19:48,852 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E0 Training  256/35181, done at 2024-02-02 19:20:30, 0:00:42\n",
      "2024-02-02 19:19:51,262 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E0 Training 2048/35181, done at 2024-02-02 19:20:35, 0:00:46\n",
      "2024-02-02 19:20:09,759 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E0 Training 16384/35181, done at 2024-02-02 19:20:34, 0:00:45\n",
      "2024-02-02 19:20:32,445 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E0 Training 35181/35181, done at 2024-02-02 19:20:32\n",
      "2024-02-02 19:20:32,451 INFO     pid:38964 __main__:011:logMetrics E0 StockPCTLabelPredictLSTM\n",
      "2024-02-02 19:20:32,477 INFO     pid:38964 __main__:072:logMetrics E0 trn      0.6717 loss\n",
      "2024-02-02 19:20:32,478 INFO     pid:38964 __main__:097:logMetrics E0 trn        58.5% correct, 0.5884 precision, 0.5662 recall, 0.5771 f1 score\n",
      "2024-02-02 19:20:32,478 INFO     pid:38964 __main__:112:logMetrics E0 trn_neg   0.6714 loss,  60.4% correct (339929 of 562892)\n",
      "2024-02-02 19:20:32,478 INFO     pid:38964 __main__:128:logMetrics E0 trn_pos   0.6720 loss,  56.6% correct (318690 of 562892)\n",
      "2024-02-02 19:20:32,515 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E0 Validation  ----/8413, starting\n",
      "2024-02-02 19:20:32,606 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E0 Validation    16/8413, done at 2024-02-02 19:20:42, 0:00:09\n",
      "2024-02-02 19:20:32,675 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E0 Validation    64/8413, done at 2024-02-02 19:20:44, 0:00:11\n",
      "2024-02-02 19:20:32,885 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E0 Validation   256/8413, done at 2024-02-02 19:20:42, 0:00:09\n",
      "2024-02-02 19:20:34,096 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E0 Validation  1024/8413, done at 2024-02-02 19:20:44, 0:00:12\n",
      "2024-02-02 19:20:37,860 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E0 Validation  4096/8413, done at 2024-02-02 19:20:43, 0:00:10\n",
      "2024-02-02 19:20:42,584 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E0 Validation  8413/8413, done at 2024-02-02 19:20:42\n",
      "2024-02-02 19:20:42,585 INFO     pid:38964 __main__:011:logMetrics E0 StockPCTLabelPredictLSTM\n",
      "2024-02-02 19:20:42,588 INFO     pid:38964 __main__:072:logMetrics E0 val      0.6813 loss\n",
      "2024-02-02 19:20:42,589 INFO     pid:38964 __main__:097:logMetrics E0 val        57.2% correct, 0.5521 precision, 0.7632 recall, 0.6407 f1 score\n",
      "2024-02-02 19:20:42,589 INFO     pid:38964 __main__:112:logMetrics E0 val_neg   0.7975 loss,  38.1% correct (51266 of 134598)\n",
      "2024-02-02 19:20:42,589 INFO     pid:38964 __main__:128:logMetrics E0 val_pos   0.5650 loss,  76.3% correct (102723 of 134598)\n",
      "2024-02-02 19:20:42,607 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E1 Training ----/35181, starting\n",
      "2024-02-02 19:20:42,741 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E1 Training   32/35181, done at 2024-02-02 19:21:21, 0:00:39\n",
      "2024-02-02 19:20:43,036 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E1 Training  256/35181, done at 2024-02-02 19:21:28, 0:00:45\n",
      "2024-02-02 19:20:45,286 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E1 Training 2048/35181, done at 2024-02-02 19:21:27, 0:00:44\n",
      "2024-02-02 19:21:03,235 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E1 Training 16384/35181, done at 2024-02-02 19:21:26, 0:00:44\n",
      "2024-02-02 19:21:25,900 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E1 Training 35181/35181, done at 2024-02-02 19:21:25\n",
      "2024-02-02 19:21:26,172 INFO     pid:38964 __main__:011:logMetrics E1 StockPCTLabelPredictLSTM\n",
      "2024-02-02 19:21:26,340 INFO     pid:38964 __main__:072:logMetrics E1 trn      0.6666 loss\n",
      "2024-02-02 19:21:26,340 INFO     pid:38964 __main__:097:logMetrics E1 trn        59.1% correct, 0.5957 precision, 0.5660 recall, 0.5805 f1 score\n",
      "2024-02-02 19:21:26,341 INFO     pid:38964 __main__:112:logMetrics E1 trn_neg   0.6658 loss,  61.6% correct (346709 of 562892)\n",
      "2024-02-02 19:21:26,341 INFO     pid:38964 __main__:128:logMetrics E1 trn_pos   0.6674 loss,  56.6% correct (318571 of 562892)\n",
      "2024-02-02 19:21:26,373 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E1 Validation  ----/8413, starting\n",
      "2024-02-02 19:21:26,478 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E1 Validation    16/8413, done at 2024-02-02 19:21:35, 0:00:09\n",
      "2024-02-02 19:21:26,569 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E1 Validation    64/8413, done at 2024-02-02 19:21:40, 0:00:14\n",
      "2024-02-02 19:21:26,785 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E1 Validation   256/8413, done at 2024-02-02 19:21:37, 0:00:10\n",
      "2024-02-02 19:21:28,008 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E1 Validation  1024/8413, done at 2024-02-02 19:21:39, 0:00:12\n",
      "2024-02-02 19:21:31,832 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E1 Validation  4096/8413, done at 2024-02-02 19:21:37, 0:00:11\n",
      "2024-02-02 19:21:37,267 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E1 Validation  8413/8413, done at 2024-02-02 19:21:37\n",
      "2024-02-02 19:21:37,269 INFO     pid:38964 __main__:011:logMetrics E1 StockPCTLabelPredictLSTM\n",
      "2024-02-02 19:21:37,272 INFO     pid:38964 __main__:072:logMetrics E1 val      0.6765 loss\n",
      "2024-02-02 19:21:37,272 INFO     pid:38964 __main__:097:logMetrics E1 val        57.8% correct, 0.5670 precision, 0.6593 recall, 0.6097 f1 score\n",
      "2024-02-02 19:21:37,272 INFO     pid:38964 __main__:112:logMetrics E1 val_neg   0.7165 loss,  49.6% correct (66826 of 134598)\n",
      "2024-02-02 19:21:37,273 INFO     pid:38964 __main__:128:logMetrics E1 val_pos   0.6365 loss,  65.9% correct (88741 of 134598)\n",
      "2024-02-02 19:21:37,284 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E2 Training ----/35181, starting\n",
      "2024-02-02 19:21:37,433 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E2 Training   32/35181, done at 2024-02-02 19:22:18, 0:00:41\n",
      "2024-02-02 19:21:37,747 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E2 Training  256/35181, done at 2024-02-02 19:22:25, 0:00:48\n",
      "2024-02-02 19:21:40,196 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E2 Training 2048/35181, done at 2024-02-02 19:22:25, 0:00:48\n",
      "2024-02-02 19:21:57,780 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E2 Training 16384/35181, done at 2024-02-02 19:22:21, 0:00:43\n",
      "2024-02-02 19:22:20,692 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E2 Training 35181/35181, done at 2024-02-02 19:22:20\n",
      "2024-02-02 19:22:21,083 INFO     pid:38964 __main__:011:logMetrics E2 StockPCTLabelPredictLSTM\n",
      "2024-02-02 19:22:21,165 INFO     pid:38964 __main__:072:logMetrics E2 trn      0.6639 loss\n",
      "2024-02-02 19:22:21,166 INFO     pid:38964 __main__:097:logMetrics E2 trn        59.5% correct, 0.6025 precision, 0.5558 recall, 0.5782 f1 score\n",
      "2024-02-02 19:22:21,166 INFO     pid:38964 __main__:112:logMetrics E2 trn_neg   0.6627 loss,  63.3% correct (356450 of 562892)\n",
      "2024-02-02 19:22:21,166 INFO     pid:38964 __main__:128:logMetrics E2 trn_pos   0.6652 loss,  55.6% correct (312876 of 562892)\n",
      "2024-02-02 19:22:21,200 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E2 Validation  ----/8413, starting\n",
      "2024-02-02 19:22:21,306 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E2 Validation    16/8413, done at 2024-02-02 19:22:31, 0:00:09\n",
      "2024-02-02 19:22:21,399 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E2 Validation    64/8413, done at 2024-02-02 19:22:36, 0:00:14\n",
      "2024-02-02 19:22:21,608 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E2 Validation   256/8413, done at 2024-02-02 19:22:31, 0:00:10\n",
      "2024-02-02 19:22:22,590 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E2 Validation  1024/8413, done at 2024-02-02 19:22:31, 0:00:10\n",
      "2024-02-02 19:22:26,292 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E2 Validation  4096/8413, done at 2024-02-02 19:22:31, 0:00:10\n",
      "2024-02-02 19:22:31,267 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E2 Validation  8413/8413, done at 2024-02-02 19:22:31\n",
      "2024-02-02 19:22:31,268 INFO     pid:38964 __main__:011:logMetrics E2 StockPCTLabelPredictLSTM\n",
      "2024-02-02 19:22:31,273 INFO     pid:38964 __main__:072:logMetrics E2 val      0.6804 loss\n",
      "2024-02-02 19:22:31,273 INFO     pid:38964 __main__:097:logMetrics E2 val        57.5% correct, 0.5606 precision, 0.6978 recall, 0.6217 f1 score\n",
      "2024-02-02 19:22:31,273 INFO     pid:38964 __main__:112:logMetrics E2 val_neg   0.7628 loss,  45.3% correct (60994 of 134598)\n",
      "2024-02-02 19:22:31,274 INFO     pid:38964 __main__:128:logMetrics E2 val_pos   0.5980 loss,  69.8% correct (93920 of 134598)\n",
      "2024-02-02 19:22:31,284 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E3 Training ----/35181, starting\n",
      "2024-02-02 19:22:31,434 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E3 Training   32/35181, done at 2024-02-02 19:23:10, 0:00:39\n",
      "2024-02-02 19:22:31,726 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E3 Training  256/35181, done at 2024-02-02 19:23:16, 0:00:45\n",
      "2024-02-02 19:22:34,119 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E3 Training 2048/35181, done at 2024-02-02 19:23:18, 0:00:46\n",
      "2024-02-02 19:22:51,896 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E3 Training 16384/35181, done at 2024-02-02 19:23:15, 0:00:44\n",
      "2024-02-02 19:23:15,638 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E3 Training 35181/35181, done at 2024-02-02 19:23:15\n",
      "2024-02-02 19:23:16,004 INFO     pid:38964 __main__:011:logMetrics E3 StockPCTLabelPredictLSTM\n",
      "2024-02-02 19:23:16,052 INFO     pid:38964 __main__:072:logMetrics E3 trn      0.6662 loss\n",
      "2024-02-02 19:23:16,053 INFO     pid:38964 __main__:097:logMetrics E3 trn        59.2% correct, 0.5990 precision, 0.5572 recall, 0.5773 f1 score\n",
      "2024-02-02 19:23:16,053 INFO     pid:38964 __main__:112:logMetrics E3 trn_neg   0.6652 loss,  62.7% correct (352895 of 562892)\n",
      "2024-02-02 19:23:16,054 INFO     pid:38964 __main__:128:logMetrics E3 trn_pos   0.6672 loss,  55.7% correct (313622 of 562892)\n",
      "2024-02-02 19:23:16,088 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E3 Validation  ----/8413, starting\n",
      "2024-02-02 19:23:16,200 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E3 Validation    16/8413, done at 2024-02-02 19:23:29, 0:00:13\n",
      "2024-02-02 19:23:16,457 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E3 Validation    64/8413, done at 2024-02-02 19:23:54, 0:00:37\n",
      "2024-02-02 19:23:16,655 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E3 Validation   256/8413, done at 2024-02-02 19:23:31, 0:00:15\n",
      "2024-02-02 19:23:17,442 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E3 Validation  1024/8413, done at 2024-02-02 19:23:26, 0:00:10\n",
      "2024-02-02 19:23:20,917 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E3 Validation  4096/8413, done at 2024-02-02 19:23:25, 0:00:09\n",
      "2024-02-02 19:23:25,863 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E3 Validation  8413/8413, done at 2024-02-02 19:23:25\n",
      "2024-02-02 19:23:25,865 INFO     pid:38964 __main__:011:logMetrics E3 StockPCTLabelPredictLSTM\n",
      "2024-02-02 19:23:25,868 INFO     pid:38964 __main__:072:logMetrics E3 val      0.6792 loss\n",
      "2024-02-02 19:23:25,869 INFO     pid:38964 __main__:097:logMetrics E3 val        57.6% correct, 0.5665 precision, 0.6471 recall, 0.6041 f1 score\n",
      "2024-02-02 19:23:25,869 INFO     pid:38964 __main__:112:logMetrics E3 val_neg   0.7005 loss,  50.5% correct (67933 of 134598)\n",
      "2024-02-02 19:23:25,869 INFO     pid:38964 __main__:128:logMetrics E3 val_pos   0.6578 loss,  64.7% correct (87102 of 134598)\n",
      "2024-02-02 19:23:25,880 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E4 Training ----/35181, starting\n",
      "2024-02-02 19:23:26,229 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E4 Training   32/35181, done at 2024-02-02 19:27:55, 0:04:29\n",
      "2024-02-02 19:23:26,514 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E4 Training  256/35181, done at 2024-02-02 19:24:37, 0:01:11\n",
      "2024-02-02 19:23:28,743 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E4 Training 2048/35181, done at 2024-02-02 19:24:13, 0:00:47\n",
      "2024-02-02 19:23:46,756 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E4 Training 16384/35181, done at 2024-02-02 19:24:10, 0:00:44\n",
      "2024-02-02 19:24:10,685 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E4 Training 35181/35181, done at 2024-02-02 19:24:10\n",
      "2024-02-02 19:24:11,039 INFO     pid:38964 __main__:011:logMetrics E4 StockPCTLabelPredictLSTM\n",
      "2024-02-02 19:24:11,083 INFO     pid:38964 __main__:072:logMetrics E4 trn      0.6625 loss\n",
      "2024-02-02 19:24:11,083 INFO     pid:38964 __main__:097:logMetrics E4 trn        59.7% correct, 0.6069 precision, 0.5494 recall, 0.5768 f1 score\n",
      "2024-02-02 19:24:11,083 INFO     pid:38964 __main__:112:logMetrics E4 trn_neg   0.6611 loss,  64.4% correct (362607 of 562892)\n",
      "2024-02-02 19:24:11,083 INFO     pid:38964 __main__:128:logMetrics E4 trn_pos   0.6639 loss,  54.9% correct (309267 of 562892)\n",
      "2024-02-02 19:24:11,119 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E4 Validation  ----/8413, starting\n",
      "2024-02-02 19:24:11,227 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E4 Validation    16/8413, done at 2024-02-02 19:24:21, 0:00:10\n",
      "2024-02-02 19:24:11,280 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E4 Validation    64/8413, done at 2024-02-02 19:24:20, 0:00:09\n",
      "2024-02-02 19:24:11,516 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E4 Validation   256/8413, done at 2024-02-02 19:24:21, 0:00:10\n",
      "2024-02-02 19:24:12,505 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E4 Validation  1024/8413, done at 2024-02-02 19:24:21, 0:00:10\n",
      "2024-02-02 19:24:15,873 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E4 Validation  4096/8413, done at 2024-02-02 19:24:20, 0:00:09\n",
      "2024-02-02 19:24:20,828 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E4 Validation  8413/8413, done at 2024-02-02 19:24:20\n",
      "2024-02-02 19:24:20,829 INFO     pid:38964 __main__:011:logMetrics E4 StockPCTLabelPredictLSTM\n",
      "2024-02-02 19:24:20,834 INFO     pid:38964 __main__:072:logMetrics E4 val      0.6832 loss\n",
      "2024-02-02 19:24:20,834 INFO     pid:38964 __main__:097:logMetrics E4 val        56.8% correct, 0.5525 precision, 0.7115 recall, 0.6220 f1 score\n",
      "2024-02-02 19:24:20,834 INFO     pid:38964 __main__:112:logMetrics E4 val_neg   0.7804 loss,  42.4% correct (57019 of 134598)\n",
      "2024-02-02 19:24:20,834 INFO     pid:38964 __main__:128:logMetrics E4 val_pos   0.5861 loss,  71.2% correct (95772 of 134598)\n",
      "2024-02-02 19:24:20,845 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E5 Training ----/35181, starting\n",
      "2024-02-02 19:24:21,002 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E5 Training   32/35181, done at 2024-02-02 19:25:04, 0:00:43\n",
      "2024-02-02 19:24:21,297 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E5 Training  256/35181, done at 2024-02-02 19:25:07, 0:00:46\n",
      "2024-02-02 19:24:23,503 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E5 Training 2048/35181, done at 2024-02-02 19:25:04, 0:00:43\n",
      "2024-02-02 19:24:41,054 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E5 Training 16384/35181, done at 2024-02-02 19:25:04, 0:00:43\n",
      "2024-02-02 19:25:03,630 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E5 Training 35181/35181, done at 2024-02-02 19:25:03\n",
      "2024-02-02 19:25:04,079 INFO     pid:38964 __main__:011:logMetrics E5 StockPCTLabelPredictLSTM\n",
      "2024-02-02 19:25:04,126 INFO     pid:38964 __main__:072:logMetrics E5 trn      0.6599 loss\n",
      "2024-02-02 19:25:04,127 INFO     pid:38964 __main__:097:logMetrics E5 trn        60.1% correct, 0.6135 precision, 0.5448 recall, 0.5771 f1 score\n",
      "2024-02-02 19:25:04,127 INFO     pid:38964 __main__:112:logMetrics E5 trn_neg   0.6580 loss,  65.7% correct (369673 of 562892)\n",
      "2024-02-02 19:25:04,127 INFO     pid:38964 __main__:128:logMetrics E5 trn_pos   0.6618 loss,  54.5% correct (306651 of 562892)\n",
      "2024-02-02 19:25:04,162 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E5 Validation  ----/8413, starting\n",
      "2024-02-02 19:25:04,269 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E5 Validation    16/8413, done at 2024-02-02 19:25:14, 0:00:10\n",
      "2024-02-02 19:25:04,324 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E5 Validation    64/8413, done at 2024-02-02 19:25:14, 0:00:09\n",
      "2024-02-02 19:25:04,551 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E5 Validation   256/8413, done at 2024-02-02 19:25:14, 0:00:09\n",
      "2024-02-02 19:25:05,560 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E5 Validation  1024/8413, done at 2024-02-02 19:25:15, 0:00:10\n",
      "2024-02-02 19:25:09,348 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E5 Validation  4096/8413, done at 2024-02-02 19:25:14, 0:00:10\n",
      "2024-02-02 19:25:14,471 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E5 Validation  8413/8413, done at 2024-02-02 19:25:14\n",
      "2024-02-02 19:25:14,473 INFO     pid:38964 __main__:011:logMetrics E5 StockPCTLabelPredictLSTM\n",
      "2024-02-02 19:25:14,478 INFO     pid:38964 __main__:072:logMetrics E5 val      0.6850 loss\n",
      "2024-02-02 19:25:14,478 INFO     pid:38964 __main__:097:logMetrics E5 val        56.1% correct, 0.5536 precision, 0.6310 recall, 0.5898 f1 score\n",
      "2024-02-02 19:25:14,478 INFO     pid:38964 __main__:112:logMetrics E5 val_neg   0.7590 loss,  49.1% correct (66122 of 134598)\n",
      "2024-02-02 19:25:14,479 INFO     pid:38964 __main__:128:logMetrics E5 val_pos   0.6109 loss,  63.1% correct (84927 of 134598)\n",
      "2024-02-02 19:25:14,489 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E6 Training ----/35181, starting\n",
      "2024-02-02 19:25:14,650 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E6 Training   32/35181, done at 2024-02-02 19:26:01, 0:00:46\n",
      "2024-02-02 19:25:14,945 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E6 Training  256/35181, done at 2024-02-02 19:26:01, 0:00:46\n",
      "2024-02-02 19:25:17,168 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E6 Training 2048/35181, done at 2024-02-02 19:25:58, 0:00:43\n",
      "2024-02-02 19:25:35,374 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E6 Training 16384/35181, done at 2024-02-02 19:25:59, 0:00:44\n",
      "2024-02-02 19:25:57,619 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E6 Training 35181/35181, done at 2024-02-02 19:25:57\n",
      "2024-02-02 19:25:57,970 INFO     pid:38964 __main__:011:logMetrics E6 StockPCTLabelPredictLSTM\n",
      "2024-02-02 19:25:58,013 INFO     pid:38964 __main__:072:logMetrics E6 trn      0.6591 loss\n",
      "2024-02-02 19:25:58,014 INFO     pid:38964 __main__:097:logMetrics E6 trn        60.2% correct, 0.6153 precision, 0.5459 recall, 0.5785 f1 score\n",
      "2024-02-02 19:25:58,014 INFO     pid:38964 __main__:112:logMetrics E6 trn_neg   0.6572 loss,  65.9% correct (370815 of 562892)\n",
      "2024-02-02 19:25:58,015 INFO     pid:38964 __main__:128:logMetrics E6 trn_pos   0.6609 loss,  54.6% correct (307278 of 562892)\n",
      "2024-02-02 19:25:58,048 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E6 Validation  ----/8413, starting\n",
      "2024-02-02 19:25:58,204 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E6 Validation    16/8413, done at 2024-02-02 19:26:33, 0:00:35\n",
      "2024-02-02 19:25:58,266 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E6 Validation    64/8413, done at 2024-02-02 19:26:14, 0:00:16\n",
      "2024-02-02 19:25:58,482 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E6 Validation   256/8413, done at 2024-02-02 19:26:09, 0:00:11\n",
      "2024-02-02 19:25:59,484 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E6 Validation  1024/8413, done at 2024-02-02 19:26:09, 0:00:11\n",
      "2024-02-02 19:26:03,172 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E6 Validation  4096/8413, done at 2024-02-02 19:26:08, 0:00:10\n",
      "2024-02-02 19:26:08,336 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E6 Validation  8413/8413, done at 2024-02-02 19:26:08\n",
      "2024-02-02 19:26:08,338 INFO     pid:38964 __main__:011:logMetrics E6 StockPCTLabelPredictLSTM\n",
      "2024-02-02 19:26:08,342 INFO     pid:38964 __main__:072:logMetrics E6 val      0.6818 loss\n",
      "2024-02-02 19:26:08,342 INFO     pid:38964 __main__:097:logMetrics E6 val        56.7% correct, 0.5749 precision, 0.5161 recall, 0.5439 f1 score\n",
      "2024-02-02 19:26:08,342 INFO     pid:38964 __main__:112:logMetrics E6 val_neg   0.6758 loss,  61.8% correct (83240 of 134598)\n",
      "2024-02-02 19:26:08,343 INFO     pid:38964 __main__:128:logMetrics E6 val_pos   0.6878 loss,  51.6% correct (69469 of 134598)\n",
      "2024-02-02 19:26:08,353 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E7 Training ----/35181, starting\n",
      "2024-02-02 19:26:08,507 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E7 Training   32/35181, done at 2024-02-02 19:26:48, 0:00:39\n",
      "2024-02-02 19:26:08,799 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E7 Training  256/35181, done at 2024-02-02 19:26:53, 0:00:45\n",
      "2024-02-02 19:26:11,268 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E7 Training 2048/35181, done at 2024-02-02 19:26:56, 0:00:48\n",
      "2024-02-02 19:26:29,278 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E7 Training 16384/35181, done at 2024-02-02 19:26:53, 0:00:44\n",
      "2024-02-02 19:26:52,814 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E7 Training 35181/35181, done at 2024-02-02 19:26:52\n",
      "2024-02-02 19:26:53,164 INFO     pid:38964 __main__:011:logMetrics E7 StockPCTLabelPredictLSTM\n",
      "2024-02-02 19:26:53,212 INFO     pid:38964 __main__:072:logMetrics E7 trn      0.6599 loss\n",
      "2024-02-02 19:26:53,213 INFO     pid:38964 __main__:097:logMetrics E7 trn        60.1% correct, 0.6167 precision, 0.5358 recall, 0.5734 f1 score\n",
      "2024-02-02 19:26:53,213 INFO     pid:38964 __main__:112:logMetrics E7 trn_neg   0.6580 loss,  66.7% correct (375459 of 562892)\n",
      "2024-02-02 19:26:53,213 INFO     pid:38964 __main__:128:logMetrics E7 trn_pos   0.6617 loss,  53.6% correct (301618 of 562892)\n",
      "2024-02-02 19:26:53,247 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E7 Validation  ----/8413, starting\n",
      "2024-02-02 19:26:53,357 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E7 Validation    16/8413, done at 2024-02-02 19:27:03, 0:00:10\n",
      "2024-02-02 19:26:53,438 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E7 Validation    64/8413, done at 2024-02-02 19:27:06, 0:00:13\n",
      "2024-02-02 19:26:53,836 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E7 Validation   256/8413, done at 2024-02-02 19:27:09, 0:00:16\n",
      "2024-02-02 19:26:54,638 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E7 Validation  1024/8413, done at 2024-02-02 19:27:04, 0:00:10\n",
      "2024-02-02 19:26:58,355 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E7 Validation  4096/8413, done at 2024-02-02 19:27:03, 0:00:10\n",
      "2024-02-02 19:27:03,316 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E7 Validation  8413/8413, done at 2024-02-02 19:27:03\n",
      "2024-02-02 19:27:03,317 INFO     pid:38964 __main__:011:logMetrics E7 StockPCTLabelPredictLSTM\n",
      "2024-02-02 19:27:03,322 INFO     pid:38964 __main__:072:logMetrics E7 val      0.6923 loss\n",
      "2024-02-02 19:27:03,322 INFO     pid:38964 __main__:097:logMetrics E7 val        57.4% correct, 0.5627 precision, 0.6614 recall, 0.6081 f1 score\n",
      "2024-02-02 19:27:03,322 INFO     pid:38964 __main__:112:logMetrics E7 val_neg   0.8243 loss,  48.6% correct (65418 of 134598)\n",
      "2024-02-02 19:27:03,323 INFO     pid:38964 __main__:128:logMetrics E7 val_pos   0.5603 loss,  66.1% correct (89019 of 134598)\n",
      "2024-02-02 19:27:03,334 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E8 Training ----/35181, starting\n",
      "2024-02-02 19:27:03,518 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E8 Training   32/35181, done at 2024-02-02 19:27:50, 0:00:47\n",
      "2024-02-02 19:27:03,983 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E8 Training  256/35181, done at 2024-02-02 19:28:13, 0:01:10\n",
      "2024-02-02 19:27:06,649 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E8 Training 2048/35181, done at 2024-02-02 19:27:58, 0:00:54\n",
      "2024-02-02 19:27:25,595 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E8 Training 16384/35181, done at 2024-02-02 19:27:50, 0:00:47\n",
      "2024-02-02 19:27:48,660 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E8 Training 35181/35181, done at 2024-02-02 19:27:48\n",
      "2024-02-02 19:27:49,032 INFO     pid:38964 __main__:011:logMetrics E8 StockPCTLabelPredictLSTM\n",
      "2024-02-02 19:27:49,075 INFO     pid:38964 __main__:072:logMetrics E8 trn      0.6593 loss\n",
      "2024-02-02 19:27:49,076 INFO     pid:38964 __main__:097:logMetrics E8 trn        60.2% correct, 0.6171 precision, 0.5352 recall, 0.5732 f1 score\n",
      "2024-02-02 19:27:49,076 INFO     pid:38964 __main__:112:logMetrics E8 trn_neg   0.6575 loss,  66.8% correct (375939 of 562892)\n",
      "2024-02-02 19:27:49,076 INFO     pid:38964 __main__:128:logMetrics E8 trn_pos   0.6611 loss,  53.5% correct (301277 of 562892)\n",
      "2024-02-02 19:27:49,109 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E8 Validation  ----/8413, starting\n",
      "2024-02-02 19:27:49,257 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E8 Validation    16/8413, done at 2024-02-02 19:27:58, 0:00:09\n",
      "2024-02-02 19:27:49,504 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E8 Validation    64/8413, done at 2024-02-02 19:28:24, 0:00:35\n",
      "2024-02-02 19:27:49,707 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E8 Validation   256/8413, done at 2024-02-02 19:28:04, 0:00:15\n",
      "2024-02-02 19:27:50,515 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E8 Validation  1024/8413, done at 2024-02-02 19:27:59, 0:00:10\n",
      "2024-02-02 19:27:54,270 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E8 Validation  4096/8413, done at 2024-02-02 19:27:59, 0:00:10\n",
      "2024-02-02 19:27:59,594 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E8 Validation  8413/8413, done at 2024-02-02 19:27:59\n",
      "2024-02-02 19:27:59,595 INFO     pid:38964 __main__:011:logMetrics E8 StockPCTLabelPredictLSTM\n",
      "2024-02-02 19:27:59,599 INFO     pid:38964 __main__:072:logMetrics E8 val      0.6830 loss\n",
      "2024-02-02 19:27:59,600 INFO     pid:38964 __main__:097:logMetrics E8 val        55.8% correct, 0.6048 precision, 0.3358 recall, 0.4318 f1 score\n",
      "2024-02-02 19:27:59,600 INFO     pid:38964 __main__:112:logMetrics E8 val_neg   0.6087 loss,  78.1% correct (105064 of 134598)\n",
      "2024-02-02 19:27:59,600 INFO     pid:38964 __main__:128:logMetrics E8 val_pos   0.7573 loss,  33.6% correct (45194 of 134598)\n",
      "2024-02-02 19:27:59,610 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E9 Training ----/35181, starting\n",
      "2024-02-02 19:27:59,769 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E9 Training   32/35181, done at 2024-02-02 19:28:41, 0:00:41\n",
      "2024-02-02 19:28:00,244 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E9 Training  256/35181, done at 2024-02-02 19:29:10, 0:01:10\n",
      "2024-02-02 19:28:02,415 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E9 Training 2048/35181, done at 2024-02-02 19:28:45, 0:00:46\n",
      "2024-02-02 19:28:20,367 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E9 Training 16384/35181, done at 2024-02-02 19:28:44, 0:00:44\n",
      "2024-02-02 19:28:43,277 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E9 Training 35181/35181, done at 2024-02-02 19:28:43\n",
      "2024-02-02 19:28:43,643 INFO     pid:38964 __main__:011:logMetrics E9 StockPCTLabelPredictLSTM\n",
      "2024-02-02 19:28:43,692 INFO     pid:38964 __main__:072:logMetrics E9 trn      0.6628 loss\n",
      "2024-02-02 19:28:43,692 INFO     pid:38964 __main__:097:logMetrics E9 trn        59.8% correct, 0.6112 precision, 0.5384 recall, 0.5725 f1 score\n",
      "2024-02-02 19:28:43,693 INFO     pid:38964 __main__:112:logMetrics E9 trn_neg   0.6613 loss,  65.8% correct (370135 of 562892)\n",
      "2024-02-02 19:28:43,693 INFO     pid:38964 __main__:128:logMetrics E9 trn_pos   0.6642 loss,  53.8% correct (303049 of 562892)\n",
      "2024-02-02 19:28:43,728 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E9 Validation  ----/8413, starting\n",
      "2024-02-02 19:28:43,844 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E9 Validation    16/8413, done at 2024-02-02 19:28:56, 0:00:12\n",
      "2024-02-02 19:28:43,902 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E9 Validation    64/8413, done at 2024-02-02 19:28:54, 0:00:10\n",
      "2024-02-02 19:28:44,139 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E9 Validation   256/8413, done at 2024-02-02 19:28:54, 0:00:10\n",
      "2024-02-02 19:28:45,130 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E9 Validation  1024/8413, done at 2024-02-02 19:28:54, 0:00:10\n",
      "2024-02-02 19:28:48,665 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E9 Validation  4096/8413, done at 2024-02-02 19:28:53, 0:00:09\n",
      "2024-02-02 19:28:53,577 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E9 Validation  8413/8413, done at 2024-02-02 19:28:53\n",
      "2024-02-02 19:28:53,579 INFO     pid:38964 __main__:011:logMetrics E9 StockPCTLabelPredictLSTM\n",
      "2024-02-02 19:28:53,582 INFO     pid:38964 __main__:072:logMetrics E9 val      0.6797 loss\n",
      "2024-02-02 19:28:53,583 INFO     pid:38964 __main__:097:logMetrics E9 val        57.5% correct, 0.5646 precision, 0.6553 recall, 0.6065 f1 score\n",
      "2024-02-02 19:28:53,583 INFO     pid:38964 __main__:112:logMetrics E9 val_neg   0.7375 loss,  49.5% correct (66573 of 134598)\n",
      "2024-02-02 19:28:53,583 INFO     pid:38964 __main__:128:logMetrics E9 val_pos   0.6219 loss,  65.5% correct (88199 of 134598)\n",
      "2024-02-02 19:28:53,594 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E10 Training ----/35181, starting\n",
      "2024-02-02 19:28:53,751 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E10 Training   32/35181, done at 2024-02-02 19:29:34, 0:00:40\n",
      "2024-02-02 19:28:54,050 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E10 Training  256/35181, done at 2024-02-02 19:29:39, 0:00:46\n",
      "2024-02-02 19:28:56,297 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E10 Training 2048/35181, done at 2024-02-02 19:29:38, 0:00:44\n",
      "2024-02-02 19:29:14,155 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E10 Training 16384/35181, done at 2024-02-02 19:29:37, 0:00:43\n",
      "2024-02-02 19:29:38,055 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E10 Training 35181/35181, done at 2024-02-02 19:29:38\n",
      "2024-02-02 19:29:38,427 INFO     pid:38964 __main__:011:logMetrics E10 StockPCTLabelPredictLSTM\n",
      "2024-02-02 19:29:38,469 INFO     pid:38964 __main__:072:logMetrics E10 trn      0.6626 loss\n",
      "2024-02-02 19:29:38,469 INFO     pid:38964 __main__:097:logMetrics E10 trn        59.8% correct, 0.6112 precision, 0.5413 recall, 0.5741 f1 score\n",
      "2024-02-02 19:29:38,470 INFO     pid:38964 __main__:112:logMetrics E10 trn_neg   0.6613 loss,  65.6% correct (369060 of 562892)\n",
      "2024-02-02 19:29:38,470 INFO     pid:38964 __main__:128:logMetrics E10 trn_pos   0.6638 loss,  54.1% correct (304702 of 562892)\n",
      "2024-02-02 19:29:38,504 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E10 Validation  ----/8413, starting\n",
      "2024-02-02 19:29:38,613 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E10 Validation    16/8413, done at 2024-02-02 19:29:48, 0:00:10\n",
      "2024-02-02 19:29:38,703 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E10 Validation    64/8413, done at 2024-02-02 19:29:53, 0:00:14\n",
      "2024-02-02 19:29:38,914 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E10 Validation   256/8413, done at 2024-02-02 19:29:49, 0:00:10\n",
      "2024-02-02 19:29:39,914 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E10 Validation  1024/8413, done at 2024-02-02 19:29:49, 0:00:10\n",
      "2024-02-02 19:29:43,682 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E10 Validation  4096/8413, done at 2024-02-02 19:29:49, 0:00:10\n",
      "2024-02-02 19:29:48,451 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E10 Validation  8413/8413, done at 2024-02-02 19:29:48\n",
      "2024-02-02 19:29:48,452 INFO     pid:38964 __main__:011:logMetrics E10 StockPCTLabelPredictLSTM\n",
      "2024-02-02 19:29:48,457 INFO     pid:38964 __main__:072:logMetrics E10 val      0.6814 loss\n",
      "2024-02-02 19:29:48,457 INFO     pid:38964 __main__:097:logMetrics E10 val        56.8% correct, 0.5618 precision, 0.6145 recall, 0.5870 f1 score\n",
      "2024-02-02 19:29:48,457 INFO     pid:38964 __main__:112:logMetrics E10 val_neg   0.7237 loss,  52.1% correct (70088 of 134598)\n",
      "2024-02-02 19:29:48,457 INFO     pid:38964 __main__:128:logMetrics E10 val_pos   0.6392 loss,  61.4% correct (82710 of 134598)\n",
      "2024-02-02 19:29:48,468 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E11 Training ----/35181, starting\n",
      "2024-02-02 19:29:48,627 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E11 Training   32/35181, done at 2024-02-02 19:30:33, 0:00:45\n",
      "2024-02-02 19:29:48,938 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E11 Training  256/35181, done at 2024-02-02 19:30:36, 0:00:48\n",
      "2024-02-02 19:29:51,168 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E11 Training 2048/35181, done at 2024-02-02 19:30:32, 0:00:44\n",
      "2024-02-02 19:30:09,464 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E11 Training 16384/35181, done at 2024-02-02 19:30:33, 0:00:44\n",
      "2024-02-02 19:30:32,037 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E11 Training 35181/35181, done at 2024-02-02 19:30:32\n",
      "2024-02-02 19:30:32,477 INFO     pid:38964 __main__:011:logMetrics E11 StockPCTLabelPredictLSTM\n",
      "2024-02-02 19:30:32,520 INFO     pid:38964 __main__:072:logMetrics E11 trn      0.6662 loss\n",
      "2024-02-02 19:30:32,520 INFO     pid:38964 __main__:097:logMetrics E11 trn        59.4% correct, 0.6008 precision, 0.5606 recall, 0.5800 f1 score\n",
      "2024-02-02 19:30:32,521 INFO     pid:38964 __main__:112:logMetrics E11 trn_neg   0.6658 loss,  62.7% correct (353194 of 562892)\n",
      "2024-02-02 19:30:32,521 INFO     pid:38964 __main__:128:logMetrics E11 trn_pos   0.6666 loss,  56.1% correct (315536 of 562892)\n",
      "2024-02-02 19:30:32,556 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E11 Validation  ----/8413, starting\n",
      "2024-02-02 19:30:32,668 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E11 Validation    16/8413, done at 2024-02-02 19:30:42, 0:00:10\n",
      "2024-02-02 19:30:32,725 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E11 Validation    64/8413, done at 2024-02-02 19:30:42, 0:00:09\n",
      "2024-02-02 19:30:32,973 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E11 Validation   256/8413, done at 2024-02-02 19:30:43, 0:00:10\n",
      "2024-02-02 19:30:33,977 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E11 Validation  1024/8413, done at 2024-02-02 19:30:43, 0:00:10\n",
      "2024-02-02 19:30:37,575 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E11 Validation  4096/8413, done at 2024-02-02 19:30:42, 0:00:10\n",
      "2024-02-02 19:30:42,611 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E11 Validation  8413/8413, done at 2024-02-02 19:30:42\n",
      "2024-02-02 19:30:42,612 INFO     pid:38964 __main__:011:logMetrics E11 StockPCTLabelPredictLSTM\n",
      "2024-02-02 19:30:42,616 INFO     pid:38964 __main__:072:logMetrics E11 val      0.6847 loss\n",
      "2024-02-02 19:30:42,617 INFO     pid:38964 __main__:097:logMetrics E11 val        56.1% correct, 0.5448 precision, 0.7387 recall, 0.6271 f1 score\n",
      "2024-02-02 19:30:42,617 INFO     pid:38964 __main__:112:logMetrics E11 val_neg   0.7625 loss,  38.3% correct (51525 of 134598)\n",
      "2024-02-02 19:30:42,617 INFO     pid:38964 __main__:128:logMetrics E11 val_pos   0.6069 loss,  73.9% correct (99427 of 134598)\n",
      "2024-02-02 19:30:42,628 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E12 Training ----/35181, starting\n",
      "2024-02-02 19:30:42,846 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E12 Training   32/35181, done at 2024-02-02 19:32:33, 0:01:50\n",
      "2024-02-02 19:30:43,111 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E12 Training  256/35181, done at 2024-02-02 19:31:32, 0:00:49\n",
      "2024-02-02 19:30:45,675 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E12 Training 2048/35181, done at 2024-02-02 19:31:33, 0:00:50\n",
      "2024-02-02 19:31:03,929 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E12 Training 16384/35181, done at 2024-02-02 19:31:28, 0:00:45\n",
      "2024-02-02 19:31:27,952 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E12 Training 35181/35181, done at 2024-02-02 19:31:27\n",
      "2024-02-02 19:31:28,318 INFO     pid:38964 __main__:011:logMetrics E12 StockPCTLabelPredictLSTM\n",
      "2024-02-02 19:31:28,360 INFO     pid:38964 __main__:072:logMetrics E12 trn      0.6642 loss\n",
      "2024-02-02 19:31:28,360 INFO     pid:38964 __main__:097:logMetrics E12 trn        59.6% correct, 0.6066 precision, 0.5485 recall, 0.5761 f1 score\n",
      "2024-02-02 19:31:28,361 INFO     pid:38964 __main__:112:logMetrics E12 trn_neg   0.6632 loss,  64.4% correct (362701 of 562892)\n",
      "2024-02-02 19:31:28,361 INFO     pid:38964 __main__:128:logMetrics E12 trn_pos   0.6652 loss,  54.8% correct (308723 of 562892)\n",
      "2024-02-02 19:31:28,393 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E12 Validation  ----/8413, starting\n",
      "2024-02-02 19:31:28,507 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E12 Validation    16/8413, done at 2024-02-02 19:31:38, 0:00:09\n",
      "2024-02-02 19:31:28,593 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E12 Validation    64/8413, done at 2024-02-02 19:31:42, 0:00:13\n",
      "2024-02-02 19:31:28,800 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E12 Validation   256/8413, done at 2024-02-02 19:31:38, 0:00:10\n",
      "2024-02-02 19:31:29,799 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E12 Validation  1024/8413, done at 2024-02-02 19:31:39, 0:00:10\n",
      "2024-02-02 19:31:33,388 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E12 Validation  4096/8413, done at 2024-02-02 19:31:38, 0:00:10\n",
      "2024-02-02 19:31:38,361 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E12 Validation  8413/8413, done at 2024-02-02 19:31:38\n",
      "2024-02-02 19:31:38,363 INFO     pid:38964 __main__:011:logMetrics E12 StockPCTLabelPredictLSTM\n",
      "2024-02-02 19:31:38,367 INFO     pid:38964 __main__:072:logMetrics E12 val      0.6831 loss\n",
      "2024-02-02 19:31:38,367 INFO     pid:38964 __main__:097:logMetrics E12 val        56.6% correct, 0.5548 precision, 0.6674 recall, 0.6059 f1 score\n",
      "2024-02-02 19:31:38,368 INFO     pid:38964 __main__:112:logMetrics E12 val_neg   0.7539 loss,  46.4% correct (62497 of 134598)\n",
      "2024-02-02 19:31:38,368 INFO     pid:38964 __main__:128:logMetrics E12 val_pos   0.6124 loss,  66.7% correct (89835 of 134598)\n",
      "2024-02-02 19:31:38,379 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E13 Training ----/35181, starting\n",
      "2024-02-02 19:31:38,565 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E13 Training   32/35181, done at 2024-02-02 19:32:22, 0:00:43\n",
      "2024-02-02 19:31:38,841 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E13 Training  256/35181, done at 2024-02-02 19:32:21, 0:00:43\n",
      "2024-02-02 19:31:41,395 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E13 Training 2048/35181, done at 2024-02-02 19:32:27, 0:00:49\n",
      "2024-02-02 19:31:59,558 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E13 Training 16384/35181, done at 2024-02-02 19:32:23, 0:00:45\n",
      "2024-02-02 19:32:23,331 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E13 Training 35181/35181, done at 2024-02-02 19:32:23\n",
      "2024-02-02 19:32:23,728 INFO     pid:38964 __main__:011:logMetrics E13 StockPCTLabelPredictLSTM\n",
      "2024-02-02 19:32:23,770 INFO     pid:38964 __main__:072:logMetrics E13 trn      0.6616 loss\n",
      "2024-02-02 19:32:23,771 INFO     pid:38964 __main__:097:logMetrics E13 trn        59.9% correct, 0.6116 precision, 0.5441 recall, 0.5759 f1 score\n",
      "2024-02-02 19:32:23,771 INFO     pid:38964 __main__:112:logMetrics E13 trn_neg   0.6601 loss,  65.4% correct (368383 of 562892)\n",
      "2024-02-02 19:32:23,772 INFO     pid:38964 __main__:128:logMetrics E13 trn_pos   0.6631 loss,  54.4% correct (306272 of 562892)\n",
      "2024-02-02 19:32:23,804 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E13 Validation  ----/8413, starting\n",
      "2024-02-02 19:32:23,913 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E13 Validation    16/8413, done at 2024-02-02 19:32:34, 0:00:10\n",
      "2024-02-02 19:32:24,001 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E13 Validation    64/8413, done at 2024-02-02 19:32:38, 0:00:14\n",
      "2024-02-02 19:32:24,407 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E13 Validation   256/8413, done at 2024-02-02 19:32:40, 0:00:16\n",
      "2024-02-02 19:32:25,218 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E13 Validation  1024/8413, done at 2024-02-02 19:32:34, 0:00:10\n",
      "2024-02-02 19:32:28,861 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E13 Validation  4096/8413, done at 2024-02-02 19:32:34, 0:00:10\n",
      "2024-02-02 19:32:34,010 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E13 Validation  8413/8413, done at 2024-02-02 19:32:34\n",
      "2024-02-02 19:32:34,011 INFO     pid:38964 __main__:011:logMetrics E13 StockPCTLabelPredictLSTM\n",
      "2024-02-02 19:32:34,015 INFO     pid:38964 __main__:072:logMetrics E13 val      0.6790 loss\n",
      "2024-02-02 19:32:34,016 INFO     pid:38964 __main__:097:logMetrics E13 val        57.0% correct, 0.5805 precision, 0.5016 recall, 0.5382 f1 score\n",
      "2024-02-02 19:32:34,016 INFO     pid:38964 __main__:112:logMetrics E13 val_neg   0.6780 loss,  63.8% correct (85810 of 134598)\n",
      "2024-02-02 19:32:34,016 INFO     pid:38964 __main__:128:logMetrics E13 val_pos   0.6801 loss,  50.2% correct (67513 of 134598)\n",
      "2024-02-02 19:32:34,028 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E14 Training ----/35181, starting\n",
      "2024-02-02 19:32:34,192 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E14 Training   32/35181, done at 2024-02-02 19:33:22, 0:00:48\n",
      "2024-02-02 19:32:34,686 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E14 Training  256/35181, done at 2024-02-02 19:33:48, 0:01:14\n",
      "2024-02-02 19:32:36,888 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E14 Training 2048/35181, done at 2024-02-02 19:33:21, 0:00:47\n",
      "2024-02-02 19:32:54,708 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E14 Training 16384/35181, done at 2024-02-02 19:33:18, 0:00:44\n",
      "2024-02-02 19:33:17,282 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E14 Training 35181/35181, done at 2024-02-02 19:33:17\n",
      "2024-02-02 19:33:17,642 INFO     pid:38964 __main__:011:logMetrics E14 StockPCTLabelPredictLSTM\n",
      "2024-02-02 19:33:17,682 INFO     pid:38964 __main__:072:logMetrics E14 trn      0.6613 loss\n",
      "2024-02-02 19:33:17,683 INFO     pid:38964 __main__:097:logMetrics E14 trn        60.0% correct, 0.6133 precision, 0.5400 recall, 0.5743 f1 score\n",
      "2024-02-02 19:33:17,683 INFO     pid:38964 __main__:112:logMetrics E14 trn_neg   0.6600 loss,  66.0% correct (371237 of 562892)\n",
      "2024-02-02 19:33:17,683 INFO     pid:38964 __main__:128:logMetrics E14 trn_pos   0.6626 loss,  54.0% correct (303948 of 562892)\n",
      "2024-02-02 19:33:17,716 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E14 Validation  ----/8413, starting\n",
      "2024-02-02 19:33:17,827 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E14 Validation    16/8413, done at 2024-02-02 19:33:27, 0:00:09\n",
      "2024-02-02 19:33:17,929 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E14 Validation    64/8413, done at 2024-02-02 19:33:33, 0:00:16\n",
      "2024-02-02 19:33:18,138 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E14 Validation   256/8413, done at 2024-02-02 19:33:28, 0:00:10\n",
      "2024-02-02 19:33:18,920 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E14 Validation  1024/8413, done at 2024-02-02 19:33:26, 0:00:09\n",
      "2024-02-02 19:33:22,546 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E14 Validation  4096/8413, done at 2024-02-02 19:33:27, 0:00:09\n",
      "2024-02-02 19:33:27,917 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E14 Validation  8413/8413, done at 2024-02-02 19:33:27\n",
      "2024-02-02 19:33:27,918 INFO     pid:38964 __main__:011:logMetrics E14 StockPCTLabelPredictLSTM\n",
      "2024-02-02 19:33:27,922 INFO     pid:38964 __main__:072:logMetrics E14 val      0.6799 loss\n",
      "2024-02-02 19:33:27,922 INFO     pid:38964 __main__:097:logMetrics E14 val        56.8% correct, 0.5889 precision, 0.4493 recall, 0.5097 f1 score\n",
      "2024-02-02 19:33:27,922 INFO     pid:38964 __main__:112:logMetrics E14 val_neg   0.6427 loss,  68.6% correct (92376 of 134598)\n",
      "2024-02-02 19:33:27,922 INFO     pid:38964 __main__:128:logMetrics E14 val_pos   0.7171 loss,  44.9% correct (60481 of 134598)\n",
      "2024-02-02 19:33:27,932 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E15 Training ----/35181, starting\n",
      "2024-02-02 19:33:28,090 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E15 Training   32/35181, done at 2024-02-02 19:34:09, 0:00:41\n",
      "2024-02-02 19:33:28,381 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E15 Training  256/35181, done at 2024-02-02 19:34:13, 0:00:45\n",
      "2024-02-02 19:33:30,611 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E15 Training 2048/35181, done at 2024-02-02 19:34:12, 0:00:43\n",
      "2024-02-02 19:33:48,021 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E15 Training 16384/35181, done at 2024-02-02 19:34:10, 0:00:42\n",
      "2024-02-02 19:34:11,025 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E15 Training 35181/35181, done at 2024-02-02 19:34:11\n",
      "2024-02-02 19:34:11,379 INFO     pid:38964 __main__:011:logMetrics E15 StockPCTLabelPredictLSTM\n",
      "2024-02-02 19:34:11,420 INFO     pid:38964 __main__:072:logMetrics E15 trn      0.6627 loss\n",
      "2024-02-02 19:34:11,421 INFO     pid:38964 __main__:097:logMetrics E15 trn        59.8% correct, 0.6088 precision, 0.5472 recall, 0.5763 f1 score\n",
      "2024-02-02 19:34:11,421 INFO     pid:38964 __main__:112:logMetrics E15 trn_neg   0.6613 loss,  64.8% correct (364974 of 562892)\n",
      "2024-02-02 19:34:11,421 INFO     pid:38964 __main__:128:logMetrics E15 trn_pos   0.6640 loss,  54.7% correct (308006 of 562892)\n",
      "2024-02-02 19:34:11,453 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E15 Validation  ----/8413, starting\n",
      "2024-02-02 19:34:11,561 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E15 Validation    16/8413, done at 2024-02-02 19:34:21, 0:00:10\n",
      "2024-02-02 19:34:11,659 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E15 Validation    64/8413, done at 2024-02-02 19:34:27, 0:00:15\n",
      "2024-02-02 19:34:11,858 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E15 Validation   256/8413, done at 2024-02-02 19:34:21, 0:00:10\n",
      "2024-02-02 19:34:13,055 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E15 Validation  1024/8413, done at 2024-02-02 19:34:23, 0:00:12\n",
      "2024-02-02 19:34:17,164 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E15 Validation  4096/8413, done at 2024-02-02 19:34:23, 0:00:11\n",
      "2024-02-02 19:34:22,360 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E15 Validation  8413/8413, done at 2024-02-02 19:34:22\n",
      "2024-02-02 19:34:22,361 INFO     pid:38964 __main__:011:logMetrics E15 StockPCTLabelPredictLSTM\n",
      "2024-02-02 19:34:22,365 INFO     pid:38964 __main__:072:logMetrics E15 val      0.6780 loss\n",
      "2024-02-02 19:34:22,366 INFO     pid:38964 __main__:097:logMetrics E15 val        57.6% correct, 0.5733 precision, 0.5964 recall, 0.5846 f1 score\n",
      "2024-02-02 19:34:22,366 INFO     pid:38964 __main__:112:logMetrics E15 val_neg   0.6953 loss,  55.6% correct (74859 of 134598)\n",
      "2024-02-02 19:34:22,366 INFO     pid:38964 __main__:128:logMetrics E15 val_pos   0.6607 loss,  59.6% correct (80276 of 134598)\n",
      "2024-02-02 19:34:22,377 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E16 Training ----/35181, starting\n",
      "2024-02-02 19:34:22,556 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E16 Training   32/35181, done at 2024-02-02 19:35:11, 0:00:49\n",
      "2024-02-02 19:34:22,819 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E16 Training  256/35181, done at 2024-02-02 19:35:04, 0:00:42\n",
      "2024-02-02 19:34:25,090 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E16 Training 2048/35181, done at 2024-02-02 19:35:06, 0:00:44\n",
      "2024-02-02 19:34:43,214 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E16 Training 16384/35181, done at 2024-02-02 19:35:06, 0:00:44\n",
      "2024-02-02 19:35:05,654 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E16 Training 35181/35181, done at 2024-02-02 19:35:05\n",
      "2024-02-02 19:35:06,033 INFO     pid:38964 __main__:011:logMetrics E16 StockPCTLabelPredictLSTM\n",
      "2024-02-02 19:35:06,073 INFO     pid:38964 __main__:072:logMetrics E16 trn      0.6684 loss\n",
      "2024-02-02 19:35:06,073 INFO     pid:38964 __main__:097:logMetrics E16 trn        58.9% correct, 0.5938 precision, 0.5658 recall, 0.5794 f1 score\n",
      "2024-02-02 19:35:06,074 INFO     pid:38964 __main__:112:logMetrics E16 trn_neg   0.6679 loss,  61.3% correct (345025 of 562892)\n",
      "2024-02-02 19:35:06,074 INFO     pid:38964 __main__:128:logMetrics E16 trn_pos   0.6690 loss,  56.6% correct (318475 of 562892)\n",
      "2024-02-02 19:35:06,107 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E16 Validation  ----/8413, starting\n",
      "2024-02-02 19:35:06,217 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E16 Validation    16/8413, done at 2024-02-02 19:35:16, 0:00:10\n",
      "2024-02-02 19:35:06,268 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E16 Validation    64/8413, done at 2024-02-02 19:35:15, 0:00:09\n",
      "2024-02-02 19:35:06,511 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E16 Validation   256/8413, done at 2024-02-02 19:35:16, 0:00:10\n",
      "2024-02-02 19:35:07,692 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E16 Validation  1024/8413, done at 2024-02-02 19:35:18, 0:00:12\n",
      "2024-02-02 19:35:11,429 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E16 Validation  4096/8413, done at 2024-02-02 19:35:16, 0:00:10\n",
      "2024-02-02 19:35:16,653 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E16 Validation  8413/8413, done at 2024-02-02 19:35:16\n",
      "2024-02-02 19:35:16,654 INFO     pid:38964 __main__:011:logMetrics E16 StockPCTLabelPredictLSTM\n",
      "2024-02-02 19:35:16,658 INFO     pid:38964 __main__:072:logMetrics E16 val      0.6975 loss\n",
      "2024-02-02 19:35:16,659 INFO     pid:38964 __main__:097:logMetrics E16 val        54.3% correct, 0.5256 precision, 0.8797 recall, 0.6581 f1 score\n",
      "2024-02-02 19:35:16,659 INFO     pid:38964 __main__:112:logMetrics E16 val_neg   0.8940 loss,  20.6% correct (27743 of 134598)\n",
      "2024-02-02 19:35:16,659 INFO     pid:38964 __main__:128:logMetrics E16 val_pos   0.5010 loss,  88.0% correct (118405 of 134598)\n",
      "2024-02-02 19:35:16,679 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E17 Training ----/35181, starting\n",
      "2024-02-02 19:35:16,837 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E17 Training   32/35181, done at 2024-02-02 19:35:57, 0:00:40\n",
      "2024-02-02 19:35:17,130 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E17 Training  256/35181, done at 2024-02-02 19:36:02, 0:00:45\n",
      "2024-02-02 19:35:19,543 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E17 Training 2048/35181, done at 2024-02-02 19:36:03, 0:00:47\n",
      "2024-02-02 19:35:37,305 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E17 Training 16384/35181, done at 2024-02-02 19:36:00, 0:00:44\n",
      "2024-02-02 19:36:00,399 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E17 Training 35181/35181, done at 2024-02-02 19:36:00\n",
      "2024-02-02 19:36:00,766 INFO     pid:38964 __main__:011:logMetrics E17 StockPCTLabelPredictLSTM\n",
      "2024-02-02 19:36:00,805 INFO     pid:38964 __main__:072:logMetrics E17 trn      0.6663 loss\n",
      "2024-02-02 19:36:00,805 INFO     pid:38964 __main__:097:logMetrics E17 trn        59.3% correct, 0.5991 precision, 0.5651 recall, 0.5816 f1 score\n",
      "2024-02-02 19:36:00,806 INFO     pid:38964 __main__:112:logMetrics E17 trn_neg   0.6657 loss,  62.2% correct (350019 of 562892)\n",
      "2024-02-02 19:36:00,806 INFO     pid:38964 __main__:128:logMetrics E17 trn_pos   0.6669 loss,  56.5% correct (318074 of 562892)\n",
      "2024-02-02 19:36:00,841 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E17 Validation  ----/8413, starting\n",
      "2024-02-02 19:36:00,967 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E17 Validation    16/8413, done at 2024-02-02 19:36:09, 0:00:08\n",
      "2024-02-02 19:36:01,023 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E17 Validation    64/8413, done at 2024-02-02 19:36:10, 0:00:09\n",
      "2024-02-02 19:36:01,233 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E17 Validation   256/8413, done at 2024-02-02 19:36:10, 0:00:09\n",
      "2024-02-02 19:36:02,253 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E17 Validation  1024/8413, done at 2024-02-02 19:36:11, 0:00:10\n",
      "2024-02-02 19:36:06,001 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E17 Validation  4096/8413, done at 2024-02-02 19:36:11, 0:00:10\n",
      "2024-02-02 19:36:11,416 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E17 Validation  8413/8413, done at 2024-02-02 19:36:11\n",
      "2024-02-02 19:36:11,418 INFO     pid:38964 __main__:011:logMetrics E17 StockPCTLabelPredictLSTM\n",
      "2024-02-02 19:36:11,422 INFO     pid:38964 __main__:072:logMetrics E17 val      0.6883 loss\n",
      "2024-02-02 19:36:11,423 INFO     pid:38964 __main__:097:logMetrics E17 val        56.6% correct, 0.5454 precision, 0.7900 recall, 0.6453 f1 score\n",
      "2024-02-02 19:36:11,423 INFO     pid:38964 __main__:112:logMetrics E17 val_neg   0.8302 loss,  34.2% correct (45978 of 134598)\n",
      "2024-02-02 19:36:11,423 INFO     pid:38964 __main__:128:logMetrics E17 val_pos   0.5463 loss,  79.0% correct (106329 of 134598)\n",
      "2024-02-02 19:36:11,433 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E18 Training ----/35181, starting\n",
      "2024-02-02 19:36:11,604 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E18 Training   32/35181, done at 2024-02-02 19:37:06, 0:00:55\n",
      "2024-02-02 19:36:11,898 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E18 Training  256/35181, done at 2024-02-02 19:36:58, 0:00:47\n",
      "2024-02-02 19:36:14,452 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E18 Training 2048/35181, done at 2024-02-02 19:37:01, 0:00:49\n",
      "2024-02-02 19:36:32,646 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E18 Training 16384/35181, done at 2024-02-02 19:36:56, 0:00:45\n",
      "2024-02-02 19:36:56,026 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E18 Training 35181/35181, done at 2024-02-02 19:36:56\n",
      "2024-02-02 19:36:56,415 INFO     pid:38964 __main__:011:logMetrics E18 StockPCTLabelPredictLSTM\n",
      "2024-02-02 19:36:56,454 INFO     pid:38964 __main__:072:logMetrics E18 trn      0.6663 loss\n",
      "2024-02-02 19:36:56,455 INFO     pid:38964 __main__:097:logMetrics E18 trn        59.4% correct, 0.5981 precision, 0.5715 recall, 0.5845 f1 score\n",
      "2024-02-02 19:36:56,455 INFO     pid:38964 __main__:112:logMetrics E18 trn_neg   0.6657 loss,  61.6% correct (346676 of 562892)\n",
      "2024-02-02 19:36:56,455 INFO     pid:38964 __main__:128:logMetrics E18 trn_pos   0.6669 loss,  57.2% correct (321705 of 562892)\n",
      "2024-02-02 19:36:56,488 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E18 Validation  ----/8413, starting\n",
      "2024-02-02 19:36:56,598 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E18 Validation    16/8413, done at 2024-02-02 19:37:07, 0:00:10\n",
      "2024-02-02 19:36:56,681 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E18 Validation    64/8413, done at 2024-02-02 19:37:10, 0:00:13\n",
      "2024-02-02 19:36:57,080 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E18 Validation   256/8413, done at 2024-02-02 19:37:13, 0:00:16\n",
      "2024-02-02 19:36:57,878 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E18 Validation  1024/8413, done at 2024-02-02 19:37:07, 0:00:10\n",
      "2024-02-02 19:37:01,821 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E18 Validation  4096/8413, done at 2024-02-02 19:37:07, 0:00:10\n",
      "2024-02-02 19:37:06,990 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E18 Validation  8413/8413, done at 2024-02-02 19:37:06\n",
      "2024-02-02 19:37:06,992 INFO     pid:38964 __main__:011:logMetrics E18 StockPCTLabelPredictLSTM\n",
      "2024-02-02 19:37:06,996 INFO     pid:38964 __main__:072:logMetrics E18 val      0.6864 loss\n",
      "2024-02-02 19:37:06,996 INFO     pid:38964 __main__:097:logMetrics E18 val        55.2% correct, 0.5335 precision, 0.8262 recall, 0.6484 f1 score\n",
      "2024-02-02 19:37:06,996 INFO     pid:38964 __main__:112:logMetrics E18 val_neg   0.8029 loss,  27.8% correct (37382 of 134598)\n",
      "2024-02-02 19:37:06,996 INFO     pid:38964 __main__:128:logMetrics E18 val_pos   0.5699 loss,  82.6% correct (111199 of 134598)\n",
      "2024-02-02 19:37:07,007 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E19 Training ----/35181, starting\n",
      "2024-02-02 19:37:07,186 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E19 Training   32/35181, done at 2024-02-02 19:37:52, 0:00:45\n",
      "2024-02-02 19:37:07,647 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E19 Training  256/35181, done at 2024-02-02 19:38:16, 0:01:09\n",
      "2024-02-02 19:37:09,845 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E19 Training 2048/35181, done at 2024-02-02 19:37:53, 0:00:46\n",
      "2024-02-02 19:37:27,969 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E19 Training 16384/35181, done at 2024-02-02 19:37:51, 0:00:44\n",
      "2024-02-02 19:37:51,437 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E19 Training 35181/35181, done at 2024-02-02 19:37:51\n",
      "2024-02-02 19:37:51,815 INFO     pid:38964 __main__:011:logMetrics E19 StockPCTLabelPredictLSTM\n",
      "2024-02-02 19:37:51,854 INFO     pid:38964 __main__:072:logMetrics E19 trn      0.6680 loss\n",
      "2024-02-02 19:37:51,854 INFO     pid:38964 __main__:097:logMetrics E19 trn        59.1% correct, 0.5958 precision, 0.5675 recall, 0.5813 f1 score\n",
      "2024-02-02 19:37:51,855 INFO     pid:38964 __main__:112:logMetrics E19 trn_neg   0.6673 loss,  61.5% correct (346190 of 562892)\n",
      "2024-02-02 19:37:51,855 INFO     pid:38964 __main__:128:logMetrics E19 trn_pos   0.6686 loss,  56.8% correct (319469 of 562892)\n",
      "2024-02-02 19:37:51,887 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E19 Validation  ----/8413, starting\n",
      "2024-02-02 19:37:51,998 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E19 Validation    16/8413, done at 2024-02-02 19:38:03, 0:00:11\n",
      "2024-02-02 19:37:52,100 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E19 Validation    64/8413, done at 2024-02-02 19:38:08, 0:00:16\n",
      "2024-02-02 19:37:52,303 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E19 Validation   256/8413, done at 2024-02-02 19:38:02, 0:00:10\n",
      "2024-02-02 19:37:53,091 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E19 Validation  1024/8413, done at 2024-02-02 19:38:01, 0:00:09\n",
      "2024-02-02 19:37:56,884 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E19 Validation  4096/8413, done at 2024-02-02 19:38:02, 0:00:10\n",
      "2024-02-02 19:38:02,091 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E19 Validation  8413/8413, done at 2024-02-02 19:38:02\n",
      "2024-02-02 19:38:02,093 INFO     pid:38964 __main__:011:logMetrics E19 StockPCTLabelPredictLSTM\n",
      "2024-02-02 19:38:02,097 INFO     pid:38964 __main__:072:logMetrics E19 val      0.6799 loss\n",
      "2024-02-02 19:38:02,097 INFO     pid:38964 __main__:097:logMetrics E19 val        57.5% correct, 0.5628 precision, 0.6707 recall, 0.6120 f1 score\n",
      "2024-02-02 19:38:02,098 INFO     pid:38964 __main__:112:logMetrics E19 val_neg   0.7332 loss,  47.9% correct (64462 of 134598)\n",
      "2024-02-02 19:38:02,098 INFO     pid:38964 __main__:128:logMetrics E19 val_pos   0.6267 loss,  67.1% correct (90269 of 134598)\n",
      "2024-02-02 19:38:02,109 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E20 Training ----/35181, starting\n",
      "2024-02-02 19:38:02,269 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E20 Training   32/35181, done at 2024-02-02 19:38:45, 0:00:43\n",
      "2024-02-02 19:38:02,559 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E20 Training  256/35181, done at 2024-02-02 19:38:47, 0:00:45\n",
      "2024-02-02 19:38:04,810 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E20 Training 2048/35181, done at 2024-02-02 19:38:46, 0:00:44\n",
      "2024-02-02 19:38:23,516 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E20 Training 16384/35181, done at 2024-02-02 19:38:47, 0:00:45\n",
      "2024-02-02 19:38:47,407 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E20 Training 35181/35181, done at 2024-02-02 19:38:47\n",
      "2024-02-02 19:38:47,808 INFO     pid:38964 __main__:011:logMetrics E20 StockPCTLabelPredictLSTM\n",
      "2024-02-02 19:38:47,847 INFO     pid:38964 __main__:072:logMetrics E20 trn      0.6687 loss\n",
      "2024-02-02 19:38:47,848 INFO     pid:38964 __main__:097:logMetrics E20 trn        58.9% correct, 0.5907 precision, 0.5769 recall, 0.5837 f1 score\n",
      "2024-02-02 19:38:47,848 INFO     pid:38964 __main__:112:logMetrics E20 trn_neg   0.6686 loss,  60.0% correct (337845 of 562892)\n",
      "2024-02-02 19:38:47,848 INFO     pid:38964 __main__:128:logMetrics E20 trn_pos   0.6689 loss,  57.7% correct (324748 of 562892)\n",
      "2024-02-02 19:38:47,879 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E20 Validation  ----/8413, starting\n",
      "2024-02-02 19:38:47,988 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E20 Validation    16/8413, done at 2024-02-02 19:38:57, 0:00:09\n",
      "2024-02-02 19:38:48,078 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E20 Validation    64/8413, done at 2024-02-02 19:39:02, 0:00:14\n",
      "2024-02-02 19:38:48,278 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E20 Validation   256/8413, done at 2024-02-02 19:38:58, 0:00:10\n",
      "2024-02-02 19:38:49,446 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E20 Validation  1024/8413, done at 2024-02-02 19:39:00, 0:00:12\n",
      "2024-02-02 19:38:53,546 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E20 Validation  4096/8413, done at 2024-02-02 19:38:59, 0:00:11\n",
      "2024-02-02 19:38:58,730 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E20 Validation  8413/8413, done at 2024-02-02 19:38:58\n",
      "2024-02-02 19:38:58,732 INFO     pid:38964 __main__:011:logMetrics E20 StockPCTLabelPredictLSTM\n",
      "2024-02-02 19:38:58,736 INFO     pid:38964 __main__:072:logMetrics E20 val      0.6864 loss\n",
      "2024-02-02 19:38:58,737 INFO     pid:38964 __main__:097:logMetrics E20 val        55.3% correct, 0.5340 precision, 0.8389 recall, 0.6526 f1 score\n",
      "2024-02-02 19:38:58,737 INFO     pid:38964 __main__:112:logMetrics E20 val_neg   0.8044 loss,  26.8% correct (36064 of 134598)\n",
      "2024-02-02 19:38:58,737 INFO     pid:38964 __main__:128:logMetrics E20 val_pos   0.5684 loss,  83.9% correct (112915 of 134598)\n",
      "2024-02-02 19:38:58,747 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E21 Training ----/35181, starting\n",
      "2024-02-02 19:38:58,913 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E21 Training   32/35181, done at 2024-02-02 19:39:45, 0:00:46\n",
      "2024-02-02 19:38:59,213 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E21 Training  256/35181, done at 2024-02-02 19:39:45, 0:00:47\n",
      "2024-02-02 19:39:01,394 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E21 Training 2048/35181, done at 2024-02-02 19:39:42, 0:00:43\n",
      "2024-02-02 19:39:19,029 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E21 Training 16384/35181, done at 2024-02-02 19:39:42, 0:00:43\n",
      "2024-02-02 19:39:41,702 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E21 Training 35181/35181, done at 2024-02-02 19:39:41\n",
      "2024-02-02 19:39:42,110 INFO     pid:38964 __main__:011:logMetrics E21 StockPCTLabelPredictLSTM\n",
      "2024-02-02 19:39:42,150 INFO     pid:38964 __main__:072:logMetrics E21 trn      0.6694 loss\n",
      "2024-02-02 19:39:42,151 INFO     pid:38964 __main__:097:logMetrics E21 trn        58.8% correct, 0.5904 precision, 0.5749 recall, 0.5826 f1 score\n",
      "2024-02-02 19:39:42,151 INFO     pid:38964 __main__:112:logMetrics E21 trn_neg   0.6689 loss,  60.1% correct (338426 of 562892)\n",
      "2024-02-02 19:39:42,151 INFO     pid:38964 __main__:128:logMetrics E21 trn_pos   0.6698 loss,  57.5% correct (323602 of 562892)\n",
      "2024-02-02 19:39:42,184 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E21 Validation  ----/8413, starting\n",
      "2024-02-02 19:39:42,295 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E21 Validation    16/8413, done at 2024-02-02 19:39:51, 0:00:09\n",
      "2024-02-02 19:39:42,354 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E21 Validation    64/8413, done at 2024-02-02 19:39:52, 0:00:10\n",
      "2024-02-02 19:39:42,608 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E21 Validation   256/8413, done at 2024-02-02 19:39:53, 0:00:10\n",
      "2024-02-02 19:39:43,618 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E21 Validation  1024/8413, done at 2024-02-02 19:39:53, 0:00:11\n",
      "2024-02-02 19:39:47,358 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E21 Validation  4096/8413, done at 2024-02-02 19:39:52, 0:00:10\n",
      "2024-02-02 19:39:52,360 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E21 Validation  8413/8413, done at 2024-02-02 19:39:52\n",
      "2024-02-02 19:39:52,362 INFO     pid:38964 __main__:011:logMetrics E21 StockPCTLabelPredictLSTM\n",
      "2024-02-02 19:39:52,367 INFO     pid:38964 __main__:072:logMetrics E21 val      0.6799 loss\n",
      "2024-02-02 19:39:52,368 INFO     pid:38964 __main__:097:logMetrics E21 val        57.3% correct, 0.5600 precision, 0.6769 recall, 0.6130 f1 score\n",
      "2024-02-02 19:39:52,368 INFO     pid:38964 __main__:112:logMetrics E21 val_neg   0.7462 loss,  46.8% correct (63023 of 134598)\n",
      "2024-02-02 19:39:52,368 INFO     pid:38964 __main__:128:logMetrics E21 val_pos   0.6135 loss,  67.7% correct (91113 of 134598)\n",
      "2024-02-02 19:39:52,380 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E22 Training ----/35181, starting\n",
      "2024-02-02 19:39:52,563 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E22 Training   32/35181, done at 2024-02-02 19:41:03, 0:01:10\n",
      "2024-02-02 19:39:52,830 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E22 Training  256/35181, done at 2024-02-02 19:40:37, 0:00:45\n",
      "2024-02-02 19:39:55,418 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E22 Training 2048/35181, done at 2024-02-02 19:40:42, 0:00:50\n",
      "2024-02-02 19:40:13,779 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E22 Training 16384/35181, done at 2024-02-02 19:40:38, 0:00:45\n",
      "2024-02-02 19:40:37,876 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E22 Training 35181/35181, done at 2024-02-02 19:40:37\n",
      "2024-02-02 19:40:38,267 INFO     pid:38964 __main__:011:logMetrics E22 StockPCTLabelPredictLSTM\n",
      "2024-02-02 19:40:38,308 INFO     pid:38964 __main__:072:logMetrics E22 trn      0.6669 loss\n",
      "2024-02-02 19:40:38,309 INFO     pid:38964 __main__:097:logMetrics E22 trn        59.2% correct, 0.5942 precision, 0.5821 recall, 0.5881 f1 score\n",
      "2024-02-02 19:40:38,309 INFO     pid:38964 __main__:112:logMetrics E22 trn_neg   0.6664 loss,  60.2% correct (339101 of 562892)\n",
      "2024-02-02 19:40:38,309 INFO     pid:38964 __main__:128:logMetrics E22 trn_pos   0.6674 loss,  58.2% correct (327674 of 562892)\n",
      "2024-02-02 19:40:38,340 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E22 Validation  ----/8413, starting\n",
      "2024-02-02 19:40:38,452 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E22 Validation    16/8413, done at 2024-02-02 19:40:50, 0:00:12\n",
      "2024-02-02 19:40:38,546 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E22 Validation    64/8413, done at 2024-02-02 19:40:53, 0:00:15\n",
      "2024-02-02 19:40:38,747 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E22 Validation   256/8413, done at 2024-02-02 19:40:48, 0:00:10\n",
      "2024-02-02 19:40:39,740 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E22 Validation  1024/8413, done at 2024-02-02 19:40:49, 0:00:10\n",
      "2024-02-02 19:40:43,509 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E22 Validation  4096/8413, done at 2024-02-02 19:40:48, 0:00:10\n",
      "2024-02-02 19:40:48,529 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E22 Validation  8413/8413, done at 2024-02-02 19:40:48\n",
      "2024-02-02 19:40:48,531 INFO     pid:38964 __main__:011:logMetrics E22 StockPCTLabelPredictLSTM\n",
      "2024-02-02 19:40:48,535 INFO     pid:38964 __main__:072:logMetrics E22 val      0.6812 loss\n",
      "2024-02-02 19:40:48,536 INFO     pid:38964 __main__:097:logMetrics E22 val        57.5% correct, 0.5607 precision, 0.6953 recall, 0.6208 f1 score\n",
      "2024-02-02 19:40:48,536 INFO     pid:38964 __main__:112:logMetrics E22 val_neg   0.7603 loss,  45.5% correct (61270 of 134598)\n",
      "2024-02-02 19:40:48,536 INFO     pid:38964 __main__:128:logMetrics E22 val_pos   0.6022 loss,  69.5% correct (93591 of 134598)\n",
      "2024-02-02 19:40:48,546 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E23 Training ----/35181, starting\n",
      "2024-02-02 19:40:48,727 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E23 Training   32/35181, done at 2024-02-02 19:41:32, 0:00:43\n",
      "2024-02-02 19:40:48,990 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E23 Training  256/35181, done at 2024-02-02 19:41:30, 0:00:41\n",
      "2024-02-02 19:40:51,442 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E23 Training 2048/35181, done at 2024-02-02 19:41:36, 0:00:47\n",
      "2024-02-02 19:41:08,917 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E23 Training 16384/35181, done at 2024-02-02 19:41:32, 0:00:43\n",
      "2024-02-02 19:41:32,565 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E23 Training 35181/35181, done at 2024-02-02 19:41:32\n",
      "2024-02-02 19:41:33,012 INFO     pid:38964 __main__:011:logMetrics E23 StockPCTLabelPredictLSTM\n",
      "2024-02-02 19:41:33,049 INFO     pid:38964 __main__:072:logMetrics E23 trn      0.6678 loss\n",
      "2024-02-02 19:41:33,050 INFO     pid:38964 __main__:097:logMetrics E23 trn        58.9% correct, 0.5922 precision, 0.5707 recall, 0.5812 f1 score\n",
      "2024-02-02 19:41:33,050 INFO     pid:38964 __main__:112:logMetrics E23 trn_neg   0.6673 loss,  60.7% correct (341641 of 562892)\n",
      "2024-02-02 19:41:33,050 INFO     pid:38964 __main__:128:logMetrics E23 trn_pos   0.6684 loss,  57.1% correct (321232 of 562892)\n",
      "2024-02-02 19:41:33,083 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E23 Validation  ----/8413, starting\n",
      "2024-02-02 19:41:33,191 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E23 Validation    16/8413, done at 2024-02-02 19:41:43, 0:00:10\n",
      "2024-02-02 19:41:33,281 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E23 Validation    64/8413, done at 2024-02-02 19:41:47, 0:00:14\n",
      "2024-02-02 19:41:33,682 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E23 Validation   256/8413, done at 2024-02-02 19:41:49, 0:00:16\n",
      "2024-02-02 19:41:34,488 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E23 Validation  1024/8413, done at 2024-02-02 19:41:43, 0:00:10\n",
      "2024-02-02 19:41:38,226 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E23 Validation  4096/8413, done at 2024-02-02 19:41:43, 0:00:10\n",
      "2024-02-02 19:41:43,160 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E23 Validation  8413/8413, done at 2024-02-02 19:41:43\n",
      "2024-02-02 19:41:43,162 INFO     pid:38964 __main__:011:logMetrics E23 StockPCTLabelPredictLSTM\n",
      "2024-02-02 19:41:43,166 INFO     pid:38964 __main__:072:logMetrics E23 val      0.6847 loss\n",
      "2024-02-02 19:41:43,167 INFO     pid:38964 __main__:097:logMetrics E23 val        56.1% correct, 0.5458 precision, 0.7283 recall, 0.6239 f1 score\n",
      "2024-02-02 19:41:43,167 INFO     pid:38964 __main__:112:logMetrics E23 val_neg   0.7758 loss,  39.4% correct (53010 of 134598)\n",
      "2024-02-02 19:41:43,167 INFO     pid:38964 __main__:128:logMetrics E23 val_pos   0.5935 loss,  72.8% correct (98024 of 134598)\n",
      "2024-02-02 19:41:43,178 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E24 Training ----/35181, starting\n",
      "2024-02-02 19:41:43,343 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E24 Training   32/35181, done at 2024-02-02 19:42:31, 0:00:48\n",
      "2024-02-02 19:41:43,847 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E24 Training  256/35181, done at 2024-02-02 19:42:58, 0:01:15\n",
      "2024-02-02 19:41:46,046 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E24 Training 2048/35181, done at 2024-02-02 19:42:30, 0:00:47\n",
      "2024-02-02 19:42:03,905 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E24 Training 16384/35181, done at 2024-02-02 19:42:27, 0:00:44\n",
      "2024-02-02 19:42:26,943 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E24 Training 35181/35181, done at 2024-02-02 19:42:26\n",
      "2024-02-02 19:42:27,321 INFO     pid:38964 __main__:011:logMetrics E24 StockPCTLabelPredictLSTM\n",
      "2024-02-02 19:42:27,361 INFO     pid:38964 __main__:072:logMetrics E24 trn      0.6706 loss\n",
      "2024-02-02 19:42:27,362 INFO     pid:38964 __main__:097:logMetrics E24 trn        58.4% correct, 0.5852 precision, 0.5739 recall, 0.5795 f1 score\n",
      "2024-02-02 19:42:27,362 INFO     pid:38964 __main__:112:logMetrics E24 trn_neg   0.6702 loss,  59.3% correct (333924 of 562892)\n",
      "2024-02-02 19:42:27,362 INFO     pid:38964 __main__:128:logMetrics E24 trn_pos   0.6710 loss,  57.4% correct (323064 of 562892)\n",
      "2024-02-02 19:42:27,393 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E24 Validation  ----/8413, starting\n",
      "2024-02-02 19:42:27,502 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E24 Validation    16/8413, done at 2024-02-02 19:42:37, 0:00:10\n",
      "2024-02-02 19:42:27,559 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E24 Validation    64/8413, done at 2024-02-02 19:42:37, 0:00:10\n",
      "2024-02-02 19:42:27,811 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E24 Validation   256/8413, done at 2024-02-02 19:42:38, 0:00:10\n",
      "2024-02-02 19:42:28,584 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E24 Validation  1024/8413, done at 2024-02-02 19:42:36, 0:00:09\n",
      "2024-02-02 19:42:32,382 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E24 Validation  4096/8413, done at 2024-02-02 19:42:37, 0:00:10\n",
      "2024-02-02 19:42:37,764 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E24 Validation  8413/8413, done at 2024-02-02 19:42:37\n",
      "2024-02-02 19:42:37,766 INFO     pid:38964 __main__:011:logMetrics E24 StockPCTLabelPredictLSTM\n",
      "2024-02-02 19:42:37,770 INFO     pid:38964 __main__:072:logMetrics E24 val      0.6857 loss\n",
      "2024-02-02 19:42:37,770 INFO     pid:38964 __main__:097:logMetrics E24 val        55.0% correct, 0.5340 precision, 0.7787 recall, 0.6335 f1 score\n",
      "2024-02-02 19:42:37,770 INFO     pid:38964 __main__:112:logMetrics E24 val_neg   0.7828 loss,  32.0% correct (43133 of 134598)\n",
      "2024-02-02 19:42:37,771 INFO     pid:38964 __main__:128:logMetrics E24 val_pos   0.5886 loss,  77.9% correct (104806 of 134598)\n",
      "2024-02-02 19:42:37,781 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E25 Training ----/35181, starting\n",
      "2024-02-02 19:42:37,941 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E25 Training   32/35181, done at 2024-02-02 19:43:21, 0:00:43\n",
      "2024-02-02 19:42:38,253 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E25 Training  256/35181, done at 2024-02-02 19:43:26, 0:00:48\n",
      "2024-02-02 19:42:40,638 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E25 Training 2048/35181, done at 2024-02-02 19:43:24, 0:00:47\n",
      "2024-02-02 19:42:58,474 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E25 Training 16384/35181, done at 2024-02-02 19:43:22, 0:00:44\n",
      "2024-02-02 19:43:21,475 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E25 Training 35181/35181, done at 2024-02-02 19:43:21\n",
      "2024-02-02 19:43:21,893 INFO     pid:38964 __main__:011:logMetrics E25 StockPCTLabelPredictLSTM\n",
      "2024-02-02 19:43:21,932 INFO     pid:38964 __main__:072:logMetrics E25 trn      0.6730 loss\n",
      "2024-02-02 19:43:21,933 INFO     pid:38964 __main__:097:logMetrics E25 trn        57.9% correct, 0.5787 precision, 0.5806 recall, 0.5797 f1 score\n",
      "2024-02-02 19:43:21,933 INFO     pid:38964 __main__:112:logMetrics E25 trn_neg   0.6723 loss,  57.7% correct (324955 of 562892)\n",
      "2024-02-02 19:43:21,933 INFO     pid:38964 __main__:128:logMetrics E25 trn_pos   0.6736 loss,  58.1% correct (326842 of 562892)\n",
      "2024-02-02 19:43:21,965 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E25 Validation  ----/8413, starting\n",
      "2024-02-02 19:43:22,075 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E25 Validation    16/8413, done at 2024-02-02 19:43:32, 0:00:10\n",
      "2024-02-02 19:43:22,184 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E25 Validation    64/8413, done at 2024-02-02 19:43:39, 0:00:17\n",
      "2024-02-02 19:43:22,387 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E25 Validation   256/8413, done at 2024-02-02 19:43:32, 0:00:10\n",
      "2024-02-02 19:43:23,386 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E25 Validation  1024/8413, done at 2024-02-02 19:43:32, 0:00:10\n",
      "2024-02-02 19:43:26,992 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E25 Validation  4096/8413, done at 2024-02-02 19:43:32, 0:00:10\n",
      "2024-02-02 19:43:31,799 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E25 Validation  8413/8413, done at 2024-02-02 19:43:31\n",
      "2024-02-02 19:43:31,801 INFO     pid:38964 __main__:011:logMetrics E25 StockPCTLabelPredictLSTM\n",
      "2024-02-02 19:43:31,805 INFO     pid:38964 __main__:072:logMetrics E25 val      0.6813 loss\n",
      "2024-02-02 19:43:31,805 INFO     pid:38964 __main__:097:logMetrics E25 val        57.3% correct, 0.5552 precision, 0.7320 recall, 0.6314 f1 score\n",
      "2024-02-02 19:43:31,805 INFO     pid:38964 __main__:112:logMetrics E25 val_neg   0.7818 loss,  41.4% correct (55667 of 134598)\n",
      "2024-02-02 19:43:31,806 INFO     pid:38964 __main__:128:logMetrics E25 val_pos   0.5808 loss,  73.2% correct (98522 of 134598)\n",
      "2024-02-02 19:43:31,817 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E26 Training ----/35181, starting\n",
      "2024-02-02 19:43:31,984 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E26 Training   32/35181, done at 2024-02-02 19:44:17, 0:00:45\n",
      "2024-02-02 19:43:32,279 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E26 Training  256/35181, done at 2024-02-02 19:44:18, 0:00:46\n",
      "2024-02-02 19:43:34,529 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E26 Training 2048/35181, done at 2024-02-02 19:44:16, 0:00:44\n",
      "2024-02-02 19:43:52,437 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E26 Training 16384/35181, done at 2024-02-02 19:44:15, 0:00:44\n",
      "2024-02-02 19:44:15,557 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E26 Training 35181/35181, done at 2024-02-02 19:44:15\n",
      "2024-02-02 19:44:15,950 INFO     pid:38964 __main__:011:logMetrics E26 StockPCTLabelPredictLSTM\n",
      "2024-02-02 19:44:15,990 INFO     pid:38964 __main__:072:logMetrics E26 trn      0.6730 loss\n",
      "2024-02-02 19:44:15,990 INFO     pid:38964 __main__:097:logMetrics E26 trn        58.1% correct, 0.5805 precision, 0.5826 recall, 0.5815 f1 score\n",
      "2024-02-02 19:44:15,991 INFO     pid:38964 __main__:112:logMetrics E26 trn_neg   0.6727 loss,  57.9% correct (325907 of 562892)\n",
      "2024-02-02 19:44:15,991 INFO     pid:38964 __main__:128:logMetrics E26 trn_pos   0.6733 loss,  58.3% correct (327917 of 562892)\n",
      "2024-02-02 19:44:16,026 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E26 Validation  ----/8413, starting\n",
      "2024-02-02 19:44:16,138 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E26 Validation    16/8413, done at 2024-02-02 19:44:26, 0:00:10\n",
      "2024-02-02 19:44:16,193 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E26 Validation    64/8413, done at 2024-02-02 19:44:25, 0:00:09\n",
      "2024-02-02 19:44:16,416 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E26 Validation   256/8413, done at 2024-02-02 19:44:25, 0:00:09\n",
      "2024-02-02 19:44:17,421 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E26 Validation  1024/8413, done at 2024-02-02 19:44:26, 0:00:10\n",
      "2024-02-02 19:44:21,026 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E26 Validation  4096/8413, done at 2024-02-02 19:44:26, 0:00:10\n",
      "2024-02-02 19:44:26,311 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E26 Validation  8413/8413, done at 2024-02-02 19:44:26\n",
      "2024-02-02 19:44:26,313 INFO     pid:38964 __main__:011:logMetrics E26 StockPCTLabelPredictLSTM\n",
      "2024-02-02 19:44:26,317 INFO     pid:38964 __main__:072:logMetrics E26 val      0.6811 loss\n",
      "2024-02-02 19:44:26,317 INFO     pid:38964 __main__:097:logMetrics E26 val        56.7% correct, 0.5531 precision, 0.6932 recall, 0.6152 f1 score\n",
      "2024-02-02 19:44:26,317 INFO     pid:38964 __main__:112:logMetrics E26 val_neg   0.6882 loss,  44.0% correct (59205 of 134598)\n",
      "2024-02-02 19:44:26,317 INFO     pid:38964 __main__:128:logMetrics E26 val_pos   0.6741 loss,  69.3% correct (93298 of 134598)\n",
      "2024-02-02 19:44:26,327 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E27 Training ----/35181, starting\n",
      "2024-02-02 19:44:26,494 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E27 Training   32/35181, done at 2024-02-02 19:45:17, 0:00:51\n",
      "2024-02-02 19:44:26,789 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E27 Training  256/35181, done at 2024-02-02 19:45:13, 0:00:46\n",
      "2024-02-02 19:44:29,471 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E27 Training 2048/35181, done at 2024-02-02 19:45:18, 0:00:51\n",
      "2024-02-02 19:44:48,239 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E27 Training 16384/35181, done at 2024-02-02 19:45:13, 0:00:46\n",
      "2024-02-02 19:45:11,933 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E27 Training 35181/35181, done at 2024-02-02 19:45:11\n",
      "2024-02-02 19:45:12,374 INFO     pid:38964 __main__:011:logMetrics E27 StockPCTLabelPredictLSTM\n",
      "2024-02-02 19:45:12,408 INFO     pid:38964 __main__:072:logMetrics E27 trn      0.6720 loss\n",
      "2024-02-02 19:45:12,409 INFO     pid:38964 __main__:097:logMetrics E27 trn        58.0% correct, 0.5809 precision, 0.5757 recall, 0.5783 f1 score\n",
      "2024-02-02 19:45:12,409 INFO     pid:38964 __main__:112:logMetrics E27 trn_neg   0.6709 loss,  58.5% correct (329119 of 562892)\n",
      "2024-02-02 19:45:12,410 INFO     pid:38964 __main__:128:logMetrics E27 trn_pos   0.6730 loss,  57.6% correct (324064 of 562892)\n",
      "2024-02-02 19:45:12,444 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E27 Validation  ----/8413, starting\n",
      "2024-02-02 19:45:12,553 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E27 Validation    16/8413, done at 2024-02-02 19:45:22, 0:00:10\n",
      "2024-02-02 19:45:12,607 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E27 Validation    64/8413, done at 2024-02-02 19:45:22, 0:00:09\n",
      "2024-02-02 19:45:12,853 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E27 Validation   256/8413, done at 2024-02-02 19:45:23, 0:00:10\n",
      "2024-02-02 19:45:13,848 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E27 Validation  1024/8413, done at 2024-02-02 19:45:23, 0:00:10\n",
      "2024-02-02 19:45:17,929 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E27 Validation  4096/8413, done at 2024-02-02 19:45:23, 0:00:11\n",
      "2024-02-02 19:45:23,694 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E27 Validation  8413/8413, done at 2024-02-02 19:45:23\n",
      "2024-02-02 19:45:23,696 INFO     pid:38964 __main__:011:logMetrics E27 StockPCTLabelPredictLSTM\n",
      "2024-02-02 19:45:23,700 INFO     pid:38964 __main__:072:logMetrics E27 val      0.6801 loss\n",
      "2024-02-02 19:45:23,701 INFO     pid:38964 __main__:097:logMetrics E27 val        57.1% correct, 0.5641 precision, 0.6268 recall, 0.5938 f1 score\n",
      "2024-02-02 19:45:23,701 INFO     pid:38964 __main__:112:logMetrics E27 val_neg   0.7040 loss,  51.6% correct (69419 of 134598)\n",
      "2024-02-02 19:45:23,701 INFO     pid:38964 __main__:128:logMetrics E27 val_pos   0.6562 loss,  62.7% correct (84360 of 134598)\n",
      "2024-02-02 19:45:23,712 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E28 Training ----/35181, starting\n",
      "2024-02-02 19:45:23,877 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E28 Training   32/35181, done at 2024-02-02 19:46:11, 0:00:47\n",
      "2024-02-02 19:45:24,163 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E28 Training  256/35181, done at 2024-02-02 19:46:09, 0:00:45\n",
      "2024-02-02 19:45:26,707 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E28 Training 2048/35181, done at 2024-02-02 19:46:13, 0:00:49\n",
      "2024-02-02 19:45:44,620 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E28 Training 16384/35181, done at 2024-02-02 19:46:08, 0:00:44\n",
      "2024-02-02 19:46:07,613 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E28 Training 35181/35181, done at 2024-02-02 19:46:07\n",
      "2024-02-02 19:46:08,010 INFO     pid:38964 __main__:011:logMetrics E28 StockPCTLabelPredictLSTM\n",
      "2024-02-02 19:46:08,048 INFO     pid:38964 __main__:072:logMetrics E28 trn      0.6726 loss\n",
      "2024-02-02 19:46:08,048 INFO     pid:38964 __main__:097:logMetrics E28 trn        57.9% correct, 0.5807 precision, 0.5661 recall, 0.5733 f1 score\n",
      "2024-02-02 19:46:08,049 INFO     pid:38964 __main__:112:logMetrics E28 trn_neg   0.6718 loss,  59.1% correct (332857 of 562892)\n",
      "2024-02-02 19:46:08,049 INFO     pid:38964 __main__:128:logMetrics E28 trn_pos   0.6734 loss,  56.6% correct (318642 of 562892)\n",
      "2024-02-02 19:46:08,080 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E28 Validation  ----/8413, starting\n",
      "2024-02-02 19:46:08,189 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E28 Validation    16/8413, done at 2024-02-02 19:46:17, 0:00:09\n",
      "2024-02-02 19:46:08,272 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E28 Validation    64/8413, done at 2024-02-02 19:46:21, 0:00:13\n",
      "2024-02-02 19:46:08,678 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E28 Validation   256/8413, done at 2024-02-02 19:46:24, 0:00:16\n",
      "2024-02-02 19:46:09,469 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E28 Validation  1024/8413, done at 2024-02-02 19:46:18, 0:00:10\n",
      "2024-02-02 19:46:13,086 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E28 Validation  4096/8413, done at 2024-02-02 19:46:18, 0:00:10\n",
      "2024-02-02 19:46:18,709 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E28 Validation  8413/8413, done at 2024-02-02 19:46:18\n",
      "2024-02-02 19:46:18,711 INFO     pid:38964 __main__:011:logMetrics E28 StockPCTLabelPredictLSTM\n",
      "2024-02-02 19:46:18,716 INFO     pid:38964 __main__:072:logMetrics E28 val      0.6841 loss\n",
      "2024-02-02 19:46:18,716 INFO     pid:38964 __main__:097:logMetrics E28 val        56.7% correct, 0.5480 precision, 0.7586 recall, 0.6364 f1 score\n",
      "2024-02-02 19:46:18,717 INFO     pid:38964 __main__:112:logMetrics E28 val_neg   0.7965 loss,  37.4% correct (50393 of 134598)\n",
      "2024-02-02 19:46:18,717 INFO     pid:38964 __main__:128:logMetrics E28 val_pos   0.5716 loss,  75.9% correct (102107 of 134598)\n",
      "2024-02-02 19:46:18,730 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E29 Training ----/35181, starting\n",
      "2024-02-02 19:46:18,944 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E29 Training   32/35181, done at 2024-02-02 19:48:01, 0:01:42\n",
      "2024-02-02 19:46:19,401 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E29 Training  256/35181, done at 2024-02-02 19:47:34, 0:01:15\n",
      "2024-02-02 19:46:21,653 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E29 Training 2048/35181, done at 2024-02-02 19:47:06, 0:00:48\n",
      "2024-02-02 19:46:40,224 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E29 Training 16384/35181, done at 2024-02-02 19:47:04, 0:00:45\n",
      "2024-02-02 19:47:04,239 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E29 Training 35181/35181, done at 2024-02-02 19:47:04\n",
      "2024-02-02 19:47:04,655 INFO     pid:38964 __main__:011:logMetrics E29 StockPCTLabelPredictLSTM\n",
      "2024-02-02 19:47:04,690 INFO     pid:38964 __main__:072:logMetrics E29 trn      0.6679 loss\n",
      "2024-02-02 19:47:04,690 INFO     pid:38964 __main__:097:logMetrics E29 trn        58.5% correct, 0.5918 precision, 0.5484 recall, 0.5693 f1 score\n",
      "2024-02-02 19:47:04,691 INFO     pid:38964 __main__:112:logMetrics E29 trn_neg   0.6665 loss,  62.2% correct (349920 of 562892)\n",
      "2024-02-02 19:47:04,691 INFO     pid:38964 __main__:128:logMetrics E29 trn_pos   0.6693 loss,  54.8% correct (308716 of 562892)\n",
      "2024-02-02 19:47:04,724 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E29 Validation  ----/8413, starting\n",
      "2024-02-02 19:47:05,039 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E29 Validation    16/8413, done at 2024-02-02 19:47:23, 0:00:18\n",
      "2024-02-02 19:47:05,095 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E29 Validation    64/8413, done at 2024-02-02 19:47:16, 0:00:11\n",
      "2024-02-02 19:47:05,302 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E29 Validation   256/8413, done at 2024-02-02 19:47:14, 0:00:09\n",
      "2024-02-02 19:47:06,097 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E29 Validation  1024/8413, done at 2024-02-02 19:47:13, 0:00:08\n",
      "2024-02-02 19:47:09,795 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E29 Validation  4096/8413, done at 2024-02-02 19:47:14, 0:00:09\n",
      "2024-02-02 19:47:14,733 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E29 Validation  8413/8413, done at 2024-02-02 19:47:14\n",
      "2024-02-02 19:47:14,734 INFO     pid:38964 __main__:011:logMetrics E29 StockPCTLabelPredictLSTM\n",
      "2024-02-02 19:47:14,739 INFO     pid:38964 __main__:072:logMetrics E29 val      0.6838 loss\n",
      "2024-02-02 19:47:14,739 INFO     pid:38964 __main__:097:logMetrics E29 val        55.8% correct, 0.5488 precision, 0.6549 recall, 0.5972 f1 score\n",
      "2024-02-02 19:47:14,740 INFO     pid:38964 __main__:112:logMetrics E29 val_neg   0.7251 loss,  46.1% correct (62111 of 134598)\n",
      "2024-02-02 19:47:14,740 INFO     pid:38964 __main__:128:logMetrics E29 val_pos   0.6425 loss,  65.5% correct (88153 of 134598)\n",
      "2024-02-02 19:47:14,751 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E30 Training ----/35181, starting\n",
      "2024-02-02 19:47:15,098 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E30 Training   32/35181, done at 2024-02-02 19:47:58, 0:00:43\n",
      "2024-02-02 19:47:15,379 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E30 Training  256/35181, done at 2024-02-02 19:47:59, 0:00:44\n",
      "2024-02-02 19:47:17,806 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E30 Training 2048/35181, done at 2024-02-02 19:48:02, 0:00:47\n",
      "2024-02-02 19:47:35,975 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E30 Training 16384/35181, done at 2024-02-02 19:47:59, 0:00:44\n",
      "2024-02-02 19:47:59,930 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E30 Training 35181/35181, done at 2024-02-02 19:47:59\n",
      "2024-02-02 19:48:00,326 INFO     pid:38964 __main__:011:logMetrics E30 StockPCTLabelPredictLSTM\n",
      "2024-02-02 19:48:00,365 INFO     pid:38964 __main__:072:logMetrics E30 trn      0.6676 loss\n",
      "2024-02-02 19:48:00,365 INFO     pid:38964 __main__:097:logMetrics E30 trn        58.6% correct, 0.5917 precision, 0.5530 recall, 0.5717 f1 score\n",
      "2024-02-02 19:48:00,366 INFO     pid:38964 __main__:112:logMetrics E30 trn_neg   0.6662 loss,  61.8% correct (348093 of 562892)\n",
      "2024-02-02 19:48:00,366 INFO     pid:38964 __main__:128:logMetrics E30 trn_pos   0.6691 loss,  55.3% correct (311302 of 562892)\n",
      "2024-02-02 19:48:00,399 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E30 Validation  ----/8413, starting\n",
      "2024-02-02 19:48:00,512 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E30 Validation    16/8413, done at 2024-02-02 19:48:12, 0:00:11\n",
      "2024-02-02 19:48:00,580 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E30 Validation    64/8413, done at 2024-02-02 19:48:12, 0:00:11\n",
      "2024-02-02 19:48:00,788 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E30 Validation   256/8413, done at 2024-02-02 19:48:10, 0:00:09\n",
      "2024-02-02 19:48:01,793 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E30 Validation  1024/8413, done at 2024-02-02 19:48:11, 0:00:10\n",
      "2024-02-02 19:48:05,361 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E30 Validation  4096/8413, done at 2024-02-02 19:48:10, 0:00:10\n",
      "2024-02-02 19:48:10,534 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E30 Validation  8413/8413, done at 2024-02-02 19:48:10\n",
      "2024-02-02 19:48:10,535 INFO     pid:38964 __main__:011:logMetrics E30 StockPCTLabelPredictLSTM\n",
      "2024-02-02 19:48:10,539 INFO     pid:38964 __main__:072:logMetrics E30 val      0.6976 loss\n",
      "2024-02-02 19:48:10,540 INFO     pid:38964 __main__:097:logMetrics E30 val        55.9% correct, 0.5408 precision, 0.7847 recall, 0.6403 f1 score\n",
      "2024-02-02 19:48:10,540 INFO     pid:38964 __main__:112:logMetrics E30 val_neg   0.8544 loss,  33.4% correct (44897 of 134598)\n",
      "2024-02-02 19:48:10,540 INFO     pid:38964 __main__:128:logMetrics E30 val_pos   0.5407 loss,  78.5% correct (105624 of 134598)\n",
      "2024-02-02 19:48:10,550 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E31 Training ----/35181, starting\n",
      "2024-02-02 19:48:10,714 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E31 Training   32/35181, done at 2024-02-02 19:48:56, 0:00:45\n",
      "2024-02-02 19:48:11,003 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E31 Training  256/35181, done at 2024-02-02 19:48:56, 0:00:45\n",
      "2024-02-02 19:48:13,240 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E31 Training 2048/35181, done at 2024-02-02 19:48:54, 0:00:44\n",
      "2024-02-02 19:48:30,271 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E31 Training 16384/35181, done at 2024-02-02 19:48:52, 0:00:42\n",
      "2024-02-02 19:48:53,004 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E31 Training 35181/35181, done at 2024-02-02 19:48:53\n",
      "2024-02-02 19:48:53,421 INFO     pid:38964 __main__:011:logMetrics E31 StockPCTLabelPredictLSTM\n",
      "2024-02-02 19:48:53,455 INFO     pid:38964 __main__:072:logMetrics E31 trn      0.6719 loss\n",
      "2024-02-02 19:48:53,456 INFO     pid:38964 __main__:097:logMetrics E31 trn        58.1% correct, 0.5821 precision, 0.5716 recall, 0.5768 f1 score\n",
      "2024-02-02 19:48:53,456 INFO     pid:38964 __main__:112:logMetrics E31 trn_neg   0.6713 loss,  59.0% correct (331892 of 562892)\n",
      "2024-02-02 19:48:53,456 INFO     pid:38964 __main__:128:logMetrics E31 trn_pos   0.6725 loss,  57.2% correct (321743 of 562892)\n",
      "2024-02-02 19:48:53,491 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E31 Validation  ----/8413, starting\n",
      "2024-02-02 19:48:53,600 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E31 Validation    16/8413, done at 2024-02-02 19:49:03, 0:00:09\n",
      "2024-02-02 19:48:53,688 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E31 Validation    64/8413, done at 2024-02-02 19:49:07, 0:00:14\n",
      "2024-02-02 19:48:53,894 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E31 Validation   256/8413, done at 2024-02-02 19:49:03, 0:00:10\n",
      "2024-02-02 19:48:54,905 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E31 Validation  1024/8413, done at 2024-02-02 19:49:04, 0:00:10\n",
      "2024-02-02 19:48:58,483 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E31 Validation  4096/8413, done at 2024-02-02 19:49:03, 0:00:10\n",
      "2024-02-02 19:49:03,711 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E31 Validation  8413/8413, done at 2024-02-02 19:49:03\n",
      "2024-02-02 19:49:03,713 INFO     pid:38964 __main__:011:logMetrics E31 StockPCTLabelPredictLSTM\n",
      "2024-02-02 19:49:03,717 INFO     pid:38964 __main__:072:logMetrics E31 val      0.6810 loss\n",
      "2024-02-02 19:49:03,717 INFO     pid:38964 __main__:097:logMetrics E31 val        56.8% correct, 0.5555 precision, 0.6808 recall, 0.6118 f1 score\n",
      "2024-02-02 19:49:03,717 INFO     pid:38964 __main__:112:logMetrics E31 val_neg   0.7146 loss,  45.5% correct (61262 of 134598)\n",
      "2024-02-02 19:49:03,717 INFO     pid:38964 __main__:128:logMetrics E31 val_pos   0.6474 loss,  68.1% correct (91639 of 134598)\n",
      "2024-02-02 19:49:03,727 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E32 Training ----/35181, starting\n",
      "2024-02-02 19:49:03,889 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E32 Training   32/35181, done at 2024-02-02 19:49:50, 0:00:46\n",
      "2024-02-02 19:49:04,207 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E32 Training  256/35181, done at 2024-02-02 19:49:53, 0:00:49\n",
      "2024-02-02 19:49:06,610 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E32 Training 2048/35181, done at 2024-02-02 19:49:51, 0:00:47\n",
      "2024-02-02 19:49:24,317 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E32 Training 16384/35181, done at 2024-02-02 19:49:47, 0:00:43\n",
      "2024-02-02 19:49:47,911 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E32 Training 35181/35181, done at 2024-02-02 19:49:47\n",
      "2024-02-02 19:49:48,304 INFO     pid:38964 __main__:011:logMetrics E32 StockPCTLabelPredictLSTM\n",
      "2024-02-02 19:49:48,341 INFO     pid:38964 __main__:072:logMetrics E32 trn      0.6702 loss\n",
      "2024-02-02 19:49:48,341 INFO     pid:38964 __main__:097:logMetrics E32 trn        58.0% correct, 0.5836 precision, 0.5582 recall, 0.5706 f1 score\n",
      "2024-02-02 19:49:48,342 INFO     pid:38964 __main__:112:logMetrics E32 trn_neg   0.6691 loss,  60.2% correct (338764 of 562892)\n",
      "2024-02-02 19:49:48,342 INFO     pid:38964 __main__:128:logMetrics E32 trn_pos   0.6714 loss,  55.8% correct (314180 of 562892)\n",
      "2024-02-02 19:49:48,374 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E32 Validation  ----/8413, starting\n",
      "2024-02-02 19:49:48,486 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E32 Validation    16/8413, done at 2024-02-02 19:49:59, 0:00:10\n",
      "2024-02-02 19:49:48,560 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E32 Validation    64/8413, done at 2024-02-02 19:50:00, 0:00:12\n",
      "2024-02-02 19:49:48,774 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E32 Validation   256/8413, done at 2024-02-02 19:49:58, 0:00:10\n",
      "2024-02-02 19:49:49,822 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E32 Validation  1024/8413, done at 2024-02-02 19:49:59, 0:00:11\n",
      "2024-02-02 19:49:53,593 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E32 Validation  4096/8413, done at 2024-02-02 19:49:58, 0:00:10\n",
      "2024-02-02 19:49:58,617 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E32 Validation  8413/8413, done at 2024-02-02 19:49:58\n",
      "2024-02-02 19:49:58,619 INFO     pid:38964 __main__:011:logMetrics E32 StockPCTLabelPredictLSTM\n",
      "2024-02-02 19:49:58,623 INFO     pid:38964 __main__:072:logMetrics E32 val      0.6865 loss\n",
      "2024-02-02 19:49:58,624 INFO     pid:38964 __main__:097:logMetrics E32 val        54.3% correct, 0.5940 precision, 0.2708 recall, 0.3720 f1 score\n",
      "2024-02-02 19:49:58,624 INFO     pid:38964 __main__:112:logMetrics E32 val_neg   0.6240 loss,  81.5% correct (109693 of 134598)\n",
      "2024-02-02 19:49:58,624 INFO     pid:38964 __main__:128:logMetrics E32 val_pos   0.7490 loss,  27.1% correct (36444 of 134598)\n",
      "2024-02-02 19:49:58,633 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E33 Training ----/35181, starting\n",
      "2024-02-02 19:49:58,794 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E33 Training   32/35181, done at 2024-02-02 19:50:41, 0:00:42\n",
      "2024-02-02 19:49:59,089 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E33 Training  256/35181, done at 2024-02-02 19:50:44, 0:00:45\n",
      "2024-02-02 19:50:01,519 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E33 Training 2048/35181, done at 2024-02-02 19:50:46, 0:00:47\n",
      "2024-02-02 19:50:19,879 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E33 Training 16384/35181, done at 2024-02-02 19:50:44, 0:00:45\n",
      "2024-02-02 19:50:43,762 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E33 Training 35181/35181, done at 2024-02-02 19:50:43\n",
      "2024-02-02 19:50:44,173 INFO     pid:38964 __main__:011:logMetrics E33 StockPCTLabelPredictLSTM\n",
      "2024-02-02 19:50:44,208 INFO     pid:38964 __main__:072:logMetrics E33 trn      0.6692 loss\n",
      "2024-02-02 19:50:44,209 INFO     pid:38964 __main__:097:logMetrics E33 trn        58.1% correct, 0.5914 precision, 0.5251 recall, 0.5563 f1 score\n",
      "2024-02-02 19:50:44,209 INFO     pid:38964 __main__:112:logMetrics E33 trn_neg   0.6677 loss,  63.7% correct (358691 of 562892)\n",
      "2024-02-02 19:50:44,209 INFO     pid:38964 __main__:128:logMetrics E33 trn_pos   0.6706 loss,  52.5% correct (295579 of 562892)\n",
      "2024-02-02 19:50:44,243 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E33 Validation  ----/8413, starting\n",
      "2024-02-02 19:50:44,370 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E33 Validation    16/8413, done at 2024-02-02 19:50:52, 0:00:08\n",
      "2024-02-02 19:50:44,428 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E33 Validation    64/8413, done at 2024-02-02 19:50:54, 0:00:09\n",
      "2024-02-02 19:50:45,039 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E33 Validation   256/8413, done at 2024-02-02 19:51:06, 0:00:22\n",
      "2024-02-02 19:50:45,849 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E33 Validation  1024/8413, done at 2024-02-02 19:50:56, 0:00:12\n",
      "2024-02-02 19:50:49,559 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E33 Validation  4096/8413, done at 2024-02-02 19:50:55, 0:00:10\n",
      "2024-02-02 19:50:54,755 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E33 Validation  8413/8413, done at 2024-02-02 19:50:54\n",
      "2024-02-02 19:50:54,757 INFO     pid:38964 __main__:011:logMetrics E33 StockPCTLabelPredictLSTM\n",
      "2024-02-02 19:50:54,761 INFO     pid:38964 __main__:072:logMetrics E33 val      0.6818 loss\n",
      "2024-02-02 19:50:54,762 INFO     pid:38964 __main__:097:logMetrics E33 val        56.6% correct, 0.5678 precision, 0.5542 recall, 0.5609 f1 score\n",
      "2024-02-02 19:50:54,762 INFO     pid:38964 __main__:112:logMetrics E33 val_neg   0.6928 loss,  57.8% correct (77809 of 134598)\n",
      "2024-02-02 19:50:54,762 INFO     pid:38964 __main__:128:logMetrics E33 val_pos   0.6709 loss,  55.4% correct (74599 of 134598)\n",
      "2024-02-02 19:50:54,774 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E34 Training ----/35181, starting\n",
      "2024-02-02 19:50:54,939 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E34 Training   32/35181, done at 2024-02-02 19:51:43, 0:00:48\n",
      "2024-02-02 19:50:55,617 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E34 Training  256/35181, done at 2024-02-02 19:52:34, 0:01:39\n",
      "2024-02-02 19:50:58,004 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E34 Training 2048/35181, done at 2024-02-02 19:51:48, 0:00:53\n",
      "2024-02-02 19:51:16,307 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E34 Training 16384/35181, done at 2024-02-02 19:51:40, 0:00:45\n",
      "2024-02-02 19:51:39,917 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E34 Training 35181/35181, done at 2024-02-02 19:51:39\n",
      "2024-02-02 19:51:40,301 INFO     pid:38964 __main__:011:logMetrics E34 StockPCTLabelPredictLSTM\n",
      "2024-02-02 19:51:40,340 INFO     pid:38964 __main__:072:logMetrics E34 trn      0.6691 loss\n",
      "2024-02-02 19:51:40,340 INFO     pid:38964 __main__:097:logMetrics E34 trn        58.2% correct, 0.5945 precision, 0.5171 recall, 0.5531 f1 score\n",
      "2024-02-02 19:51:40,341 INFO     pid:38964 __main__:112:logMetrics E34 trn_neg   0.6676 loss,  64.7% correct (364373 of 562892)\n",
      "2024-02-02 19:51:40,341 INFO     pid:38964 __main__:128:logMetrics E34 trn_pos   0.6706 loss,  51.7% correct (291074 of 562892)\n",
      "2024-02-02 19:51:40,372 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E34 Validation  ----/8413, starting\n",
      "2024-02-02 19:51:40,481 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E34 Validation    16/8413, done at 2024-02-02 19:51:49, 0:00:08\n",
      "2024-02-02 19:51:40,747 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E34 Validation    64/8413, done at 2024-02-02 19:52:18, 0:00:38\n",
      "2024-02-02 19:51:40,943 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E34 Validation   256/8413, done at 2024-02-02 19:51:56, 0:00:15\n",
      "2024-02-02 19:51:41,733 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E34 Validation  1024/8413, done at 2024-02-02 19:51:50, 0:00:10\n",
      "2024-02-02 19:51:45,300 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E34 Validation  4096/8413, done at 2024-02-02 19:51:50, 0:00:09\n",
      "2024-02-02 19:51:50,658 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E34 Validation  8413/8413, done at 2024-02-02 19:51:50\n",
      "2024-02-02 19:51:50,660 INFO     pid:38964 __main__:011:logMetrics E34 StockPCTLabelPredictLSTM\n",
      "2024-02-02 19:51:50,664 INFO     pid:38964 __main__:072:logMetrics E34 val      0.6860 loss\n",
      "2024-02-02 19:51:50,665 INFO     pid:38964 __main__:097:logMetrics E34 val        55.5% correct, 0.5360 precision, 0.8186 recall, 0.6479 f1 score\n",
      "2024-02-02 19:51:50,665 INFO     pid:38964 __main__:112:logMetrics E34 val_neg   0.7812 loss,  29.1% correct (39235 of 134598)\n",
      "2024-02-02 19:51:50,665 INFO     pid:38964 __main__:128:logMetrics E34 val_pos   0.5909 loss,  81.9% correct (110181 of 134598)\n",
      "2024-02-02 19:51:50,674 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E35 Training ----/35181, starting\n",
      "2024-02-02 19:51:51,038 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E35 Training   32/35181, done at 2024-02-02 19:56:32, 0:04:41\n",
      "2024-02-02 19:51:51,287 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E35 Training  256/35181, done at 2024-02-02 19:52:58, 0:01:07\n",
      "2024-02-02 19:51:53,439 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E35 Training 2048/35181, done at 2024-02-02 19:52:36, 0:00:45\n",
      "2024-02-02 19:52:10,898 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E35 Training 16384/35181, done at 2024-02-02 19:52:33, 0:00:43\n",
      "2024-02-02 19:52:33,741 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E35 Training 35181/35181, done at 2024-02-02 19:52:33\n",
      "2024-02-02 19:52:34,152 INFO     pid:38964 __main__:011:logMetrics E35 StockPCTLabelPredictLSTM\n",
      "2024-02-02 19:52:34,186 INFO     pid:38964 __main__:072:logMetrics E35 trn      0.6675 loss\n",
      "2024-02-02 19:52:34,186 INFO     pid:38964 __main__:097:logMetrics E35 trn        58.5% correct, 0.5973 precision, 0.5245 recall, 0.5586 f1 score\n",
      "2024-02-02 19:52:34,187 INFO     pid:38964 __main__:112:logMetrics E35 trn_neg   0.6657 loss,  64.6% correct (363822 of 562892)\n",
      "2024-02-02 19:52:34,187 INFO     pid:38964 __main__:128:logMetrics E35 trn_pos   0.6693 loss,  52.5% correct (295264 of 562892)\n",
      "2024-02-02 19:52:34,221 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E35 Validation  ----/8413, starting\n",
      "2024-02-02 19:52:34,330 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E35 Validation    16/8413, done at 2024-02-02 19:52:43, 0:00:09\n",
      "2024-02-02 19:52:34,422 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E35 Validation    64/8413, done at 2024-02-02 19:52:48, 0:00:14\n",
      "2024-02-02 19:52:34,623 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E35 Validation   256/8413, done at 2024-02-02 19:52:44, 0:00:10\n",
      "2024-02-02 19:52:35,613 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E35 Validation  1024/8413, done at 2024-02-02 19:52:45, 0:00:10\n",
      "2024-02-02 19:52:39,013 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E35 Validation  4096/8413, done at 2024-02-02 19:52:43, 0:00:09\n",
      "2024-02-02 19:52:44,247 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E35 Validation  8413/8413, done at 2024-02-02 19:52:44\n",
      "2024-02-02 19:52:44,248 INFO     pid:38964 __main__:011:logMetrics E35 StockPCTLabelPredictLSTM\n",
      "2024-02-02 19:52:44,252 INFO     pid:38964 __main__:072:logMetrics E35 val      0.6850 loss\n",
      "2024-02-02 19:52:44,253 INFO     pid:38964 __main__:097:logMetrics E35 val        55.8% correct, 0.5435 precision, 0.7268 recall, 0.6219 f1 score\n",
      "2024-02-02 19:52:44,253 INFO     pid:38964 __main__:112:logMetrics E35 val_neg   0.7452 loss,  39.0% correct (52429 of 134598)\n",
      "2024-02-02 19:52:44,253 INFO     pid:38964 __main__:128:logMetrics E35 val_pos   0.6248 loss,  72.7% correct (97827 of 134598)\n",
      "2024-02-02 19:52:44,264 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E36 Training ----/35181, starting\n",
      "2024-02-02 19:52:44,426 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E36 Training   32/35181, done at 2024-02-02 19:53:27, 0:00:42\n",
      "2024-02-02 19:52:44,733 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E36 Training  256/35181, done at 2024-02-02 19:53:31, 0:00:47\n",
      "2024-02-02 19:52:47,128 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E36 Training 2048/35181, done at 2024-02-02 19:53:31, 0:00:47\n",
      "2024-02-02 19:53:04,919 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E36 Training 16384/35181, done at 2024-02-02 19:53:28, 0:00:44\n",
      "2024-02-02 19:53:27,804 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E36 Training 35181/35181, done at 2024-02-02 19:53:27\n",
      "2024-02-02 19:53:28,193 INFO     pid:38964 __main__:011:logMetrics E36 StockPCTLabelPredictLSTM\n",
      "2024-02-02 19:53:28,231 INFO     pid:38964 __main__:072:logMetrics E36 trn      0.6673 loss\n",
      "2024-02-02 19:53:28,232 INFO     pid:38964 __main__:097:logMetrics E36 trn        58.6% correct, 0.5995 precision, 0.5203 recall, 0.5571 f1 score\n",
      "2024-02-02 19:53:28,232 INFO     pid:38964 __main__:112:logMetrics E36 trn_neg   0.6655 loss,  65.2% correct (367238 of 562892)\n",
      "2024-02-02 19:53:28,233 INFO     pid:38964 __main__:128:logMetrics E36 trn_pos   0.6690 loss,  52.0% correct (292899 of 562892)\n",
      "2024-02-02 19:53:28,264 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E36 Validation  ----/8413, starting\n",
      "2024-02-02 19:53:28,398 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E36 Validation    16/8413, done at 2024-02-02 19:53:39, 0:00:10\n",
      "2024-02-02 19:53:28,453 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E36 Validation    64/8413, done at 2024-02-02 19:53:38, 0:00:09\n",
      "2024-02-02 19:53:28,663 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E36 Validation   256/8413, done at 2024-02-02 19:53:37, 0:00:09\n",
      "2024-02-02 19:53:29,655 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E36 Validation  1024/8413, done at 2024-02-02 19:53:38, 0:00:10\n",
      "2024-02-02 19:53:33,214 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E36 Validation  4096/8413, done at 2024-02-02 19:53:38, 0:00:09\n",
      "2024-02-02 19:53:37,999 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E36 Validation  8413/8413, done at 2024-02-02 19:53:37\n",
      "2024-02-02 19:53:38,001 INFO     pid:38964 __main__:011:logMetrics E36 StockPCTLabelPredictLSTM\n",
      "2024-02-02 19:53:38,005 INFO     pid:38964 __main__:072:logMetrics E36 val      0.6834 loss\n",
      "2024-02-02 19:53:38,006 INFO     pid:38964 __main__:097:logMetrics E36 val        55.9% correct, 0.5689 precision, 0.4854 recall, 0.5238 f1 score\n",
      "2024-02-02 19:53:38,006 INFO     pid:38964 __main__:112:logMetrics E36 val_neg   0.6874 loss,  63.2% correct (85091 of 134598)\n",
      "2024-02-02 19:53:38,006 INFO     pid:38964 __main__:128:logMetrics E36 val_pos   0.6794 loss,  48.5% correct (65329 of 134598)\n",
      "2024-02-02 19:53:38,016 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E37 Training ----/35181, starting\n",
      "2024-02-02 19:53:38,173 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E37 Training   32/35181, done at 2024-02-02 19:54:19, 0:00:41\n",
      "2024-02-02 19:53:38,458 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E37 Training  256/35181, done at 2024-02-02 19:54:22, 0:00:44\n",
      "2024-02-02 19:53:40,726 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E37 Training 2048/35181, done at 2024-02-02 19:54:22, 0:00:44\n",
      "2024-02-02 19:53:59,510 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E37 Training 16384/35181, done at 2024-02-02 19:54:24, 0:00:45\n",
      "2024-02-02 19:54:22,564 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E37 Training 35181/35181, done at 2024-02-02 19:54:22\n",
      "2024-02-02 19:54:22,971 INFO     pid:38964 __main__:011:logMetrics E37 StockPCTLabelPredictLSTM\n",
      "2024-02-02 19:54:23,005 INFO     pid:38964 __main__:072:logMetrics E37 trn      0.6666 loss\n",
      "2024-02-02 19:54:23,006 INFO     pid:38964 __main__:097:logMetrics E37 trn        58.9% correct, 0.6035 precision, 0.5207 recall, 0.5591 f1 score\n",
      "2024-02-02 19:54:23,006 INFO     pid:38964 __main__:112:logMetrics E37 trn_neg   0.6646 loss,  65.8% correct (370293 of 562892)\n",
      "2024-02-02 19:54:23,006 INFO     pid:38964 __main__:128:logMetrics E37 trn_pos   0.6686 loss,  52.1% correct (293115 of 562892)\n",
      "2024-02-02 19:54:23,040 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E37 Validation  ----/8413, starting\n",
      "2024-02-02 19:54:23,149 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E37 Validation    16/8413, done at 2024-02-02 19:54:33, 0:00:10\n",
      "2024-02-02 19:54:23,232 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E37 Validation    64/8413, done at 2024-02-02 19:54:36, 0:00:13\n",
      "2024-02-02 19:54:23,443 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E37 Validation   256/8413, done at 2024-02-02 19:54:33, 0:00:10\n",
      "2024-02-02 19:54:24,442 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E37 Validation  1024/8413, done at 2024-02-02 19:54:33, 0:00:10\n",
      "2024-02-02 19:54:28,174 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E37 Validation  4096/8413, done at 2024-02-02 19:54:33, 0:00:10\n",
      "2024-02-02 19:54:33,246 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E37 Validation  8413/8413, done at 2024-02-02 19:54:33\n",
      "2024-02-02 19:54:33,248 INFO     pid:38964 __main__:011:logMetrics E37 StockPCTLabelPredictLSTM\n",
      "2024-02-02 19:54:33,252 INFO     pid:38964 __main__:072:logMetrics E37 val      0.6845 loss\n",
      "2024-02-02 19:54:33,252 INFO     pid:38964 __main__:097:logMetrics E37 val        56.3% correct, 0.5632 precision, 0.5613 recall, 0.5622 f1 score\n",
      "2024-02-02 19:54:33,252 INFO     pid:38964 __main__:112:logMetrics E37 val_neg   0.7127 loss,  56.5% correct (76015 of 134598)\n",
      "2024-02-02 19:54:33,253 INFO     pid:38964 __main__:128:logMetrics E37 val_pos   0.6564 loss,  56.1% correct (75544 of 134598)\n",
      "2024-02-02 19:54:33,263 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E38 Training ----/35181, starting\n",
      "2024-02-02 19:54:33,423 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E38 Training   32/35181, done at 2024-02-02 19:55:14, 0:00:41\n",
      "2024-02-02 19:54:33,718 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E38 Training  256/35181, done at 2024-02-02 19:55:19, 0:00:45\n",
      "2024-02-02 19:54:36,342 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E38 Training 2048/35181, done at 2024-02-02 19:55:24, 0:00:50\n",
      "2024-02-02 19:54:54,762 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E38 Training 16384/35181, done at 2024-02-02 19:55:19, 0:00:45\n",
      "2024-02-02 19:55:19,038 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E38 Training 35181/35181, done at 2024-02-02 19:55:19\n",
      "2024-02-02 19:55:19,429 INFO     pid:38964 __main__:011:logMetrics E38 StockPCTLabelPredictLSTM\n",
      "2024-02-02 19:55:19,467 INFO     pid:38964 __main__:072:logMetrics E38 trn      0.6674 loss\n",
      "2024-02-02 19:55:19,467 INFO     pid:38964 __main__:097:logMetrics E38 trn        58.8% correct, 0.5994 precision, 0.5280 recall, 0.5614 f1 score\n",
      "2024-02-02 19:55:19,467 INFO     pid:38964 __main__:112:logMetrics E38 trn_neg   0.6659 loss,  64.7% correct (364260 of 562892)\n",
      "2024-02-02 19:55:19,468 INFO     pid:38964 __main__:128:logMetrics E38 trn_pos   0.6688 loss,  52.8% correct (297181 of 562892)\n",
      "2024-02-02 19:55:19,498 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E38 Validation  ----/8413, starting\n",
      "2024-02-02 19:55:19,605 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E38 Validation    16/8413, done at 2024-02-02 19:55:29, 0:00:10\n",
      "2024-02-02 19:55:19,683 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E38 Validation    64/8413, done at 2024-02-02 19:55:32, 0:00:12\n",
      "2024-02-02 19:55:20,101 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E38 Validation   256/8413, done at 2024-02-02 19:55:36, 0:00:16\n",
      "2024-02-02 19:55:20,924 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E38 Validation  1024/8413, done at 2024-02-02 19:55:30, 0:00:10\n",
      "2024-02-02 19:55:24,519 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E38 Validation  4096/8413, done at 2024-02-02 19:55:29, 0:00:10\n",
      "2024-02-02 19:55:29,757 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E38 Validation  8413/8413, done at 2024-02-02 19:55:29\n",
      "2024-02-02 19:55:29,758 INFO     pid:38964 __main__:011:logMetrics E38 StockPCTLabelPredictLSTM\n",
      "2024-02-02 19:55:29,762 INFO     pid:38964 __main__:072:logMetrics E38 val      0.6813 loss\n",
      "2024-02-02 19:55:29,763 INFO     pid:38964 __main__:097:logMetrics E38 val        56.4% correct, 0.5549 precision, 0.6485 recall, 0.5981 f1 score\n",
      "2024-02-02 19:55:29,763 INFO     pid:38964 __main__:112:logMetrics E38 val_neg   0.7254 loss,  48.0% correct (64573 of 134598)\n",
      "2024-02-02 19:55:29,763 INFO     pid:38964 __main__:128:logMetrics E38 val_pos   0.6373 loss,  64.9% correct (87289 of 134598)\n",
      "2024-02-02 19:55:29,773 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E39 Training ----/35181, starting\n",
      "2024-02-02 19:55:29,938 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E39 Training   32/35181, done at 2024-02-02 19:56:14, 0:00:44\n",
      "2024-02-02 19:55:30,413 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E39 Training  256/35181, done at 2024-02-02 19:56:40, 0:01:11\n",
      "2024-02-02 19:55:32,940 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E39 Training 2048/35181, done at 2024-02-02 19:56:22, 0:00:52\n",
      "2024-02-02 19:55:51,672 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E39 Training 16384/35181, done at 2024-02-02 19:56:16, 0:00:46\n",
      "2024-02-02 19:56:15,781 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E39 Training 35181/35181, done at 2024-02-02 19:56:15\n",
      "2024-02-02 19:56:16,204 INFO     pid:38964 __main__:011:logMetrics E39 StockPCTLabelPredictLSTM\n",
      "2024-02-02 19:56:16,238 INFO     pid:38964 __main__:072:logMetrics E39 trn      0.6668 loss\n",
      "2024-02-02 19:56:16,239 INFO     pid:38964 __main__:097:logMetrics E39 trn        58.7% correct, 0.6000 precision, 0.5211 recall, 0.5578 f1 score\n",
      "2024-02-02 19:56:16,239 INFO     pid:38964 __main__:112:logMetrics E39 trn_neg   0.6652 loss,  65.3% correct (367365 of 562892)\n",
      "2024-02-02 19:56:16,239 INFO     pid:38964 __main__:128:logMetrics E39 trn_pos   0.6685 loss,  52.1% correct (293302 of 562892)\n",
      "2024-02-02 19:56:16,273 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E39 Validation  ----/8413, starting\n",
      "2024-02-02 19:56:16,380 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E39 Validation    16/8413, done at 2024-02-02 19:56:25, 0:00:09\n",
      "2024-02-02 19:56:16,655 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E39 Validation    64/8413, done at 2024-02-02 19:56:55, 0:00:39\n",
      "2024-02-02 19:56:16,865 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E39 Validation   256/8413, done at 2024-02-02 19:56:32, 0:00:16\n",
      "2024-02-02 19:56:17,668 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E39 Validation  1024/8413, done at 2024-02-02 19:56:27, 0:00:10\n",
      "2024-02-02 19:56:21,556 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E39 Validation  4096/8413, done at 2024-02-02 19:56:27, 0:00:10\n",
      "2024-02-02 19:56:27,185 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E39 Validation  8413/8413, done at 2024-02-02 19:56:27\n",
      "2024-02-02 19:56:27,186 INFO     pid:38964 __main__:011:logMetrics E39 StockPCTLabelPredictLSTM\n",
      "2024-02-02 19:56:27,190 INFO     pid:38964 __main__:072:logMetrics E39 val      0.6926 loss\n",
      "2024-02-02 19:56:27,190 INFO     pid:38964 __main__:097:logMetrics E39 val        54.7% correct, 0.5330 precision, 0.7672 recall, 0.6290 f1 score\n",
      "2024-02-02 19:56:27,191 INFO     pid:38964 __main__:112:logMetrics E39 val_neg   0.8353 loss,  32.8% correct (44124 of 134598)\n",
      "2024-02-02 19:56:27,191 INFO     pid:38964 __main__:128:logMetrics E39 val_pos   0.5499 loss,  76.7% correct (103259 of 134598)\n",
      "2024-02-02 19:56:27,201 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E40 Training ----/35181, starting\n",
      "2024-02-02 19:56:27,368 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E40 Training   32/35181, done at 2024-02-02 19:57:17, 0:00:50\n",
      "2024-02-02 19:56:27,860 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E40 Training  256/35181, done at 2024-02-02 19:57:41, 0:01:14\n",
      "2024-02-02 19:56:30,078 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E40 Training 2048/35181, done at 2024-02-02 19:57:14, 0:00:47\n",
      "2024-02-02 19:56:48,166 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E40 Training 16384/35181, done at 2024-02-02 19:57:12, 0:00:44\n",
      "2024-02-02 19:57:12,336 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E40 Training 35181/35181, done at 2024-02-02 19:57:12\n",
      "2024-02-02 19:57:12,735 INFO     pid:38964 __main__:011:logMetrics E40 StockPCTLabelPredictLSTM\n",
      "2024-02-02 19:57:12,770 INFO     pid:38964 __main__:072:logMetrics E40 trn      0.6672 loss\n",
      "2024-02-02 19:57:12,771 INFO     pid:38964 __main__:097:logMetrics E40 trn        58.6% correct, 0.5979 precision, 0.5259 recall, 0.5596 f1 score\n",
      "2024-02-02 19:57:12,771 INFO     pid:38964 __main__:112:logMetrics E40 trn_neg   0.6655 loss,  64.6% correct (363800 of 562892)\n",
      "2024-02-02 19:57:12,771 INFO     pid:38964 __main__:128:logMetrics E40 trn_pos   0.6688 loss,  52.6% correct (296030 of 562892)\n",
      "2024-02-02 19:57:12,803 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E40 Validation  ----/8413, starting\n",
      "2024-02-02 19:57:12,932 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E40 Validation    16/8413, done at 2024-02-02 19:57:35, 0:00:22\n",
      "2024-02-02 19:57:12,986 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E40 Validation    64/8413, done at 2024-02-02 19:57:25, 0:00:12\n",
      "2024-02-02 19:57:13,194 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E40 Validation   256/8413, done at 2024-02-02 19:57:22, 0:00:09\n",
      "2024-02-02 19:57:14,191 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E40 Validation  1024/8413, done at 2024-02-02 19:57:23, 0:00:10\n",
      "2024-02-02 19:57:17,790 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E40 Validation  4096/8413, done at 2024-02-02 19:57:22, 0:00:10\n",
      "2024-02-02 19:57:23,232 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E40 Validation  8413/8413, done at 2024-02-02 19:57:23\n",
      "2024-02-02 19:57:23,234 INFO     pid:38964 __main__:011:logMetrics E40 StockPCTLabelPredictLSTM\n",
      "2024-02-02 19:57:23,239 INFO     pid:38964 __main__:072:logMetrics E40 val      0.6841 loss\n",
      "2024-02-02 19:57:23,239 INFO     pid:38964 __main__:097:logMetrics E40 val        56.1% correct, 0.5449 precision, 0.7438 recall, 0.6290 f1 score\n",
      "2024-02-02 19:57:23,239 INFO     pid:38964 __main__:112:logMetrics E40 val_neg   0.7417 loss,  37.9% correct (50964 of 134598)\n",
      "2024-02-02 19:57:23,240 INFO     pid:38964 __main__:128:logMetrics E40 val_pos   0.6264 loss,  74.4% correct (100118 of 134598)\n",
      "2024-02-02 19:57:23,250 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E41 Training ----/35181, starting\n",
      "2024-02-02 19:57:23,413 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E41 Training   32/35181, done at 2024-02-02 19:58:08, 0:00:45\n",
      "2024-02-02 19:57:23,713 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E41 Training  256/35181, done at 2024-02-02 19:58:10, 0:00:46\n",
      "2024-02-02 19:57:25,980 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E41 Training 2048/35181, done at 2024-02-02 19:58:08, 0:00:44\n",
      "2024-02-02 19:57:43,927 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E41 Training 16384/35181, done at 2024-02-02 19:58:07, 0:00:44\n",
      "2024-02-02 19:58:07,243 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E41 Training 35181/35181, done at 2024-02-02 19:58:07\n",
      "2024-02-02 19:58:07,666 INFO     pid:38964 __main__:011:logMetrics E41 StockPCTLabelPredictLSTM\n",
      "2024-02-02 19:58:07,699 INFO     pid:38964 __main__:072:logMetrics E41 trn      0.6664 loss\n",
      "2024-02-02 19:58:07,699 INFO     pid:38964 __main__:097:logMetrics E41 trn        58.9% correct, 0.6032 precision, 0.5216 recall, 0.5594 f1 score\n",
      "2024-02-02 19:58:07,699 INFO     pid:38964 __main__:112:logMetrics E41 trn_neg   0.6646 loss,  65.7% correct (369761 of 562892)\n",
      "2024-02-02 19:58:07,700 INFO     pid:38964 __main__:128:logMetrics E41 trn_pos   0.6682 loss,  52.2% correct (293582 of 562892)\n",
      "2024-02-02 19:58:07,734 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E41 Validation  ----/8413, starting\n",
      "2024-02-02 19:58:07,847 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E41 Validation    16/8413, done at 2024-02-02 19:58:20, 0:00:12\n",
      "2024-02-02 19:58:07,902 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E41 Validation    64/8413, done at 2024-02-02 19:58:18, 0:00:10\n",
      "2024-02-02 19:58:08,100 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E41 Validation   256/8413, done at 2024-02-02 19:58:16, 0:00:09\n",
      "2024-02-02 19:58:09,170 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E41 Validation  1024/8413, done at 2024-02-02 19:58:18, 0:00:11\n",
      "2024-02-02 19:58:12,949 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E41 Validation  4096/8413, done at 2024-02-02 19:58:18, 0:00:10\n",
      "2024-02-02 19:58:17,752 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E41 Validation  8413/8413, done at 2024-02-02 19:58:17\n",
      "2024-02-02 19:58:17,753 INFO     pid:38964 __main__:011:logMetrics E41 StockPCTLabelPredictLSTM\n",
      "2024-02-02 19:58:17,757 INFO     pid:38964 __main__:072:logMetrics E41 val      0.6786 loss\n",
      "2024-02-02 19:58:17,757 INFO     pid:38964 __main__:097:logMetrics E41 val        56.7% correct, 0.6164 precision, 0.3542 recall, 0.4499 f1 score\n",
      "2024-02-02 19:58:17,757 INFO     pid:38964 __main__:112:logMetrics E41 val_neg   0.6420 loss,  78.0% correct (104932 of 134598)\n",
      "2024-02-02 19:58:17,757 INFO     pid:38964 __main__:128:logMetrics E41 val_pos   0.7152 loss,  35.4% correct (47671 of 134598)\n",
      "2024-02-02 19:58:17,767 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E42 Training ----/35181, starting\n",
      "2024-02-02 19:58:17,936 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E42 Training   32/35181, done at 2024-02-02 19:59:08, 0:00:50\n",
      "2024-02-02 19:58:18,237 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E42 Training  256/35181, done at 2024-02-02 19:59:05, 0:00:47\n",
      "2024-02-02 19:58:20,486 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E42 Training 2048/35181, done at 2024-02-02 19:59:02, 0:00:44\n",
      "2024-02-02 19:58:38,667 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E42 Training 16384/35181, done at 2024-02-02 19:59:02, 0:00:44\n",
      "2024-02-02 19:59:00,745 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E42 Training 35181/35181, done at 2024-02-02 19:59:00\n",
      "2024-02-02 19:59:01,154 INFO     pid:38964 __main__:011:logMetrics E42 StockPCTLabelPredictLSTM\n",
      "2024-02-02 19:59:01,184 INFO     pid:38964 __main__:072:logMetrics E42 trn      0.6659 loss\n",
      "2024-02-02 19:59:01,185 INFO     pid:38964 __main__:097:logMetrics E42 trn        58.9% correct, 0.6053 precision, 0.5132 recall, 0.5555 f1 score\n",
      "2024-02-02 19:59:01,185 INFO     pid:38964 __main__:112:logMetrics E42 trn_neg   0.6640 loss,  66.5% correct (374536 of 562892)\n",
      "2024-02-02 19:59:01,186 INFO     pid:38964 __main__:128:logMetrics E42 trn_pos   0.6677 loss,  51.3% correct (288902 of 562892)\n",
      "2024-02-02 19:59:01,217 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E42 Validation  ----/8413, starting\n",
      "2024-02-02 19:59:01,330 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E42 Validation    16/8413, done at 2024-02-02 19:59:13, 0:00:12\n",
      "2024-02-02 19:59:01,415 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E42 Validation    64/8413, done at 2024-02-02 19:59:15, 0:00:14\n",
      "2024-02-02 19:59:01,633 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E42 Validation   256/8413, done at 2024-02-02 19:59:12, 0:00:10\n",
      "2024-02-02 19:59:02,625 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E42 Validation  1024/8413, done at 2024-02-02 19:59:12, 0:00:10\n",
      "2024-02-02 19:59:06,146 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E42 Validation  4096/8413, done at 2024-02-02 19:59:11, 0:00:09\n",
      "2024-02-02 19:59:11,566 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E42 Validation  8413/8413, done at 2024-02-02 19:59:11\n",
      "2024-02-02 19:59:11,568 INFO     pid:38964 __main__:011:logMetrics E42 StockPCTLabelPredictLSTM\n",
      "2024-02-02 19:59:11,572 INFO     pid:38964 __main__:072:logMetrics E42 val      0.6878 loss\n",
      "2024-02-02 19:59:11,572 INFO     pid:38964 __main__:097:logMetrics E42 val        56.1% correct, 0.5425 precision, 0.7753 recall, 0.6383 f1 score\n",
      "2024-02-02 19:59:11,573 INFO     pid:38964 __main__:112:logMetrics E42 val_neg   0.8178 loss,  34.6% correct (46591 of 134598)\n",
      "2024-02-02 19:59:11,573 INFO     pid:38964 __main__:128:logMetrics E42 val_pos   0.5578 loss,  77.5% correct (104348 of 134598)\n",
      "2024-02-02 19:59:11,583 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E43 Training ----/35181, starting\n",
      "2024-02-02 19:59:11,747 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E43 Training   32/35181, done at 2024-02-02 19:59:57, 0:00:45\n",
      "2024-02-02 19:59:12,035 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E43 Training  256/35181, done at 2024-02-02 19:59:56, 0:00:45\n",
      "2024-02-02 19:59:14,600 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E43 Training 2048/35181, done at 2024-02-02 20:00:01, 0:00:49\n",
      "2024-02-02 19:59:32,223 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E43 Training 16384/35181, done at 2024-02-02 19:59:55, 0:00:44\n",
      "2024-02-02 19:59:55,683 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E43 Training 35181/35181, done at 2024-02-02 19:59:55\n",
      "2024-02-02 19:59:56,100 INFO     pid:38964 __main__:011:logMetrics E43 StockPCTLabelPredictLSTM\n",
      "2024-02-02 19:59:56,134 INFO     pid:38964 __main__:072:logMetrics E43 trn      0.6662 loss\n",
      "2024-02-02 19:59:56,134 INFO     pid:38964 __main__:097:logMetrics E43 trn        58.9% correct, 0.6011 precision, 0.5284 recall, 0.5624 f1 score\n",
      "2024-02-02 19:59:56,134 INFO     pid:38964 __main__:112:logMetrics E43 trn_neg   0.6645 loss,  64.9% correct (365465 of 562892)\n",
      "2024-02-02 19:59:56,135 INFO     pid:38964 __main__:128:logMetrics E43 trn_pos   0.6678 loss,  52.8% correct (297457 of 562892)\n",
      "2024-02-02 19:59:56,168 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E43 Validation  ----/8413, starting\n",
      "2024-02-02 19:59:56,278 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E43 Validation    16/8413, done at 2024-02-02 20:00:05, 0:00:09\n",
      "2024-02-02 19:59:56,366 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E43 Validation    64/8413, done at 2024-02-02 20:00:10, 0:00:13\n",
      "2024-02-02 19:59:56,575 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E43 Validation   256/8413, done at 2024-02-02 20:00:06, 0:00:10\n",
      "2024-02-02 19:59:57,582 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E43 Validation  1024/8413, done at 2024-02-02 20:00:07, 0:00:10\n",
      "2024-02-02 20:00:01,182 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E43 Validation  4096/8413, done at 2024-02-02 20:00:06, 0:00:10\n",
      "2024-02-02 20:00:06,406 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E43 Validation  8413/8413, done at 2024-02-02 20:00:06\n",
      "2024-02-02 20:00:06,408 INFO     pid:38964 __main__:011:logMetrics E43 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:00:06,412 INFO     pid:38964 __main__:072:logMetrics E43 val      0.6864 loss\n",
      "2024-02-02 20:00:06,412 INFO     pid:38964 __main__:097:logMetrics E43 val        57.3% correct, 0.5601 precision, 0.6775 recall, 0.6132 f1 score\n",
      "2024-02-02 20:00:06,413 INFO     pid:38964 __main__:112:logMetrics E43 val_neg   0.7612 loss,  46.8% correct (62973 of 134598)\n",
      "2024-02-02 20:00:06,413 INFO     pid:38964 __main__:128:logMetrics E43 val_pos   0.6116 loss,  67.8% correct (91195 of 134598)\n",
      "2024-02-02 20:00:06,424 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E44 Training ----/35181, starting\n",
      "2024-02-02 20:00:06,594 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E44 Training   32/35181, done at 2024-02-02 20:00:55, 0:00:48\n",
      "2024-02-02 20:00:06,892 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E44 Training  256/35181, done at 2024-02-02 20:00:53, 0:00:46\n",
      "2024-02-02 20:00:09,329 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E44 Training 2048/35181, done at 2024-02-02 20:00:54, 0:00:47\n",
      "2024-02-02 20:00:26,976 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E44 Training 16384/35181, done at 2024-02-02 20:00:50, 0:00:43\n",
      "2024-02-02 20:00:49,831 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E44 Training 35181/35181, done at 2024-02-02 20:00:49\n",
      "2024-02-02 20:00:50,223 INFO     pid:38964 __main__:011:logMetrics E44 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:00:50,254 INFO     pid:38964 __main__:072:logMetrics E44 trn      0.6658 loss\n",
      "2024-02-02 20:00:50,255 INFO     pid:38964 __main__:097:logMetrics E44 trn        58.9% correct, 0.6002 precision, 0.5333 recall, 0.5648 f1 score\n",
      "2024-02-02 20:00:50,255 INFO     pid:38964 __main__:112:logMetrics E44 trn_neg   0.6641 loss,  64.5% correct (362915 of 562892)\n",
      "2024-02-02 20:00:50,256 INFO     pid:38964 __main__:128:logMetrics E44 trn_pos   0.6675 loss,  53.3% correct (300195 of 562892)\n",
      "2024-02-02 20:00:50,289 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E44 Validation  ----/8413, starting\n",
      "2024-02-02 20:00:50,429 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E44 Validation    16/8413, done at 2024-02-02 20:01:18, 0:00:27\n",
      "2024-02-02 20:00:50,486 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E44 Validation    64/8413, done at 2024-02-02 20:01:04, 0:00:14\n",
      "2024-02-02 20:00:50,889 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E44 Validation   256/8413, done at 2024-02-02 20:01:07, 0:00:16\n",
      "2024-02-02 20:00:51,693 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E44 Validation  1024/8413, done at 2024-02-02 20:01:01, 0:00:10\n",
      "2024-02-02 20:00:55,437 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E44 Validation  4096/8413, done at 2024-02-02 20:01:00, 0:00:10\n",
      "2024-02-02 20:01:00,868 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E44 Validation  8413/8413, done at 2024-02-02 20:01:00\n",
      "2024-02-02 20:01:00,870 INFO     pid:38964 __main__:011:logMetrics E44 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:01:00,874 INFO     pid:38964 __main__:072:logMetrics E44 val      0.6837 loss\n",
      "2024-02-02 20:01:00,874 INFO     pid:38964 __main__:097:logMetrics E44 val        56.1% correct, 0.5565 precision, 0.6002 recall, 0.5776 f1 score\n",
      "2024-02-02 20:01:00,874 INFO     pid:38964 __main__:112:logMetrics E44 val_neg   0.7426 loss,  52.2% correct (70216 of 134598)\n",
      "2024-02-02 20:01:00,874 INFO     pid:38964 __main__:128:logMetrics E44 val_pos   0.6247 loss,  60.0% correct (80792 of 134598)\n",
      "2024-02-02 20:01:00,885 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E45 Training ----/35181, starting\n",
      "2024-02-02 20:01:01,086 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E45 Training   32/35181, done at 2024-02-02 20:02:25, 0:01:24\n",
      "2024-02-02 20:01:01,544 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E45 Training  256/35181, done at 2024-02-02 20:02:14, 0:01:13\n",
      "2024-02-02 20:01:03,744 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E45 Training 2048/35181, done at 2024-02-02 20:01:47, 0:00:46\n",
      "2024-02-02 20:01:21,755 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E45 Training 16384/35181, done at 2024-02-02 20:01:45, 0:00:44\n",
      "2024-02-02 20:01:44,742 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E45 Training 35181/35181, done at 2024-02-02 20:01:44\n",
      "2024-02-02 20:01:45,201 INFO     pid:38964 __main__:011:logMetrics E45 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:01:45,231 INFO     pid:38964 __main__:072:logMetrics E45 trn      0.6661 loss\n",
      "2024-02-02 20:01:45,231 INFO     pid:38964 __main__:097:logMetrics E45 trn        58.7% correct, 0.5993 precision, 0.5234 recall, 0.5588 f1 score\n",
      "2024-02-02 20:01:45,231 INFO     pid:38964 __main__:112:logMetrics E45 trn_neg   0.6643 loss,  65.0% correct (365873 of 562892)\n",
      "2024-02-02 20:01:45,232 INFO     pid:38964 __main__:128:logMetrics E45 trn_pos   0.6679 loss,  52.3% correct (294615 of 562892)\n",
      "2024-02-02 20:01:45,268 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E45 Validation  ----/8413, starting\n",
      "2024-02-02 20:01:45,377 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E45 Validation    16/8413, done at 2024-02-02 20:01:54, 0:00:09\n",
      "2024-02-02 20:01:45,429 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E45 Validation    64/8413, done at 2024-02-02 20:01:54, 0:00:09\n",
      "2024-02-02 20:01:45,627 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E45 Validation   256/8413, done at 2024-02-02 20:01:54, 0:00:08\n",
      "2024-02-02 20:01:46,473 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E45 Validation  1024/8413, done at 2024-02-02 20:01:54, 0:00:09\n",
      "2024-02-02 20:01:50,099 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E45 Validation  4096/8413, done at 2024-02-02 20:01:55, 0:00:09\n",
      "2024-02-02 20:01:55,344 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E45 Validation  8413/8413, done at 2024-02-02 20:01:55\n",
      "2024-02-02 20:01:55,345 INFO     pid:38964 __main__:011:logMetrics E45 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:01:55,350 INFO     pid:38964 __main__:072:logMetrics E45 val      0.6794 loss\n",
      "2024-02-02 20:01:55,350 INFO     pid:38964 __main__:097:logMetrics E45 val        57.8% correct, 0.5701 precision, 0.6318 recall, 0.5993 f1 score\n",
      "2024-02-02 20:01:55,350 INFO     pid:38964 __main__:112:logMetrics E45 val_neg   0.7066 loss,  52.3% correct (70462 of 134598)\n",
      "2024-02-02 20:01:55,351 INFO     pid:38964 __main__:128:logMetrics E45 val_pos   0.6522 loss,  63.2% correct (85038 of 134598)\n",
      "2024-02-02 20:01:55,362 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E46 Training ----/35181, starting\n",
      "2024-02-02 20:01:55,527 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E46 Training   32/35181, done at 2024-02-02 20:02:37, 0:00:41\n",
      "2024-02-02 20:01:55,829 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E46 Training  256/35181, done at 2024-02-02 20:02:42, 0:00:46\n",
      "2024-02-02 20:01:58,075 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E46 Training 2048/35181, done at 2024-02-02 20:02:39, 0:00:44\n",
      "2024-02-02 20:02:15,897 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E46 Training 16384/35181, done at 2024-02-02 20:02:39, 0:00:43\n",
      "2024-02-02 20:02:39,499 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E46 Training 35181/35181, done at 2024-02-02 20:02:39\n",
      "2024-02-02 20:02:39,920 INFO     pid:38964 __main__:011:logMetrics E46 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:02:39,953 INFO     pid:38964 __main__:072:logMetrics E46 trn      0.6660 loss\n",
      "2024-02-02 20:02:39,954 INFO     pid:38964 __main__:097:logMetrics E46 trn        58.7% correct, 0.5989 precision, 0.5273 recall, 0.5608 f1 score\n",
      "2024-02-02 20:02:39,954 INFO     pid:38964 __main__:112:logMetrics E46 trn_neg   0.6643 loss,  64.7% correct (364100 of 562892)\n",
      "2024-02-02 20:02:39,954 INFO     pid:38964 __main__:128:logMetrics E46 trn_pos   0.6677 loss,  52.7% correct (296819 of 562892)\n",
      "2024-02-02 20:02:39,985 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E46 Validation  ----/8413, starting\n",
      "2024-02-02 20:02:40,130 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E46 Validation    16/8413, done at 2024-02-02 20:02:48, 0:00:08\n",
      "2024-02-02 20:02:40,186 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E46 Validation    64/8413, done at 2024-02-02 20:02:49, 0:00:09\n",
      "2024-02-02 20:02:40,392 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E46 Validation   256/8413, done at 2024-02-02 20:02:49, 0:00:09\n",
      "2024-02-02 20:02:41,582 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E46 Validation  1024/8413, done at 2024-02-02 20:02:52, 0:00:12\n",
      "2024-02-02 20:02:45,514 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E46 Validation  4096/8413, done at 2024-02-02 20:02:51, 0:00:11\n",
      "2024-02-02 20:02:50,718 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E46 Validation  8413/8413, done at 2024-02-02 20:02:50\n",
      "2024-02-02 20:02:50,720 INFO     pid:38964 __main__:011:logMetrics E46 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:02:50,724 INFO     pid:38964 __main__:072:logMetrics E46 val      0.6841 loss\n",
      "2024-02-02 20:02:50,724 INFO     pid:38964 __main__:097:logMetrics E46 val        56.3% correct, 0.5494 precision, 0.6954 recall, 0.6139 f1 score\n",
      "2024-02-02 20:02:50,725 INFO     pid:38964 __main__:112:logMetrics E46 val_neg   0.7661 loss,  43.0% correct (57837 of 134598)\n",
      "2024-02-02 20:02:50,725 INFO     pid:38964 __main__:128:logMetrics E46 val_pos   0.6021 loss,  69.5% correct (93606 of 134598)\n",
      "2024-02-02 20:02:50,736 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E47 Training ----/35181, starting\n",
      "2024-02-02 20:02:50,900 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E47 Training   32/35181, done at 2024-02-02 20:03:36, 0:00:45\n",
      "2024-02-02 20:02:51,201 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E47 Training  256/35181, done at 2024-02-02 20:03:37, 0:00:47\n",
      "2024-02-02 20:02:53,641 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E47 Training 2048/35181, done at 2024-02-02 20:03:38, 0:00:47\n",
      "2024-02-02 20:03:12,317 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E47 Training 16384/35181, done at 2024-02-02 20:03:36, 0:00:46\n",
      "2024-02-02 20:03:34,755 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E47 Training 35181/35181, done at 2024-02-02 20:03:34\n",
      "2024-02-02 20:03:35,161 INFO     pid:38964 __main__:011:logMetrics E47 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:03:35,196 INFO     pid:38964 __main__:072:logMetrics E47 trn      0.6660 loss\n",
      "2024-02-02 20:03:35,197 INFO     pid:38964 __main__:097:logMetrics E47 trn        59.0% correct, 0.5982 precision, 0.5464 recall, 0.5711 f1 score\n",
      "2024-02-02 20:03:35,197 INFO     pid:38964 __main__:112:logMetrics E47 trn_neg   0.6641 loss,  63.3% correct (356333 of 562892)\n",
      "2024-02-02 20:03:35,197 INFO     pid:38964 __main__:128:logMetrics E47 trn_pos   0.6678 loss,  54.6% correct (307565 of 562892)\n",
      "2024-02-02 20:03:35,231 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E47 Validation  ----/8413, starting\n",
      "2024-02-02 20:03:35,340 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E47 Validation    16/8413, done at 2024-02-02 20:03:45, 0:00:10\n",
      "2024-02-02 20:03:35,432 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E47 Validation    64/8413, done at 2024-02-02 20:03:50, 0:00:14\n",
      "2024-02-02 20:03:35,634 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E47 Validation   256/8413, done at 2024-02-02 20:03:45, 0:00:10\n",
      "2024-02-02 20:03:36,623 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E47 Validation  1024/8413, done at 2024-02-02 20:03:46, 0:00:10\n",
      "2024-02-02 20:03:40,528 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E47 Validation  4096/8413, done at 2024-02-02 20:03:46, 0:00:10\n",
      "2024-02-02 20:03:45,906 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E47 Validation  8413/8413, done at 2024-02-02 20:03:45\n",
      "2024-02-02 20:03:45,908 INFO     pid:38964 __main__:011:logMetrics E47 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:03:45,912 INFO     pid:38964 __main__:072:logMetrics E47 val      0.6846 loss\n",
      "2024-02-02 20:03:45,912 INFO     pid:38964 __main__:097:logMetrics E47 val        57.2% correct, 0.5578 precision, 0.6988 recall, 0.6204 f1 score\n",
      "2024-02-02 20:03:45,912 INFO     pid:38964 __main__:112:logMetrics E47 val_neg   0.7547 loss,  44.6% correct (60038 of 134598)\n",
      "2024-02-02 20:03:45,912 INFO     pid:38964 __main__:128:logMetrics E47 val_pos   0.6144 loss,  69.9% correct (94063 of 134598)\n",
      "2024-02-02 20:03:45,922 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E48 Training ----/35181, starting\n",
      "2024-02-02 20:03:46,085 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E48 Training   32/35181, done at 2024-02-02 20:04:29, 0:00:43\n",
      "2024-02-02 20:03:46,407 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E48 Training  256/35181, done at 2024-02-02 20:04:35, 0:00:49\n",
      "2024-02-02 20:03:48,788 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E48 Training 2048/35181, done at 2024-02-02 20:04:33, 0:00:47\n",
      "2024-02-02 20:04:07,271 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E48 Training 16384/35181, done at 2024-02-02 20:04:31, 0:00:45\n",
      "2024-02-02 20:04:30,938 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E48 Training 35181/35181, done at 2024-02-02 20:04:30\n",
      "2024-02-02 20:04:31,338 INFO     pid:38964 __main__:011:logMetrics E48 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:04:31,374 INFO     pid:38964 __main__:072:logMetrics E48 trn      0.6651 loss\n",
      "2024-02-02 20:04:31,374 INFO     pid:38964 __main__:097:logMetrics E48 trn        59.1% correct, 0.6026 precision, 0.5343 recall, 0.5664 f1 score\n",
      "2024-02-02 20:04:31,374 INFO     pid:38964 __main__:112:logMetrics E48 trn_neg   0.6633 loss,  64.8% correct (364554 of 562892)\n",
      "2024-02-02 20:04:31,375 INFO     pid:38964 __main__:128:logMetrics E48 trn_pos   0.6668 loss,  53.4% correct (300772 of 562892)\n",
      "2024-02-02 20:04:31,406 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E48 Validation  ----/8413, starting\n",
      "2024-02-02 20:04:31,551 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E48 Validation    16/8413, done at 2024-02-02 20:05:02, 0:00:30\n",
      "2024-02-02 20:04:31,607 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E48 Validation    64/8413, done at 2024-02-02 20:04:46, 0:00:14\n",
      "2024-02-02 20:04:31,810 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E48 Validation   256/8413, done at 2024-02-02 20:04:41, 0:00:10\n",
      "2024-02-02 20:04:32,806 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E48 Validation  1024/8413, done at 2024-02-02 20:04:42, 0:00:10\n",
      "2024-02-02 20:04:36,862 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E48 Validation  4096/8413, done at 2024-02-02 20:04:42, 0:00:11\n",
      "2024-02-02 20:04:42,230 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E48 Validation  8413/8413, done at 2024-02-02 20:04:42\n",
      "2024-02-02 20:04:42,231 INFO     pid:38964 __main__:011:logMetrics E48 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:04:42,235 INFO     pid:38964 __main__:072:logMetrics E48 val      0.6856 loss\n",
      "2024-02-02 20:04:42,235 INFO     pid:38964 __main__:097:logMetrics E48 val        56.6% correct, 0.5482 precision, 0.7467 recall, 0.6322 f1 score\n",
      "2024-02-02 20:04:42,236 INFO     pid:38964 __main__:112:logMetrics E48 val_neg   0.7777 loss,  38.5% correct (51770 of 134598)\n",
      "2024-02-02 20:04:42,236 INFO     pid:38964 __main__:128:logMetrics E48 val_pos   0.5935 loss,  74.7% correct (100506 of 134598)\n",
      "2024-02-02 20:04:42,246 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E49 Training ----/35181, starting\n",
      "2024-02-02 20:04:42,412 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E49 Training   32/35181, done at 2024-02-02 20:05:28, 0:00:46\n",
      "2024-02-02 20:04:42,710 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E49 Training  256/35181, done at 2024-02-02 20:05:29, 0:00:46\n",
      "2024-02-02 20:04:45,152 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E49 Training 2048/35181, done at 2024-02-02 20:05:30, 0:00:47\n",
      "2024-02-02 20:05:02,821 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E49 Training 16384/35181, done at 2024-02-02 20:05:26, 0:00:43\n",
      "2024-02-02 20:05:25,953 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E49 Training 35181/35181, done at 2024-02-02 20:05:25\n",
      "2024-02-02 20:05:26,355 INFO     pid:38964 __main__:011:logMetrics E49 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:05:26,387 INFO     pid:38964 __main__:072:logMetrics E49 trn      0.6667 loss\n",
      "2024-02-02 20:05:26,387 INFO     pid:38964 __main__:097:logMetrics E49 trn        58.6% correct, 0.5951 precision, 0.5385 recall, 0.5654 f1 score\n",
      "2024-02-02 20:05:26,387 INFO     pid:38964 __main__:112:logMetrics E49 trn_neg   0.6652 loss,  63.4% correct (356616 of 562892)\n",
      "2024-02-02 20:05:26,388 INFO     pid:38964 __main__:128:logMetrics E49 trn_pos   0.6681 loss,  53.9% correct (303130 of 562892)\n",
      "2024-02-02 20:05:26,420 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E49 Validation  ----/8413, starting\n",
      "2024-02-02 20:05:26,529 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E49 Validation    16/8413, done at 2024-02-02 20:05:36, 0:00:09\n",
      "2024-02-02 20:05:26,585 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E49 Validation    64/8413, done at 2024-02-02 20:05:36, 0:00:09\n",
      "2024-02-02 20:05:27,003 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E49 Validation   256/8413, done at 2024-02-02 20:05:42, 0:00:16\n",
      "2024-02-02 20:05:27,815 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E49 Validation  1024/8413, done at 2024-02-02 20:05:37, 0:00:10\n",
      "2024-02-02 20:05:31,431 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E49 Validation  4096/8413, done at 2024-02-02 20:05:36, 0:00:10\n",
      "2024-02-02 20:05:36,617 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E49 Validation  8413/8413, done at 2024-02-02 20:05:36\n",
      "2024-02-02 20:05:36,618 INFO     pid:38964 __main__:011:logMetrics E49 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:05:36,623 INFO     pid:38964 __main__:072:logMetrics E49 val      0.6925 loss\n",
      "2024-02-02 20:05:36,623 INFO     pid:38964 __main__:097:logMetrics E49 val        56.0% correct, 0.5449 precision, 0.7335 recall, 0.6253 f1 score\n",
      "2024-02-02 20:05:36,623 INFO     pid:38964 __main__:112:logMetrics E49 val_neg   0.7765 loss,  38.7% correct (52142 of 134598)\n",
      "2024-02-02 20:05:36,623 INFO     pid:38964 __main__:128:logMetrics E49 val_pos   0.6084 loss,  73.4% correct (98731 of 134598)\n",
      "2024-02-02 20:05:36,634 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E50 Training ----/35181, starting\n",
      "2024-02-02 20:05:36,799 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E50 Training   32/35181, done at 2024-02-02 20:06:23, 0:00:46\n",
      "2024-02-02 20:05:37,316 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E50 Training  256/35181, done at 2024-02-02 20:06:53, 0:01:17\n",
      "2024-02-02 20:05:39,545 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E50 Training 2048/35181, done at 2024-02-02 20:06:24, 0:00:47\n",
      "2024-02-02 20:05:57,525 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E50 Training 16384/35181, done at 2024-02-02 20:06:21, 0:00:44\n",
      "2024-02-02 20:06:21,112 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E50 Training 35181/35181, done at 2024-02-02 20:06:21\n",
      "2024-02-02 20:06:21,544 INFO     pid:38964 __main__:011:logMetrics E50 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:06:21,575 INFO     pid:38964 __main__:072:logMetrics E50 trn      0.6674 loss\n",
      "2024-02-02 20:06:21,576 INFO     pid:38964 __main__:097:logMetrics E50 trn        58.7% correct, 0.5929 precision, 0.5542 recall, 0.5729 f1 score\n",
      "2024-02-02 20:06:21,576 INFO     pid:38964 __main__:112:logMetrics E50 trn_neg   0.6658 loss,  61.9% correct (348685 of 562892)\n",
      "2024-02-02 20:06:21,577 INFO     pid:38964 __main__:128:logMetrics E50 trn_pos   0.6689 loss,  55.4% correct (311955 of 562892)\n",
      "2024-02-02 20:06:21,608 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E50 Validation  ----/8413, starting\n",
      "2024-02-02 20:06:21,734 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E50 Validation    16/8413, done at 2024-02-02 20:06:30, 0:00:08\n",
      "2024-02-02 20:06:21,786 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E50 Validation    64/8413, done at 2024-02-02 20:06:30, 0:00:08\n",
      "2024-02-02 20:06:21,988 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E50 Validation   256/8413, done at 2024-02-02 20:06:30, 0:00:08\n",
      "2024-02-02 20:06:22,786 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E50 Validation  1024/8413, done at 2024-02-02 20:06:30, 0:00:08\n",
      "2024-02-02 20:06:26,848 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E50 Validation  4096/8413, done at 2024-02-02 20:06:32, 0:00:10\n",
      "2024-02-02 20:06:32,072 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E50 Validation  8413/8413, done at 2024-02-02 20:06:32\n",
      "2024-02-02 20:06:32,074 INFO     pid:38964 __main__:011:logMetrics E50 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:06:32,078 INFO     pid:38964 __main__:072:logMetrics E50 val      0.6836 loss\n",
      "2024-02-02 20:06:32,078 INFO     pid:38964 __main__:097:logMetrics E50 val        57.0% correct, 0.5583 precision, 0.6701 recall, 0.6091 f1 score\n",
      "2024-02-02 20:06:32,079 INFO     pid:38964 __main__:112:logMetrics E50 val_neg   0.7228 loss,  47.0% correct (63226 of 134598)\n",
      "2024-02-02 20:06:32,079 INFO     pid:38964 __main__:128:logMetrics E50 val_pos   0.6443 loss,  67.0% correct (90199 of 134598)\n",
      "2024-02-02 20:06:32,091 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E51 Training ----/35181, starting\n",
      "2024-02-02 20:06:32,259 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E51 Training   32/35181, done at 2024-02-02 20:07:18, 0:00:45\n",
      "2024-02-02 20:06:32,547 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E51 Training  256/35181, done at 2024-02-02 20:07:17, 0:00:45\n",
      "2024-02-02 20:06:34,820 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E51 Training 2048/35181, done at 2024-02-02 20:07:16, 0:00:44\n",
      "2024-02-02 20:06:52,430 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E51 Training 16384/35181, done at 2024-02-02 20:07:15, 0:00:43\n",
      "2024-02-02 20:07:15,656 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E51 Training 35181/35181, done at 2024-02-02 20:07:15\n",
      "2024-02-02 20:07:16,096 INFO     pid:38964 __main__:011:logMetrics E51 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:07:16,128 INFO     pid:38964 __main__:072:logMetrics E51 trn      0.6673 loss\n",
      "2024-02-02 20:07:16,129 INFO     pid:38964 __main__:097:logMetrics E51 trn        58.7% correct, 0.5936 precision, 0.5517 recall, 0.5719 f1 score\n",
      "2024-02-02 20:07:16,129 INFO     pid:38964 __main__:112:logMetrics E51 trn_neg   0.6658 loss,  62.2% correct (350317 of 562892)\n",
      "2024-02-02 20:07:16,129 INFO     pid:38964 __main__:128:logMetrics E51 trn_pos   0.6688 loss,  55.2% correct (310543 of 562892)\n",
      "2024-02-02 20:07:16,164 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E51 Validation  ----/8413, starting\n",
      "2024-02-02 20:07:16,273 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E51 Validation    16/8413, done at 2024-02-02 20:07:26, 0:00:10\n",
      "2024-02-02 20:07:16,367 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E51 Validation    64/8413, done at 2024-02-02 20:07:31, 0:00:15\n",
      "2024-02-02 20:07:16,571 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E51 Validation   256/8413, done at 2024-02-02 20:07:26, 0:00:10\n",
      "2024-02-02 20:07:17,588 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E51 Validation  1024/8413, done at 2024-02-02 20:07:27, 0:00:10\n",
      "2024-02-02 20:07:21,202 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E51 Validation  4096/8413, done at 2024-02-02 20:07:26, 0:00:10\n",
      "2024-02-02 20:07:26,092 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E51 Validation  8413/8413, done at 2024-02-02 20:07:26\n",
      "2024-02-02 20:07:26,094 INFO     pid:38964 __main__:011:logMetrics E51 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:07:26,098 INFO     pid:38964 __main__:072:logMetrics E51 val      0.6867 loss\n",
      "2024-02-02 20:07:26,098 INFO     pid:38964 __main__:097:logMetrics E51 val        55.9% correct, 0.5399 precision, 0.8036 recall, 0.6459 f1 score\n",
      "2024-02-02 20:07:26,098 INFO     pid:38964 __main__:112:logMetrics E51 val_neg   0.7926 loss,  31.5% correct (42433 of 134598)\n",
      "2024-02-02 20:07:26,098 INFO     pid:38964 __main__:128:logMetrics E51 val_pos   0.5808 loss,  80.4% correct (108157 of 134598)\n",
      "2024-02-02 20:07:26,108 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E52 Training ----/35181, starting\n",
      "2024-02-02 20:07:26,267 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E52 Training   32/35181, done at 2024-02-02 20:08:07, 0:00:41\n",
      "2024-02-02 20:07:26,558 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E52 Training  256/35181, done at 2024-02-02 20:08:11, 0:00:45\n",
      "2024-02-02 20:07:29,009 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E52 Training 2048/35181, done at 2024-02-02 20:08:13, 0:00:47\n",
      "2024-02-02 20:07:47,537 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E52 Training 16384/35181, done at 2024-02-02 20:08:11, 0:00:45\n",
      "2024-02-02 20:08:11,714 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E52 Training 35181/35181, done at 2024-02-02 20:08:11\n",
      "2024-02-02 20:08:12,114 INFO     pid:38964 __main__:011:logMetrics E52 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:08:12,149 INFO     pid:38964 __main__:072:logMetrics E52 trn      0.6662 loss\n",
      "2024-02-02 20:08:12,149 INFO     pid:38964 __main__:097:logMetrics E52 trn        58.7% correct, 0.5966 precision, 0.5374 recall, 0.5654 f1 score\n",
      "2024-02-02 20:08:12,150 INFO     pid:38964 __main__:112:logMetrics E52 trn_neg   0.6647 loss,  63.7% correct (358334 of 562892)\n",
      "2024-02-02 20:08:12,150 INFO     pid:38964 __main__:128:logMetrics E52 trn_pos   0.6677 loss,  53.7% correct (302481 of 562892)\n",
      "2024-02-02 20:08:12,182 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E52 Validation  ----/8413, starting\n",
      "2024-02-02 20:08:12,292 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E52 Validation    16/8413, done at 2024-02-02 20:08:22, 0:00:09\n",
      "2024-02-02 20:08:12,344 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E52 Validation    64/8413, done at 2024-02-02 20:08:21, 0:00:09\n",
      "2024-02-02 20:08:12,579 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E52 Validation   256/8413, done at 2024-02-02 20:08:22, 0:00:10\n",
      "2024-02-02 20:08:13,561 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E52 Validation  1024/8413, done at 2024-02-02 20:08:22, 0:00:10\n",
      "2024-02-02 20:08:17,213 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E52 Validation  4096/8413, done at 2024-02-02 20:08:22, 0:00:10\n",
      "2024-02-02 20:08:22,413 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E52 Validation  8413/8413, done at 2024-02-02 20:08:22\n",
      "2024-02-02 20:08:22,415 INFO     pid:38964 __main__:011:logMetrics E52 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:08:22,420 INFO     pid:38964 __main__:072:logMetrics E52 val      0.6918 loss\n",
      "2024-02-02 20:08:22,420 INFO     pid:38964 __main__:097:logMetrics E52 val        55.3% correct, 0.5504 precision, 0.5822 recall, 0.5658 f1 score\n",
      "2024-02-02 20:08:22,420 INFO     pid:38964 __main__:112:logMetrics E52 val_neg   0.5920 loss,  52.4% correct (70573 of 134598)\n",
      "2024-02-02 20:08:22,421 INFO     pid:38964 __main__:128:logMetrics E52 val_pos   0.7916 loss,  58.2% correct (78365 of 134598)\n",
      "2024-02-02 20:08:22,431 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E53 Training ----/35181, starting\n",
      "2024-02-02 20:08:22,593 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E53 Training   32/35181, done at 2024-02-02 20:09:05, 0:00:43\n",
      "2024-02-02 20:08:22,910 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E53 Training  256/35181, done at 2024-02-02 20:09:11, 0:00:48\n",
      "2024-02-02 20:08:25,437 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E53 Training 2048/35181, done at 2024-02-02 20:09:12, 0:00:49\n",
      "2024-02-02 20:08:43,650 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E53 Training 16384/35181, done at 2024-02-02 20:09:07, 0:00:45\n",
      "2024-02-02 20:09:07,616 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E53 Training 35181/35181, done at 2024-02-02 20:09:07\n",
      "2024-02-02 20:09:08,018 INFO     pid:38964 __main__:011:logMetrics E53 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:09:08,049 INFO     pid:38964 __main__:072:logMetrics E53 trn      0.6740 loss\n",
      "2024-02-02 20:09:08,049 INFO     pid:38964 __main__:097:logMetrics E53 trn        57.8% correct, 0.5781 precision, 0.5790 recall, 0.5786 f1 score\n",
      "2024-02-02 20:09:08,049 INFO     pid:38964 __main__:112:logMetrics E53 trn_neg   0.6735 loss,  57.7% correct (325037 of 562892)\n",
      "2024-02-02 20:09:08,049 INFO     pid:38964 __main__:128:logMetrics E53 trn_pos   0.6745 loss,  57.9% correct (325916 of 562892)\n",
      "2024-02-02 20:09:08,082 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E53 Validation  ----/8413, starting\n",
      "2024-02-02 20:09:08,195 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E53 Validation    16/8413, done at 2024-02-02 20:09:20, 0:00:12\n",
      "2024-02-02 20:09:08,250 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E53 Validation    64/8413, done at 2024-02-02 20:09:18, 0:00:10\n",
      "2024-02-02 20:09:08,480 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E53 Validation   256/8413, done at 2024-02-02 20:09:18, 0:00:10\n",
      "2024-02-02 20:09:09,509 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E53 Validation  1024/8413, done at 2024-02-02 20:09:19, 0:00:10\n",
      "2024-02-02 20:09:13,291 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E53 Validation  4096/8413, done at 2024-02-02 20:09:18, 0:00:10\n",
      "2024-02-02 20:09:18,717 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E53 Validation  8413/8413, done at 2024-02-02 20:09:18\n",
      "2024-02-02 20:09:18,718 INFO     pid:38964 __main__:011:logMetrics E53 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:09:18,723 INFO     pid:38964 __main__:072:logMetrics E53 val      0.6912 loss\n",
      "2024-02-02 20:09:18,723 INFO     pid:38964 __main__:097:logMetrics E53 val        54.2% correct, 0.5253 precision, 0.8742 recall, 0.6563 f1 score\n",
      "2024-02-02 20:09:18,723 INFO     pid:38964 __main__:112:logMetrics E53 val_neg   0.8307 loss,  21.0% correct (28264 of 134598)\n",
      "2024-02-02 20:09:18,723 INFO     pid:38964 __main__:128:logMetrics E53 val_pos   0.5516 loss,  87.4% correct (117665 of 134598)\n",
      "2024-02-02 20:09:18,732 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E54 Training ----/35181, starting\n",
      "2024-02-02 20:09:18,898 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E54 Training   32/35181, done at 2024-02-02 20:10:04, 0:00:46\n",
      "2024-02-02 20:09:19,206 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E54 Training  256/35181, done at 2024-02-02 20:10:06, 0:00:47\n",
      "2024-02-02 20:09:21,766 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E54 Training 2048/35181, done at 2024-02-02 20:10:08, 0:00:49\n",
      "2024-02-02 20:09:39,605 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E54 Training 16384/35181, done at 2024-02-02 20:10:03, 0:00:44\n",
      "2024-02-02 20:10:03,233 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E54 Training 35181/35181, done at 2024-02-02 20:10:03\n",
      "2024-02-02 20:10:03,643 INFO     pid:38964 __main__:011:logMetrics E54 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:10:03,676 INFO     pid:38964 __main__:072:logMetrics E54 trn      0.6708 loss\n",
      "2024-02-02 20:10:03,676 INFO     pid:38964 __main__:097:logMetrics E54 trn        58.2% correct, 0.5903 precision, 0.5380 recall, 0.5629 f1 score\n",
      "2024-02-02 20:10:03,677 INFO     pid:38964 __main__:112:logMetrics E54 trn_neg   0.6699 loss,  62.7% correct (352685 of 562892)\n",
      "2024-02-02 20:10:03,677 INFO     pid:38964 __main__:128:logMetrics E54 trn_pos   0.6716 loss,  53.8% correct (302809 of 562892)\n",
      "2024-02-02 20:10:03,710 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E54 Validation  ----/8413, starting\n",
      "2024-02-02 20:10:03,821 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E54 Validation    16/8413, done at 2024-02-02 20:10:14, 0:00:10\n",
      "2024-02-02 20:10:03,874 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E54 Validation    64/8413, done at 2024-02-02 20:10:13, 0:00:09\n",
      "2024-02-02 20:10:04,306 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E54 Validation   256/8413, done at 2024-02-02 20:10:20, 0:00:16\n",
      "2024-02-02 20:10:05,109 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E54 Validation  1024/8413, done at 2024-02-02 20:10:14, 0:00:10\n",
      "2024-02-02 20:10:08,661 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E54 Validation  4096/8413, done at 2024-02-02 20:10:13, 0:00:09\n",
      "2024-02-02 20:10:13,793 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E54 Validation  8413/8413, done at 2024-02-02 20:10:13\n",
      "2024-02-02 20:10:13,795 INFO     pid:38964 __main__:011:logMetrics E54 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:10:13,799 INFO     pid:38964 __main__:072:logMetrics E54 val      0.6820 loss\n",
      "2024-02-02 20:10:13,799 INFO     pid:38964 __main__:097:logMetrics E54 val        55.8% correct, 0.6242 precision, 0.2905 recall, 0.3965 f1 score\n",
      "2024-02-02 20:10:13,800 INFO     pid:38964 __main__:112:logMetrics E54 val_neg   0.6722 loss,  82.5% correct (111053 of 134598)\n",
      "2024-02-02 20:10:13,800 INFO     pid:38964 __main__:128:logMetrics E54 val_pos   0.6917 loss,  29.1% correct (39103 of 134598)\n",
      "2024-02-02 20:10:13,810 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E55 Training ----/35181, starting\n",
      "2024-02-02 20:10:13,978 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E55 Training   32/35181, done at 2024-02-02 20:10:58, 0:00:44\n",
      "2024-02-02 20:10:14,458 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E55 Training  256/35181, done at 2024-02-02 20:11:25, 0:01:11\n",
      "2024-02-02 20:10:16,668 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E55 Training 2048/35181, done at 2024-02-02 20:11:00, 0:00:46\n",
      "2024-02-02 20:10:34,917 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E55 Training 16384/35181, done at 2024-02-02 20:10:58, 0:00:45\n",
      "2024-02-02 20:10:57,960 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E55 Training 35181/35181, done at 2024-02-02 20:10:57\n",
      "2024-02-02 20:10:58,355 INFO     pid:38964 __main__:011:logMetrics E55 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:10:58,389 INFO     pid:38964 __main__:072:logMetrics E55 trn      0.6725 loss\n",
      "2024-02-02 20:10:58,390 INFO     pid:38964 __main__:097:logMetrics E55 trn        57.8% correct, 0.5812 precision, 0.5595 recall, 0.5701 f1 score\n",
      "2024-02-02 20:10:58,390 INFO     pid:38964 __main__:112:logMetrics E55 trn_neg   0.6716 loss,  59.7% correct (335918 of 562892)\n",
      "2024-02-02 20:10:58,391 INFO     pid:38964 __main__:128:logMetrics E55 trn_pos   0.6733 loss,  55.9% correct (314936 of 562892)\n",
      "2024-02-02 20:10:58,422 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E55 Validation  ----/8413, starting\n",
      "2024-02-02 20:10:58,533 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E55 Validation    16/8413, done at 2024-02-02 20:11:07, 0:00:08\n",
      "2024-02-02 20:10:58,585 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E55 Validation    64/8413, done at 2024-02-02 20:11:07, 0:00:09\n",
      "2024-02-02 20:10:58,782 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E55 Validation   256/8413, done at 2024-02-02 20:11:07, 0:00:08\n",
      "2024-02-02 20:10:59,623 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E55 Validation  1024/8413, done at 2024-02-02 20:11:07, 0:00:09\n",
      "2024-02-02 20:11:03,406 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E55 Validation  4096/8413, done at 2024-02-02 20:11:08, 0:00:10\n",
      "2024-02-02 20:11:08,780 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E55 Validation  8413/8413, done at 2024-02-02 20:11:08\n",
      "2024-02-02 20:11:08,781 INFO     pid:38964 __main__:011:logMetrics E55 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:11:08,786 INFO     pid:38964 __main__:072:logMetrics E55 val      0.6836 loss\n",
      "2024-02-02 20:11:08,786 INFO     pid:38964 __main__:097:logMetrics E55 val        55.3% correct, 0.5348 precision, 0.8198 recall, 0.6473 f1 score\n",
      "2024-02-02 20:11:08,786 INFO     pid:38964 __main__:112:logMetrics E55 val_neg   0.7688 loss,  28.7% correct (38605 of 134598)\n",
      "2024-02-02 20:11:08,787 INFO     pid:38964 __main__:128:logMetrics E55 val_pos   0.5983 loss,  82.0% correct (110340 of 134598)\n",
      "2024-02-02 20:11:08,796 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E56 Training ----/35181, starting\n",
      "2024-02-02 20:11:08,979 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E56 Training   32/35181, done at 2024-02-02 20:11:58, 0:00:49\n",
      "2024-02-02 20:11:09,252 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E56 Training  256/35181, done at 2024-02-02 20:11:52, 0:00:43\n",
      "2024-02-02 20:11:11,650 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E56 Training 2048/35181, done at 2024-02-02 20:11:55, 0:00:46\n",
      "2024-02-02 20:11:30,013 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E56 Training 16384/35181, done at 2024-02-02 20:11:54, 0:00:45\n",
      "2024-02-02 20:11:54,105 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E56 Training 35181/35181, done at 2024-02-02 20:11:54\n",
      "2024-02-02 20:11:54,512 INFO     pid:38964 __main__:011:logMetrics E56 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:11:54,546 INFO     pid:38964 __main__:072:logMetrics E56 trn      0.6675 loss\n",
      "2024-02-02 20:11:54,546 INFO     pid:38964 __main__:097:logMetrics E56 trn        58.5% correct, 0.5971 precision, 0.5223 recall, 0.5572 f1 score\n",
      "2024-02-02 20:11:54,547 INFO     pid:38964 __main__:112:logMetrics E56 trn_neg   0.6659 loss,  64.8% correct (364557 of 562892)\n",
      "2024-02-02 20:11:54,547 INFO     pid:38964 __main__:128:logMetrics E56 trn_pos   0.6691 loss,  52.2% correct (293981 of 562892)\n",
      "2024-02-02 20:11:54,582 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E56 Validation  ----/8413, starting\n",
      "2024-02-02 20:11:54,693 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E56 Validation    16/8413, done at 2024-02-02 20:12:04, 0:00:10\n",
      "2024-02-02 20:11:54,751 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E56 Validation    64/8413, done at 2024-02-02 20:12:04, 0:00:10\n",
      "2024-02-02 20:11:54,989 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E56 Validation   256/8413, done at 2024-02-02 20:12:05, 0:00:10\n",
      "2024-02-02 20:11:55,974 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E56 Validation  1024/8413, done at 2024-02-02 20:12:05, 0:00:10\n",
      "2024-02-02 20:11:59,584 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E56 Validation  4096/8413, done at 2024-02-02 20:12:04, 0:00:10\n",
      "2024-02-02 20:12:04,622 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E56 Validation  8413/8413, done at 2024-02-02 20:12:04\n",
      "2024-02-02 20:12:04,623 INFO     pid:38964 __main__:011:logMetrics E56 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:12:04,628 INFO     pid:38964 __main__:072:logMetrics E56 val      0.6812 loss\n",
      "2024-02-02 20:12:04,628 INFO     pid:38964 __main__:097:logMetrics E56 val        56.7% correct, 0.5559 precision, 0.6623 recall, 0.6044 f1 score\n",
      "2024-02-02 20:12:04,629 INFO     pid:38964 __main__:112:logMetrics E56 val_neg   0.7183 loss,  47.1% correct (63374 of 134598)\n",
      "2024-02-02 20:12:04,629 INFO     pid:38964 __main__:128:logMetrics E56 val_pos   0.6441 loss,  66.2% correct (89138 of 134598)\n",
      "2024-02-02 20:12:04,639 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E57 Training ----/35181, starting\n",
      "2024-02-02 20:12:04,804 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E57 Training   32/35181, done at 2024-02-02 20:12:52, 0:00:47\n",
      "2024-02-02 20:12:05,097 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E57 Training  256/35181, done at 2024-02-02 20:12:50, 0:00:46\n",
      "2024-02-02 20:12:07,339 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E57 Training 2048/35181, done at 2024-02-02 20:12:49, 0:00:44\n",
      "2024-02-02 20:12:24,549 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E57 Training 16384/35181, done at 2024-02-02 20:12:47, 0:00:42\n",
      "2024-02-02 20:12:47,028 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E57 Training 35181/35181, done at 2024-02-02 20:12:47\n",
      "2024-02-02 20:12:47,450 INFO     pid:38964 __main__:011:logMetrics E57 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:12:47,485 INFO     pid:38964 __main__:072:logMetrics E57 trn      0.6681 loss\n",
      "2024-02-02 20:12:47,486 INFO     pid:38964 __main__:097:logMetrics E57 trn        58.5% correct, 0.5906 precision, 0.5555 recall, 0.5725 f1 score\n",
      "2024-02-02 20:12:47,486 INFO     pid:38964 __main__:112:logMetrics E57 trn_neg   0.6666 loss,  61.5% correct (346148 of 562892)\n",
      "2024-02-02 20:12:47,486 INFO     pid:38964 __main__:128:logMetrics E57 trn_pos   0.6696 loss,  55.5% correct (312661 of 562892)\n",
      "2024-02-02 20:12:47,519 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E57 Validation  ----/8413, starting\n",
      "2024-02-02 20:12:47,630 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E57 Validation    16/8413, done at 2024-02-02 20:12:58, 0:00:10\n",
      "2024-02-02 20:12:47,681 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E57 Validation    64/8413, done at 2024-02-02 20:12:57, 0:00:09\n",
      "2024-02-02 20:12:47,911 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E57 Validation   256/8413, done at 2024-02-02 20:12:57, 0:00:09\n",
      "2024-02-02 20:12:48,896 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E57 Validation  1024/8413, done at 2024-02-02 20:12:58, 0:00:10\n",
      "2024-02-02 20:12:52,818 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E57 Validation  4096/8413, done at 2024-02-02 20:12:58, 0:00:10\n",
      "2024-02-02 20:12:58,124 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E57 Validation  8413/8413, done at 2024-02-02 20:12:58\n",
      "2024-02-02 20:12:58,125 INFO     pid:38964 __main__:011:logMetrics E57 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:12:58,130 INFO     pid:38964 __main__:072:logMetrics E57 val      0.6974 loss\n",
      "2024-02-02 20:12:58,130 INFO     pid:38964 __main__:097:logMetrics E57 val        53.1% correct, 0.5228 precision, 0.7148 recall, 0.6039 f1 score\n",
      "2024-02-02 20:12:58,130 INFO     pid:38964 __main__:112:logMetrics E57 val_neg   0.7992 loss,  34.7% correct (46767 of 134598)\n",
      "2024-02-02 20:12:58,130 INFO     pid:38964 __main__:128:logMetrics E57 val_pos   0.5956 loss,  71.5% correct (96207 of 134598)\n",
      "2024-02-02 20:12:58,139 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E58 Training ----/35181, starting\n",
      "2024-02-02 20:12:58,303 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E58 Training   32/35181, done at 2024-02-02 20:13:45, 0:00:46\n",
      "2024-02-02 20:12:58,603 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E58 Training  256/35181, done at 2024-02-02 20:13:45, 0:00:47\n",
      "2024-02-02 20:13:01,094 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E58 Training 2048/35181, done at 2024-02-02 20:13:46, 0:00:48\n",
      "2024-02-02 20:13:19,363 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E58 Training 16384/35181, done at 2024-02-02 20:13:43, 0:00:45\n",
      "2024-02-02 20:13:43,098 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E58 Training 35181/35181, done at 2024-02-02 20:13:43\n",
      "2024-02-02 20:13:43,528 INFO     pid:38964 __main__:011:logMetrics E58 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:13:43,561 INFO     pid:38964 __main__:072:logMetrics E58 trn      0.6675 loss\n",
      "2024-02-02 20:13:43,562 INFO     pid:38964 __main__:097:logMetrics E58 trn        58.6% correct, 0.5946 precision, 0.5433 recall, 0.5678 f1 score\n",
      "2024-02-02 20:13:43,562 INFO     pid:38964 __main__:112:logMetrics E58 trn_neg   0.6660 loss,  63.0% correct (354344 of 562892)\n",
      "2024-02-02 20:13:43,563 INFO     pid:38964 __main__:128:logMetrics E58 trn_pos   0.6690 loss,  54.3% correct (305827 of 562892)\n",
      "2024-02-02 20:13:43,594 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E58 Validation  ----/8413, starting\n",
      "2024-02-02 20:13:43,752 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E58 Validation    16/8413, done at 2024-02-02 20:14:21, 0:00:38\n",
      "2024-02-02 20:13:43,813 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E58 Validation    64/8413, done at 2024-02-02 20:14:00, 0:00:16\n",
      "2024-02-02 20:13:44,020 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E58 Validation   256/8413, done at 2024-02-02 20:13:54, 0:00:10\n",
      "2024-02-02 20:13:45,034 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E58 Validation  1024/8413, done at 2024-02-02 20:13:54, 0:00:11\n",
      "2024-02-02 20:13:48,701 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E58 Validation  4096/8413, done at 2024-02-02 20:13:53, 0:00:10\n",
      "2024-02-02 20:13:53,835 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E58 Validation  8413/8413, done at 2024-02-02 20:13:53\n",
      "2024-02-02 20:13:53,836 INFO     pid:38964 __main__:011:logMetrics E58 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:13:53,840 INFO     pid:38964 __main__:072:logMetrics E58 val      0.6843 loss\n",
      "2024-02-02 20:13:53,841 INFO     pid:38964 __main__:097:logMetrics E58 val        55.5% correct, 0.5501 precision, 0.5998 recall, 0.5739 f1 score\n",
      "2024-02-02 20:13:53,841 INFO     pid:38964 __main__:112:logMetrics E58 val_neg   0.7262 loss,  50.9% correct (68562 of 134598)\n",
      "2024-02-02 20:13:53,841 INFO     pid:38964 __main__:128:logMetrics E58 val_pos   0.6424 loss,  60.0% correct (80735 of 134598)\n",
      "2024-02-02 20:13:53,851 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E59 Training ----/35181, starting\n",
      "2024-02-02 20:13:54,018 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E59 Training   32/35181, done at 2024-02-02 20:14:40, 0:00:46\n",
      "2024-02-02 20:13:54,327 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E59 Training  256/35181, done at 2024-02-02 20:14:42, 0:00:48\n",
      "2024-02-02 20:13:56,768 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E59 Training 2048/35181, done at 2024-02-02 20:14:41, 0:00:47\n",
      "2024-02-02 20:14:14,551 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E59 Training 16384/35181, done at 2024-02-02 20:14:38, 0:00:44\n",
      "2024-02-02 20:14:38,130 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E59 Training 35181/35181, done at 2024-02-02 20:14:38\n",
      "2024-02-02 20:14:38,530 INFO     pid:38964 __main__:011:logMetrics E59 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:14:38,564 INFO     pid:38964 __main__:072:logMetrics E59 trn      0.6676 loss\n",
      "2024-02-02 20:14:38,564 INFO     pid:38964 __main__:097:logMetrics E59 trn        58.7% correct, 0.5987 precision, 0.5259 recall, 0.5599 f1 score\n",
      "2024-02-02 20:14:38,565 INFO     pid:38964 __main__:112:logMetrics E59 trn_neg   0.6662 loss,  64.8% correct (364481 of 562892)\n",
      "2024-02-02 20:14:38,565 INFO     pid:38964 __main__:128:logMetrics E59 trn_pos   0.6690 loss,  52.6% correct (296023 of 562892)\n",
      "2024-02-02 20:14:38,598 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E59 Validation  ----/8413, starting\n",
      "2024-02-02 20:14:38,710 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E59 Validation    16/8413, done at 2024-02-02 20:14:48, 0:00:10\n",
      "2024-02-02 20:14:38,801 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E59 Validation    64/8413, done at 2024-02-02 20:14:53, 0:00:14\n",
      "2024-02-02 20:14:39,397 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E59 Validation   256/8413, done at 2024-02-02 20:15:01, 0:00:23\n",
      "2024-02-02 20:14:40,212 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E59 Validation  1024/8413, done at 2024-02-02 20:14:51, 0:00:12\n",
      "2024-02-02 20:14:44,185 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E59 Validation  4096/8413, done at 2024-02-02 20:14:49, 0:00:11\n",
      "2024-02-02 20:14:49,504 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E59 Validation  8413/8413, done at 2024-02-02 20:14:49\n",
      "2024-02-02 20:14:49,505 INFO     pid:38964 __main__:011:logMetrics E59 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:14:49,509 INFO     pid:38964 __main__:072:logMetrics E59 val      0.6810 loss\n",
      "2024-02-02 20:14:49,510 INFO     pid:38964 __main__:097:logMetrics E59 val        56.5% correct, 0.6011 precision, 0.3870 recall, 0.4708 f1 score\n",
      "2024-02-02 20:14:49,510 INFO     pid:38964 __main__:112:logMetrics E59 val_neg   0.6340 loss,  74.3% correct (100035 of 134598)\n",
      "2024-02-02 20:14:49,510 INFO     pid:38964 __main__:128:logMetrics E59 val_pos   0.7280 loss,  38.7% correct (52083 of 134598)\n",
      "2024-02-02 20:14:49,519 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E60 Training ----/35181, starting\n",
      "2024-02-02 20:14:49,687 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E60 Training   32/35181, done at 2024-02-02 20:15:38, 0:00:48\n",
      "2024-02-02 20:14:50,179 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E60 Training  256/35181, done at 2024-02-02 20:16:03, 0:01:13\n",
      "2024-02-02 20:14:52,465 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E60 Training 2048/35181, done at 2024-02-02 20:15:38, 0:00:48\n",
      "2024-02-02 20:15:11,820 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E60 Training 16384/35181, done at 2024-02-02 20:15:37, 0:00:47\n",
      "2024-02-02 20:15:35,672 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E60 Training 35181/35181, done at 2024-02-02 20:15:35\n",
      "2024-02-02 20:15:36,085 INFO     pid:38964 __main__:011:logMetrics E60 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:15:36,118 INFO     pid:38964 __main__:072:logMetrics E60 trn      0.6705 loss\n",
      "2024-02-02 20:15:36,119 INFO     pid:38964 __main__:097:logMetrics E60 trn        58.0% correct, 0.5840 precision, 0.5584 recall, 0.5709 f1 score\n",
      "2024-02-02 20:15:36,119 INFO     pid:38964 __main__:112:logMetrics E60 trn_neg   0.6695 loss,  60.2% correct (338970 of 562892)\n",
      "2024-02-02 20:15:36,119 INFO     pid:38964 __main__:128:logMetrics E60 trn_pos   0.6716 loss,  55.8% correct (314344 of 562892)\n",
      "2024-02-02 20:15:36,152 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E60 Validation  ----/8413, starting\n",
      "2024-02-02 20:15:36,453 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E60 Validation    16/8413, done at 2024-02-02 20:15:45, 0:00:08\n",
      "2024-02-02 20:15:36,541 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E60 Validation    64/8413, done at 2024-02-02 20:15:50, 0:00:13\n",
      "2024-02-02 20:15:36,750 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E60 Validation   256/8413, done at 2024-02-02 20:15:46, 0:00:10\n",
      "2024-02-02 20:15:37,563 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E60 Validation  1024/8413, done at 2024-02-02 20:15:45, 0:00:09\n",
      "2024-02-02 20:15:41,360 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E60 Validation  4096/8413, done at 2024-02-02 20:15:46, 0:00:10\n",
      "2024-02-02 20:15:46,903 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E60 Validation  8413/8413, done at 2024-02-02 20:15:46\n",
      "2024-02-02 20:15:46,904 INFO     pid:38964 __main__:011:logMetrics E60 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:15:46,909 INFO     pid:38964 __main__:072:logMetrics E60 val      0.6806 loss\n",
      "2024-02-02 20:15:46,909 INFO     pid:38964 __main__:097:logMetrics E60 val        57.3% correct, 0.5854 precision, 0.4991 recall, 0.5388 f1 score\n",
      "2024-02-02 20:15:46,910 INFO     pid:38964 __main__:112:logMetrics E60 val_neg   0.6800 loss,  64.7% correct (87032 of 134598)\n",
      "2024-02-02 20:15:46,910 INFO     pid:38964 __main__:128:logMetrics E60 val_pos   0.6813 loss,  49.9% correct (67172 of 134598)\n",
      "2024-02-02 20:15:46,920 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E61 Training ----/35181, starting\n",
      "2024-02-02 20:15:47,274 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E61 Training   32/35181, done at 2024-02-02 20:16:28, 0:00:40\n",
      "2024-02-02 20:15:47,590 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E61 Training  256/35181, done at 2024-02-02 20:16:35, 0:00:48\n",
      "2024-02-02 20:15:50,151 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E61 Training 2048/35181, done at 2024-02-02 20:16:37, 0:00:50\n",
      "2024-02-02 20:16:08,139 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E61 Training 16384/35181, done at 2024-02-02 20:16:32, 0:00:44\n",
      "2024-02-02 20:16:30,815 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E61 Training 35181/35181, done at 2024-02-02 20:16:30\n",
      "2024-02-02 20:16:31,237 INFO     pid:38964 __main__:011:logMetrics E61 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:16:31,270 INFO     pid:38964 __main__:072:logMetrics E61 trn      0.6671 loss\n",
      "2024-02-02 20:16:31,271 INFO     pid:38964 __main__:097:logMetrics E61 trn        58.8% correct, 0.6003 precision, 0.5236 recall, 0.5593 f1 score\n",
      "2024-02-02 20:16:31,271 INFO     pid:38964 __main__:112:logMetrics E61 trn_neg   0.6653 loss,  65.1% correct (366702 of 562892)\n",
      "2024-02-02 20:16:31,271 INFO     pid:38964 __main__:128:logMetrics E61 trn_pos   0.6688 loss,  52.4% correct (294706 of 562892)\n",
      "2024-02-02 20:16:31,304 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E61 Validation  ----/8413, starting\n",
      "2024-02-02 20:16:31,413 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E61 Validation    16/8413, done at 2024-02-02 20:16:41, 0:00:10\n",
      "2024-02-02 20:16:31,467 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E61 Validation    64/8413, done at 2024-02-02 20:16:41, 0:00:09\n",
      "2024-02-02 20:16:31,713 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E61 Validation   256/8413, done at 2024-02-02 20:16:41, 0:00:10\n",
      "2024-02-02 20:16:32,745 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E61 Validation  1024/8413, done at 2024-02-02 20:16:42, 0:00:11\n",
      "2024-02-02 20:16:36,390 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E61 Validation  4096/8413, done at 2024-02-02 20:16:41, 0:00:10\n",
      "2024-02-02 20:16:41,633 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E61 Validation  8413/8413, done at 2024-02-02 20:16:41\n",
      "2024-02-02 20:16:41,634 INFO     pid:38964 __main__:011:logMetrics E61 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:16:41,638 INFO     pid:38964 __main__:072:logMetrics E61 val      0.6796 loss\n",
      "2024-02-02 20:16:41,638 INFO     pid:38964 __main__:097:logMetrics E61 val        57.5% correct, 0.5624 precision, 0.6787 recall, 0.6151 f1 score\n",
      "2024-02-02 20:16:41,638 INFO     pid:38964 __main__:112:logMetrics E61 val_neg   0.7153 loss,  47.2% correct (63503 of 134598)\n",
      "2024-02-02 20:16:41,638 INFO     pid:38964 __main__:128:logMetrics E61 val_pos   0.6438 loss,  67.9% correct (91358 of 134598)\n",
      "2024-02-02 20:16:41,649 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E62 Training ----/35181, starting\n",
      "2024-02-02 20:16:41,816 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E62 Training   32/35181, done at 2024-02-02 20:17:26, 0:00:44\n",
      "2024-02-02 20:16:42,120 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E62 Training  256/35181, done at 2024-02-02 20:17:28, 0:00:47\n",
      "2024-02-02 20:16:44,378 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E62 Training 2048/35181, done at 2024-02-02 20:17:26, 0:00:44\n",
      "2024-02-02 20:17:02,081 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E62 Training 16384/35181, done at 2024-02-02 20:17:25, 0:00:43\n",
      "2024-02-02 20:17:25,594 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E62 Training 35181/35181, done at 2024-02-02 20:17:25\n",
      "2024-02-02 20:17:25,993 INFO     pid:38964 __main__:011:logMetrics E62 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:17:26,026 INFO     pid:38964 __main__:072:logMetrics E62 trn      0.6674 loss\n",
      "2024-02-02 20:17:26,027 INFO     pid:38964 __main__:097:logMetrics E62 trn        58.6% correct, 0.5957 precision, 0.5364 recall, 0.5645 f1 score\n",
      "2024-02-02 20:17:26,027 INFO     pid:38964 __main__:112:logMetrics E62 trn_neg   0.6659 loss,  63.6% correct (357920 of 562892)\n",
      "2024-02-02 20:17:26,027 INFO     pid:38964 __main__:128:logMetrics E62 trn_pos   0.6688 loss,  53.6% correct (301950 of 562892)\n",
      "2024-02-02 20:17:26,060 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E62 Validation  ----/8413, starting\n",
      "2024-02-02 20:17:26,171 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E62 Validation    16/8413, done at 2024-02-02 20:17:35, 0:00:09\n",
      "2024-02-02 20:17:26,249 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E62 Validation    64/8413, done at 2024-02-02 20:17:38, 0:00:12\n",
      "2024-02-02 20:17:26,457 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E62 Validation   256/8413, done at 2024-02-02 20:17:36, 0:00:09\n",
      "2024-02-02 20:17:27,472 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E62 Validation  1024/8413, done at 2024-02-02 20:17:36, 0:00:10\n",
      "2024-02-02 20:17:31,493 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E62 Validation  4096/8413, done at 2024-02-02 20:17:37, 0:00:10\n",
      "2024-02-02 20:17:36,789 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E62 Validation  8413/8413, done at 2024-02-02 20:17:36\n",
      "2024-02-02 20:17:36,790 INFO     pid:38964 __main__:011:logMetrics E62 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:17:36,794 INFO     pid:38964 __main__:072:logMetrics E62 val      0.6805 loss\n",
      "2024-02-02 20:17:36,794 INFO     pid:38964 __main__:097:logMetrics E62 val        57.0% correct, 0.5630 precision, 0.6271 recall, 0.5933 f1 score\n",
      "2024-02-02 20:17:36,794 INFO     pid:38964 __main__:112:logMetrics E62 val_neg   0.7080 loss,  51.3% correct (69095 of 134598)\n",
      "2024-02-02 20:17:36,794 INFO     pid:38964 __main__:128:logMetrics E62 val_pos   0.6531 loss,  62.7% correct (84402 of 134598)\n",
      "2024-02-02 20:17:36,805 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E63 Training ----/35181, starting\n",
      "2024-02-02 20:17:37,000 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E63 Training   32/35181, done at 2024-02-02 20:18:57, 0:01:20\n",
      "2024-02-02 20:17:37,279 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E63 Training  256/35181, done at 2024-02-02 20:18:24, 0:00:48\n",
      "2024-02-02 20:17:39,705 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E63 Training 2048/35181, done at 2024-02-02 20:18:24, 0:00:47\n",
      "2024-02-02 20:17:58,234 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E63 Training 16384/35181, done at 2024-02-02 20:18:22, 0:00:45\n",
      "2024-02-02 20:18:22,512 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E63 Training 35181/35181, done at 2024-02-02 20:18:22\n",
      "2024-02-02 20:18:22,919 INFO     pid:38964 __main__:011:logMetrics E63 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:18:22,953 INFO     pid:38964 __main__:072:logMetrics E63 trn      0.6673 loss\n",
      "2024-02-02 20:18:22,954 INFO     pid:38964 __main__:097:logMetrics E63 trn        58.6% correct, 0.5946 precision, 0.5410 recall, 0.5666 f1 score\n",
      "2024-02-02 20:18:22,954 INFO     pid:38964 __main__:112:logMetrics E63 trn_neg   0.6659 loss,  63.1% correct (355268 of 562892)\n",
      "2024-02-02 20:18:22,954 INFO     pid:38964 __main__:128:logMetrics E63 trn_pos   0.6688 loss,  54.1% correct (304539 of 562892)\n",
      "2024-02-02 20:18:23,032 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E63 Validation  ----/8413, starting\n",
      "2024-02-02 20:18:23,147 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E63 Validation    16/8413, done at 2024-02-02 20:18:33, 0:00:09\n",
      "2024-02-02 20:18:23,205 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E63 Validation    64/8413, done at 2024-02-02 20:18:33, 0:00:10\n",
      "2024-02-02 20:18:23,418 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E63 Validation   256/8413, done at 2024-02-02 20:18:32, 0:00:09\n",
      "2024-02-02 20:18:24,640 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E63 Validation  1024/8413, done at 2024-02-02 20:18:35, 0:00:12\n",
      "2024-02-02 20:18:28,370 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E63 Validation  4096/8413, done at 2024-02-02 20:18:33, 0:00:10\n",
      "2024-02-02 20:18:33,684 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E63 Validation  8413/8413, done at 2024-02-02 20:18:33\n",
      "2024-02-02 20:18:33,686 INFO     pid:38964 __main__:011:logMetrics E63 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:18:33,691 INFO     pid:38964 __main__:072:logMetrics E63 val      0.6911 loss\n",
      "2024-02-02 20:18:33,692 INFO     pid:38964 __main__:097:logMetrics E63 val        55.4% correct, 0.5377 precision, 0.7702 recall, 0.6332 f1 score\n",
      "2024-02-02 20:18:33,692 INFO     pid:38964 __main__:112:logMetrics E63 val_neg   0.8010 loss,  33.8% correct (45451 of 134598)\n",
      "2024-02-02 20:18:33,692 INFO     pid:38964 __main__:128:logMetrics E63 val_pos   0.5813 loss,  77.0% correct (103666 of 134598)\n",
      "2024-02-02 20:18:33,702 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E64 Training ----/35181, starting\n",
      "2024-02-02 20:18:33,852 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E64 Training   32/35181, done at 2024-02-02 20:19:15, 0:00:42\n",
      "2024-02-02 20:18:34,124 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E64 Training  256/35181, done at 2024-02-02 20:19:16, 0:00:42\n",
      "2024-02-02 20:18:36,537 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E64 Training 2048/35181, done at 2024-02-02 20:19:20, 0:00:46\n",
      "2024-02-02 20:18:54,300 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E64 Training 16384/35181, done at 2024-02-02 20:19:17, 0:00:43\n",
      "2024-02-02 20:19:17,083 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E64 Training 35181/35181, done at 2024-02-02 20:19:17\n",
      "2024-02-02 20:19:17,478 INFO     pid:38964 __main__:011:logMetrics E64 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:19:17,515 INFO     pid:38964 __main__:072:logMetrics E64 trn      0.6675 loss\n",
      "2024-02-02 20:19:17,516 INFO     pid:38964 __main__:097:logMetrics E64 trn        58.6% correct, 0.5959 precision, 0.5345 recall, 0.5635 f1 score\n",
      "2024-02-02 20:19:17,516 INFO     pid:38964 __main__:112:logMetrics E64 trn_neg   0.6661 loss,  63.7% correct (358835 of 562892)\n",
      "2024-02-02 20:19:17,516 INFO     pid:38964 __main__:128:logMetrics E64 trn_pos   0.6689 loss,  53.5% correct (300872 of 562892)\n",
      "2024-02-02 20:19:17,549 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E64 Validation  ----/8413, starting\n",
      "2024-02-02 20:19:17,659 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E64 Validation    16/8413, done at 2024-02-02 20:19:26, 0:00:09\n",
      "2024-02-02 20:19:17,716 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E64 Validation    64/8413, done at 2024-02-02 20:19:27, 0:00:09\n",
      "2024-02-02 20:19:18,148 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E64 Validation   256/8413, done at 2024-02-02 20:19:34, 0:00:16\n",
      "2024-02-02 20:19:18,953 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E64 Validation  1024/8413, done at 2024-02-02 20:19:28, 0:00:10\n",
      "2024-02-02 20:19:22,634 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E64 Validation  4096/8413, done at 2024-02-02 20:19:27, 0:00:10\n",
      "2024-02-02 20:19:28,157 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E64 Validation  8413/8413, done at 2024-02-02 20:19:28\n",
      "2024-02-02 20:19:28,159 INFO     pid:38964 __main__:011:logMetrics E64 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:19:28,163 INFO     pid:38964 __main__:072:logMetrics E64 val      0.6949 loss\n",
      "2024-02-02 20:19:28,163 INFO     pid:38964 __main__:097:logMetrics E64 val        55.6% correct, 0.5363 precision, 0.8217 recall, 0.6490 f1 score\n",
      "2024-02-02 20:19:28,164 INFO     pid:38964 __main__:112:logMetrics E64 val_neg   0.8233 loss,  28.9% correct (38953 of 134598)\n",
      "2024-02-02 20:19:28,164 INFO     pid:38964 __main__:128:logMetrics E64 val_pos   0.5665 loss,  82.2% correct (110604 of 134598)\n",
      "2024-02-02 20:19:28,174 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E65 Training ----/35181, starting\n",
      "2024-02-02 20:19:28,341 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E65 Training   32/35181, done at 2024-02-02 20:20:14, 0:00:45\n",
      "2024-02-02 20:19:28,862 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E65 Training  256/35181, done at 2024-02-02 20:20:45, 0:01:17\n",
      "2024-02-02 20:19:31,253 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E65 Training 2048/35181, done at 2024-02-02 20:20:19, 0:00:50\n",
      "2024-02-02 20:19:49,018 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E65 Training 16384/35181, done at 2024-02-02 20:20:12, 0:00:44\n",
      "2024-02-02 20:20:11,311 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E65 Training 35181/35181, done at 2024-02-02 20:20:11\n",
      "2024-02-02 20:20:11,719 INFO     pid:38964 __main__:011:logMetrics E65 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:20:11,751 INFO     pid:38964 __main__:072:logMetrics E65 trn      0.6678 loss\n",
      "2024-02-02 20:20:11,752 INFO     pid:38964 __main__:097:logMetrics E65 trn        58.7% correct, 0.5968 precision, 0.5350 recall, 0.5642 f1 score\n",
      "2024-02-02 20:20:11,752 INFO     pid:38964 __main__:112:logMetrics E65 trn_neg   0.6663 loss,  63.9% correct (359448 of 562892)\n",
      "2024-02-02 20:20:11,753 INFO     pid:38964 __main__:128:logMetrics E65 trn_pos   0.6694 loss,  53.5% correct (301122 of 562892)\n",
      "2024-02-02 20:20:11,786 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E65 Validation  ----/8413, starting\n",
      "2024-02-02 20:20:11,896 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E65 Validation    16/8413, done at 2024-02-02 20:20:21, 0:00:09\n",
      "2024-02-02 20:20:12,167 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E65 Validation    64/8413, done at 2024-02-02 20:20:50, 0:00:38\n",
      "2024-02-02 20:20:12,376 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E65 Validation   256/8413, done at 2024-02-02 20:20:28, 0:00:16\n",
      "2024-02-02 20:20:13,194 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E65 Validation  1024/8413, done at 2024-02-02 20:20:22, 0:00:10\n",
      "2024-02-02 20:20:16,973 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E65 Validation  4096/8413, done at 2024-02-02 20:20:22, 0:00:10\n",
      "2024-02-02 20:20:22,405 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E65 Validation  8413/8413, done at 2024-02-02 20:20:22\n",
      "2024-02-02 20:20:22,407 INFO     pid:38964 __main__:011:logMetrics E65 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:20:22,411 INFO     pid:38964 __main__:072:logMetrics E65 val      0.6843 loss\n",
      "2024-02-02 20:20:22,411 INFO     pid:38964 __main__:097:logMetrics E65 val        57.0% correct, 0.5592 precision, 0.6581 recall, 0.6046 f1 score\n",
      "2024-02-02 20:20:22,411 INFO     pid:38964 __main__:112:logMetrics E65 val_neg   0.7614 loss,  48.1% correct (64770 of 134598)\n",
      "2024-02-02 20:20:22,412 INFO     pid:38964 __main__:128:logMetrics E65 val_pos   0.6073 loss,  65.8% correct (88578 of 134598)\n",
      "2024-02-02 20:20:22,422 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E66 Training ----/35181, starting\n",
      "2024-02-02 20:20:22,792 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E66 Training   32/35181, done at 2024-02-02 20:24:58, 0:04:35\n",
      "2024-02-02 20:20:23,100 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E66 Training  256/35181, done at 2024-02-02 20:21:37, 0:01:15\n",
      "2024-02-02 20:20:25,485 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E66 Training 2048/35181, done at 2024-02-02 20:21:12, 0:00:50\n",
      "2024-02-02 20:20:44,152 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E66 Training 16384/35181, done at 2024-02-02 20:21:08, 0:00:46\n",
      "2024-02-02 20:21:08,355 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E66 Training 35181/35181, done at 2024-02-02 20:21:08\n",
      "2024-02-02 20:21:08,754 INFO     pid:38964 __main__:011:logMetrics E66 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:21:08,791 INFO     pid:38964 __main__:072:logMetrics E66 trn      0.6666 loss\n",
      "2024-02-02 20:21:08,792 INFO     pid:38964 __main__:097:logMetrics E66 trn        58.6% correct, 0.5966 precision, 0.5302 recall, 0.5614 f1 score\n",
      "2024-02-02 20:21:08,792 INFO     pid:38964 __main__:112:logMetrics E66 trn_neg   0.6650 loss,  64.1% correct (361089 of 562892)\n",
      "2024-02-02 20:21:08,792 INFO     pid:38964 __main__:128:logMetrics E66 trn_pos   0.6682 loss,  53.0% correct (298433 of 562892)\n",
      "2024-02-02 20:21:08,825 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E66 Validation  ----/8413, starting\n",
      "2024-02-02 20:21:08,939 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E66 Validation    16/8413, done at 2024-02-02 20:21:19, 0:00:10\n",
      "2024-02-02 20:21:09,051 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E66 Validation    64/8413, done at 2024-02-02 20:21:26, 0:00:17\n",
      "2024-02-02 20:21:09,265 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E66 Validation   256/8413, done at 2024-02-02 20:21:20, 0:00:11\n",
      "2024-02-02 20:21:10,322 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E66 Validation  1024/8413, done at 2024-02-02 20:21:20, 0:00:11\n",
      "2024-02-02 20:21:13,957 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E66 Validation  4096/8413, done at 2024-02-02 20:21:19, 0:00:10\n",
      "2024-02-02 20:21:19,280 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E66 Validation  8413/8413, done at 2024-02-02 20:21:19\n",
      "2024-02-02 20:21:19,282 INFO     pid:38964 __main__:011:logMetrics E66 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:21:19,286 INFO     pid:38964 __main__:072:logMetrics E66 val      0.6815 loss\n",
      "2024-02-02 20:21:19,286 INFO     pid:38964 __main__:097:logMetrics E66 val        57.1% correct, 0.5666 precision, 0.6006 recall, 0.5831 f1 score\n",
      "2024-02-02 20:21:19,286 INFO     pid:38964 __main__:112:logMetrics E66 val_neg   0.7213 loss,  54.1% correct (72754 of 134598)\n",
      "2024-02-02 20:21:19,287 INFO     pid:38964 __main__:128:logMetrics E66 val_pos   0.6417 loss,  60.1% correct (80837 of 134598)\n",
      "2024-02-02 20:21:19,297 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E67 Training ----/35181, starting\n",
      "2024-02-02 20:21:19,460 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E67 Training   32/35181, done at 2024-02-02 20:22:02, 0:00:42\n",
      "2024-02-02 20:21:19,775 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E67 Training  256/35181, done at 2024-02-02 20:22:08, 0:00:48\n",
      "2024-02-02 20:21:22,023 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E67 Training 2048/35181, done at 2024-02-02 20:22:04, 0:00:44\n",
      "2024-02-02 20:21:40,557 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E67 Training 16384/35181, done at 2024-02-02 20:22:04, 0:00:45\n",
      "2024-02-02 20:22:04,957 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E67 Training 35181/35181, done at 2024-02-02 20:22:04\n",
      "2024-02-02 20:22:05,367 INFO     pid:38964 __main__:011:logMetrics E67 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:22:05,402 INFO     pid:38964 __main__:072:logMetrics E67 trn      0.6657 loss\n",
      "2024-02-02 20:22:05,403 INFO     pid:38964 __main__:097:logMetrics E67 trn        58.8% correct, 0.6000 precision, 0.5285 recall, 0.5620 f1 score\n",
      "2024-02-02 20:22:05,403 INFO     pid:38964 __main__:112:logMetrics E67 trn_neg   0.6638 loss,  64.8% correct (364514 of 562892)\n",
      "2024-02-02 20:22:05,403 INFO     pid:38964 __main__:128:logMetrics E67 trn_pos   0.6675 loss,  52.9% correct (297514 of 562892)\n",
      "2024-02-02 20:22:05,435 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E67 Validation  ----/8413, starting\n",
      "2024-02-02 20:22:05,546 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E67 Validation    16/8413, done at 2024-02-02 20:22:16, 0:00:10\n",
      "2024-02-02 20:22:05,642 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E67 Validation    64/8413, done at 2024-02-02 20:22:21, 0:00:15\n",
      "2024-02-02 20:22:05,857 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E67 Validation   256/8413, done at 2024-02-02 20:22:16, 0:00:10\n",
      "2024-02-02 20:22:07,069 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E67 Validation  1024/8413, done at 2024-02-02 20:22:18, 0:00:12\n",
      "2024-02-02 20:22:10,908 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E67 Validation  4096/8413, done at 2024-02-02 20:22:16, 0:00:11\n",
      "2024-02-02 20:22:16,009 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E67 Validation  8413/8413, done at 2024-02-02 20:22:16\n",
      "2024-02-02 20:22:16,010 INFO     pid:38964 __main__:011:logMetrics E67 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:22:16,014 INFO     pid:38964 __main__:072:logMetrics E67 val      0.6894 loss\n",
      "2024-02-02 20:22:16,014 INFO     pid:38964 __main__:097:logMetrics E67 val        56.5% correct, 0.5475 precision, 0.7502 recall, 0.6330 f1 score\n",
      "2024-02-02 20:22:16,015 INFO     pid:38964 __main__:112:logMetrics E67 val_neg   0.7610 loss,  38.0% correct (51159 of 134598)\n",
      "2024-02-02 20:22:16,015 INFO     pid:38964 __main__:128:logMetrics E67 val_pos   0.6177 loss,  75.0% correct (100973 of 134598)\n",
      "2024-02-02 20:22:16,025 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E68 Training ----/35181, starting\n",
      "2024-02-02 20:22:16,191 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E68 Training   32/35181, done at 2024-02-02 20:23:01, 0:00:45\n",
      "2024-02-02 20:22:16,480 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E68 Training  256/35181, done at 2024-02-02 20:23:01, 0:00:45\n",
      "2024-02-02 20:22:18,771 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E68 Training 2048/35181, done at 2024-02-02 20:23:01, 0:00:45\n",
      "2024-02-02 20:22:37,575 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E68 Training 16384/35181, done at 2024-02-02 20:23:02, 0:00:46\n",
      "2024-02-02 20:23:00,435 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E68 Training 35181/35181, done at 2024-02-02 20:23:00\n",
      "2024-02-02 20:23:00,854 INFO     pid:38964 __main__:011:logMetrics E68 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:23:00,889 INFO     pid:38964 __main__:072:logMetrics E68 trn      0.6657 loss\n",
      "2024-02-02 20:23:00,890 INFO     pid:38964 __main__:097:logMetrics E68 trn        59.0% correct, 0.5986 precision, 0.5443 recall, 0.5702 f1 score\n",
      "2024-02-02 20:23:00,890 INFO     pid:38964 __main__:112:logMetrics E68 trn_neg   0.6638 loss,  63.5% correct (357409 of 562892)\n",
      "2024-02-02 20:23:00,891 INFO     pid:38964 __main__:128:logMetrics E68 trn_pos   0.6675 loss,  54.4% correct (306398 of 562892)\n",
      "2024-02-02 20:23:00,924 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E68 Validation  ----/8413, starting\n",
      "2024-02-02 20:23:01,040 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E68 Validation    16/8413, done at 2024-02-02 20:23:12, 0:00:11\n",
      "2024-02-02 20:23:01,140 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E68 Validation    64/8413, done at 2024-02-02 20:23:17, 0:00:16\n",
      "2024-02-02 20:23:01,353 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E68 Validation   256/8413, done at 2024-02-02 20:23:12, 0:00:10\n",
      "2024-02-02 20:23:02,366 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E68 Validation  1024/8413, done at 2024-02-02 20:23:12, 0:00:11\n",
      "2024-02-02 20:23:06,175 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E68 Validation  4096/8413, done at 2024-02-02 20:23:11, 0:00:10\n",
      "2024-02-02 20:23:11,513 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E68 Validation  8413/8413, done at 2024-02-02 20:23:11\n",
      "2024-02-02 20:23:11,515 INFO     pid:38964 __main__:011:logMetrics E68 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:23:11,520 INFO     pid:38964 __main__:072:logMetrics E68 val      0.6817 loss\n",
      "2024-02-02 20:23:11,520 INFO     pid:38964 __main__:097:logMetrics E68 val        57.4% correct, 0.5557 precision, 0.7391 recall, 0.6344 f1 score\n",
      "2024-02-02 20:23:11,521 INFO     pid:38964 __main__:112:logMetrics E68 val_neg   0.7426 loss,  40.9% correct (55058 of 134598)\n",
      "2024-02-02 20:23:11,521 INFO     pid:38964 __main__:128:logMetrics E68 val_pos   0.6207 loss,  73.9% correct (99485 of 134598)\n",
      "2024-02-02 20:23:11,531 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E69 Training ----/35181, starting\n",
      "2024-02-02 20:23:11,697 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E69 Training   32/35181, done at 2024-02-02 20:23:53, 0:00:41\n",
      "2024-02-02 20:23:11,999 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E69 Training  256/35181, done at 2024-02-02 20:23:58, 0:00:46\n",
      "2024-02-02 20:23:14,499 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E69 Training 2048/35181, done at 2024-02-02 20:24:00, 0:00:48\n",
      "2024-02-02 20:23:33,460 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E69 Training 16384/35181, done at 2024-02-02 20:23:58, 0:00:46\n",
      "2024-02-02 20:23:57,565 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E69 Training 35181/35181, done at 2024-02-02 20:23:57\n",
      "2024-02-02 20:23:57,999 INFO     pid:38964 __main__:011:logMetrics E69 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:23:58,033 INFO     pid:38964 __main__:072:logMetrics E69 trn      0.6666 loss\n",
      "2024-02-02 20:23:58,034 INFO     pid:38964 __main__:097:logMetrics E69 trn        58.7% correct, 0.5958 precision, 0.5408 recall, 0.5670 f1 score\n",
      "2024-02-02 20:23:58,034 INFO     pid:38964 __main__:112:logMetrics E69 trn_neg   0.6651 loss,  63.3% correct (356425 of 562892)\n",
      "2024-02-02 20:23:58,034 INFO     pid:38964 __main__:128:logMetrics E69 trn_pos   0.6680 loss,  54.1% correct (304385 of 562892)\n",
      "2024-02-02 20:23:58,066 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E69 Validation  ----/8413, starting\n",
      "2024-02-02 20:23:58,179 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E69 Validation    16/8413, done at 2024-02-02 20:24:09, 0:00:10\n",
      "2024-02-02 20:23:58,236 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E69 Validation    64/8413, done at 2024-02-02 20:24:08, 0:00:10\n",
      "2024-02-02 20:23:58,690 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E69 Validation   256/8413, done at 2024-02-02 20:24:15, 0:00:17\n",
      "2024-02-02 20:23:59,497 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E69 Validation  1024/8413, done at 2024-02-02 20:24:09, 0:00:11\n",
      "2024-02-02 20:24:03,166 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E69 Validation  4096/8413, done at 2024-02-02 20:24:08, 0:00:10\n",
      "2024-02-02 20:24:08,888 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E69 Validation  8413/8413, done at 2024-02-02 20:24:08\n",
      "2024-02-02 20:24:08,889 INFO     pid:38964 __main__:011:logMetrics E69 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:24:08,893 INFO     pid:38964 __main__:072:logMetrics E69 val      0.6824 loss\n",
      "2024-02-02 20:24:08,894 INFO     pid:38964 __main__:097:logMetrics E69 val        57.4% correct, 0.5616 precision, 0.6700 recall, 0.6111 f1 score\n",
      "2024-02-02 20:24:08,894 INFO     pid:38964 __main__:112:logMetrics E69 val_neg   0.7215 loss,  47.7% correct (64209 of 134598)\n",
      "2024-02-02 20:24:08,894 INFO     pid:38964 __main__:128:logMetrics E69 val_pos   0.6433 loss,  67.0% correct (90182 of 134598)\n",
      "2024-02-02 20:24:08,905 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E70 Training ----/35181, starting\n",
      "2024-02-02 20:24:09,071 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E70 Training   32/35181, done at 2024-02-02 20:24:52, 0:00:43\n",
      "2024-02-02 20:24:09,569 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E70 Training  256/35181, done at 2024-02-02 20:25:23, 0:01:14\n",
      "2024-02-02 20:24:11,783 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E70 Training 2048/35181, done at 2024-02-02 20:24:56, 0:00:47\n",
      "2024-02-02 20:24:30,165 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E70 Training 16384/35181, done at 2024-02-02 20:24:54, 0:00:45\n",
      "2024-02-02 20:24:53,784 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E70 Training 35181/35181, done at 2024-02-02 20:24:53\n",
      "2024-02-02 20:24:54,192 INFO     pid:38964 __main__:011:logMetrics E70 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:24:54,228 INFO     pid:38964 __main__:072:logMetrics E70 trn      0.6664 loss\n",
      "2024-02-02 20:24:54,228 INFO     pid:38964 __main__:097:logMetrics E70 trn        58.8% correct, 0.5964 precision, 0.5427 recall, 0.5682 f1 score\n",
      "2024-02-02 20:24:54,229 INFO     pid:38964 __main__:112:logMetrics E70 trn_neg   0.6646 loss,  63.3% correct (356152 of 562892)\n",
      "2024-02-02 20:24:54,229 INFO     pid:38964 __main__:128:logMetrics E70 trn_pos   0.6683 loss,  54.3% correct (305455 of 562892)\n",
      "2024-02-02 20:24:54,260 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E70 Validation  ----/8413, starting\n",
      "2024-02-02 20:24:54,370 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E70 Validation    16/8413, done at 2024-02-02 20:25:03, 0:00:09\n",
      "2024-02-02 20:24:54,630 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E70 Validation    64/8413, done at 2024-02-02 20:25:31, 0:00:37\n",
      "2024-02-02 20:24:54,833 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E70 Validation   256/8413, done at 2024-02-02 20:25:10, 0:00:15\n",
      "2024-02-02 20:24:55,628 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E70 Validation  1024/8413, done at 2024-02-02 20:25:04, 0:00:10\n",
      "2024-02-02 20:24:59,502 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E70 Validation  4096/8413, done at 2024-02-02 20:25:04, 0:00:10\n",
      "2024-02-02 20:25:04,875 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E70 Validation  8413/8413, done at 2024-02-02 20:25:04\n",
      "2024-02-02 20:25:04,876 INFO     pid:38964 __main__:011:logMetrics E70 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:25:04,880 INFO     pid:38964 __main__:072:logMetrics E70 val      0.6834 loss\n",
      "2024-02-02 20:25:04,881 INFO     pid:38964 __main__:097:logMetrics E70 val        56.9% correct, 0.5629 precision, 0.6145 recall, 0.5876 f1 score\n",
      "2024-02-02 20:25:04,881 INFO     pid:38964 __main__:112:logMetrics E70 val_neg   0.7544 loss,  52.3% correct (70369 of 134598)\n",
      "2024-02-02 20:25:04,881 INFO     pid:38964 __main__:128:logMetrics E70 val_pos   0.6124 loss,  61.5% correct (82716 of 134598)\n",
      "2024-02-02 20:25:04,892 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E71 Training ----/35181, starting\n",
      "2024-02-02 20:25:05,100 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E71 Training   32/35181, done at 2024-02-02 20:26:36, 0:01:31\n",
      "2024-02-02 20:25:05,551 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E71 Training  256/35181, done at 2024-02-02 20:26:18, 0:01:13\n",
      "2024-02-02 20:25:07,756 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E71 Training 2048/35181, done at 2024-02-02 20:25:52, 0:00:47\n",
      "2024-02-02 20:25:25,634 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E71 Training 16384/35181, done at 2024-02-02 20:25:49, 0:00:44\n",
      "2024-02-02 20:25:49,274 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E71 Training 35181/35181, done at 2024-02-02 20:25:49\n",
      "2024-02-02 20:25:49,688 INFO     pid:38964 __main__:011:logMetrics E71 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:25:49,721 INFO     pid:38964 __main__:072:logMetrics E71 trn      0.6669 loss\n",
      "2024-02-02 20:25:49,722 INFO     pid:38964 __main__:097:logMetrics E71 trn        58.8% correct, 0.5961 precision, 0.5443 recall, 0.5690 f1 score\n",
      "2024-02-02 20:25:49,722 INFO     pid:38964 __main__:112:logMetrics E71 trn_neg   0.6652 loss,  63.1% correct (355271 of 562892)\n",
      "2024-02-02 20:25:49,722 INFO     pid:38964 __main__:128:logMetrics E71 trn_pos   0.6685 loss,  54.4% correct (306366 of 562892)\n",
      "2024-02-02 20:25:49,757 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E71 Validation  ----/8413, starting\n",
      "2024-02-02 20:25:49,869 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E71 Validation    16/8413, done at 2024-02-02 20:26:00, 0:00:10\n",
      "2024-02-02 20:25:49,965 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E71 Validation    64/8413, done at 2024-02-02 20:26:05, 0:00:15\n",
      "2024-02-02 20:25:50,172 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E71 Validation   256/8413, done at 2024-02-02 20:26:00, 0:00:10\n",
      "2024-02-02 20:25:51,174 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E71 Validation  1024/8413, done at 2024-02-02 20:26:00, 0:00:10\n",
      "2024-02-02 20:25:54,749 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E71 Validation  4096/8413, done at 2024-02-02 20:25:59, 0:00:10\n",
      "2024-02-02 20:25:59,785 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E71 Validation  8413/8413, done at 2024-02-02 20:25:59\n",
      "2024-02-02 20:25:59,786 INFO     pid:38964 __main__:011:logMetrics E71 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:25:59,790 INFO     pid:38964 __main__:072:logMetrics E71 val      0.6874 loss\n",
      "2024-02-02 20:25:59,790 INFO     pid:38964 __main__:097:logMetrics E71 val        56.1% correct, 0.5485 precision, 0.6863 recall, 0.6097 f1 score\n",
      "2024-02-02 20:25:59,790 INFO     pid:38964 __main__:112:logMetrics E71 val_neg   0.7673 loss,  43.5% correct (58558 of 134598)\n",
      "2024-02-02 20:25:59,791 INFO     pid:38964 __main__:128:logMetrics E71 val_pos   0.6075 loss,  68.6% correct (92372 of 134598)\n",
      "2024-02-02 20:25:59,801 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E72 Training ----/35181, starting\n",
      "2024-02-02 20:25:59,976 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E72 Training   32/35181, done at 2024-02-02 20:26:50, 0:00:50\n",
      "2024-02-02 20:26:00,255 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E72 Training  256/35181, done at 2024-02-02 20:26:44, 0:00:44\n",
      "2024-02-02 20:26:02,488 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E72 Training 2048/35181, done at 2024-02-02 20:26:43, 0:00:43\n",
      "2024-02-02 20:26:20,765 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E72 Training 16384/35181, done at 2024-02-02 20:26:44, 0:00:44\n",
      "2024-02-02 20:26:44,694 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E72 Training 35181/35181, done at 2024-02-02 20:26:44\n",
      "2024-02-02 20:26:45,102 INFO     pid:38964 __main__:011:logMetrics E72 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:26:45,140 INFO     pid:38964 __main__:072:logMetrics E72 trn      0.6670 loss\n",
      "2024-02-02 20:26:45,140 INFO     pid:38964 __main__:097:logMetrics E72 trn        58.6% correct, 0.5926 precision, 0.5501 recall, 0.5705 f1 score\n",
      "2024-02-02 20:26:45,140 INFO     pid:38964 __main__:112:logMetrics E72 trn_neg   0.6654 loss,  62.2% correct (350041 of 562892)\n",
      "2024-02-02 20:26:45,140 INFO     pid:38964 __main__:128:logMetrics E72 trn_pos   0.6686 loss,  55.0% correct (309621 of 562892)\n",
      "2024-02-02 20:26:45,173 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E72 Validation  ----/8413, starting\n",
      "2024-02-02 20:26:45,317 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E72 Validation    16/8413, done at 2024-02-02 20:26:55, 0:00:09\n",
      "2024-02-02 20:26:45,369 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E72 Validation    64/8413, done at 2024-02-02 20:26:54, 0:00:09\n",
      "2024-02-02 20:26:45,578 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E72 Validation   256/8413, done at 2024-02-02 20:26:54, 0:00:09\n",
      "2024-02-02 20:26:46,604 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E72 Validation  1024/8413, done at 2024-02-02 20:26:56, 0:00:10\n",
      "2024-02-02 20:26:50,249 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E72 Validation  4096/8413, done at 2024-02-02 20:26:55, 0:00:10\n",
      "2024-02-02 20:26:55,074 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E72 Validation  8413/8413, done at 2024-02-02 20:26:55\n",
      "2024-02-02 20:26:55,076 INFO     pid:38964 __main__:011:logMetrics E72 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:26:55,081 INFO     pid:38964 __main__:072:logMetrics E72 val      0.6894 loss\n",
      "2024-02-02 20:26:55,082 INFO     pid:38964 __main__:097:logMetrics E72 val        55.3% correct, 0.5373 precision, 0.7626 recall, 0.6305 f1 score\n",
      "2024-02-02 20:26:55,082 INFO     pid:38964 __main__:112:logMetrics E72 val_neg   0.7960 loss,  34.3% correct (46222 of 134598)\n",
      "2024-02-02 20:26:55,082 INFO     pid:38964 __main__:128:logMetrics E72 val_pos   0.5827 loss,  76.3% correct (102644 of 134598)\n",
      "2024-02-02 20:26:55,093 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E73 Training ----/35181, starting\n",
      "2024-02-02 20:26:55,261 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E73 Training   32/35181, done at 2024-02-02 20:27:39, 0:00:44\n",
      "2024-02-02 20:26:55,559 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E73 Training  256/35181, done at 2024-02-02 20:27:41, 0:00:46\n",
      "2024-02-02 20:26:57,770 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E73 Training 2048/35181, done at 2024-02-02 20:27:39, 0:00:43\n",
      "2024-02-02 20:27:15,701 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E73 Training 16384/35181, done at 2024-02-02 20:27:39, 0:00:43\n",
      "2024-02-02 20:27:38,197 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E73 Training 35181/35181, done at 2024-02-02 20:27:38\n",
      "2024-02-02 20:27:38,613 INFO     pid:38964 __main__:011:logMetrics E73 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:27:38,650 INFO     pid:38964 __main__:072:logMetrics E73 trn      0.6668 loss\n",
      "2024-02-02 20:27:38,650 INFO     pid:38964 __main__:097:logMetrics E73 trn        58.6% correct, 0.5941 precision, 0.5458 recall, 0.5689 f1 score\n",
      "2024-02-02 20:27:38,651 INFO     pid:38964 __main__:112:logMetrics E73 trn_neg   0.6654 loss,  62.7% correct (353029 of 562892)\n",
      "2024-02-02 20:27:38,651 INFO     pid:38964 __main__:128:logMetrics E73 trn_pos   0.6682 loss,  54.6% correct (307206 of 562892)\n",
      "2024-02-02 20:27:38,684 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E73 Validation  ----/8413, starting\n",
      "2024-02-02 20:27:38,820 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E73 Validation    16/8413, done at 2024-02-02 20:27:48, 0:00:09\n",
      "2024-02-02 20:27:38,877 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E73 Validation    64/8413, done at 2024-02-02 20:27:48, 0:00:09\n",
      "2024-02-02 20:27:39,082 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E73 Validation   256/8413, done at 2024-02-02 20:27:48, 0:00:09\n",
      "2024-02-02 20:27:40,349 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E73 Validation  1024/8413, done at 2024-02-02 20:27:51, 0:00:12\n",
      "2024-02-02 20:27:43,960 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E73 Validation  4096/8413, done at 2024-02-02 20:27:49, 0:00:10\n",
      "2024-02-02 20:27:49,161 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E73 Validation  8413/8413, done at 2024-02-02 20:27:49\n",
      "2024-02-02 20:27:49,163 INFO     pid:38964 __main__:011:logMetrics E73 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:27:49,166 INFO     pid:38964 __main__:072:logMetrics E73 val      0.6858 loss\n",
      "2024-02-02 20:27:49,167 INFO     pid:38964 __main__:097:logMetrics E73 val        57.0% correct, 0.5672 precision, 0.5934 recall, 0.5800 f1 score\n",
      "2024-02-02 20:27:49,167 INFO     pid:38964 __main__:112:logMetrics E73 val_neg   0.7213 loss,  54.7% correct (73653 of 134598)\n",
      "2024-02-02 20:27:49,167 INFO     pid:38964 __main__:128:logMetrics E73 val_pos   0.6502 loss,  59.3% correct (79873 of 134598)\n",
      "2024-02-02 20:27:49,178 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E74 Training ----/35181, starting\n",
      "2024-02-02 20:27:49,344 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E74 Training   32/35181, done at 2024-02-02 20:28:35, 0:00:46\n",
      "2024-02-02 20:27:49,645 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E74 Training  256/35181, done at 2024-02-02 20:28:36, 0:00:47\n",
      "2024-02-02 20:27:52,047 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E74 Training 2048/35181, done at 2024-02-02 20:28:36, 0:00:47\n",
      "2024-02-02 20:28:10,503 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E74 Training 16384/35181, done at 2024-02-02 20:28:34, 0:00:45\n",
      "2024-02-02 20:28:34,751 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E74 Training 35181/35181, done at 2024-02-02 20:28:34\n",
      "2024-02-02 20:28:35,165 INFO     pid:38964 __main__:011:logMetrics E74 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:28:35,201 INFO     pid:38964 __main__:072:logMetrics E74 trn      0.6671 loss\n",
      "2024-02-02 20:28:35,202 INFO     pid:38964 __main__:097:logMetrics E74 trn        58.6% correct, 0.5935 precision, 0.5460 recall, 0.5687 f1 score\n",
      "2024-02-02 20:28:35,202 INFO     pid:38964 __main__:112:logMetrics E74 trn_neg   0.6653 loss,  62.6% correct (352372 of 562892)\n",
      "2024-02-02 20:28:35,202 INFO     pid:38964 __main__:128:logMetrics E74 trn_pos   0.6688 loss,  54.6% correct (307335 of 562892)\n",
      "2024-02-02 20:28:35,239 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E74 Validation  ----/8413, starting\n",
      "2024-02-02 20:28:35,393 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E74 Validation    16/8413, done at 2024-02-02 20:29:10, 0:00:35\n",
      "2024-02-02 20:28:35,449 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E74 Validation    64/8413, done at 2024-02-02 20:28:50, 0:00:15\n",
      "2024-02-02 20:28:35,657 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E74 Validation   256/8413, done at 2024-02-02 20:28:46, 0:00:10\n",
      "2024-02-02 20:28:36,639 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E74 Validation  1024/8413, done at 2024-02-02 20:28:46, 0:00:10\n",
      "2024-02-02 20:28:40,225 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E74 Validation  4096/8413, done at 2024-02-02 20:28:45, 0:00:10\n",
      "2024-02-02 20:28:45,267 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E74 Validation  8413/8413, done at 2024-02-02 20:28:45\n",
      "2024-02-02 20:28:45,269 INFO     pid:38964 __main__:011:logMetrics E74 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:28:45,274 INFO     pid:38964 __main__:072:logMetrics E74 val      0.6801 loss\n",
      "2024-02-02 20:28:45,274 INFO     pid:38964 __main__:097:logMetrics E74 val        57.1% correct, 0.5593 precision, 0.6726 recall, 0.6108 f1 score\n",
      "2024-02-02 20:28:45,274 INFO     pid:38964 __main__:112:logMetrics E74 val_neg   0.7107 loss,  47.0% correct (63265 of 134598)\n",
      "2024-02-02 20:28:45,274 INFO     pid:38964 __main__:128:logMetrics E74 val_pos   0.6494 loss,  67.3% correct (90536 of 134598)\n",
      "2024-02-02 20:28:45,284 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E75 Training ----/35181, starting\n",
      "2024-02-02 20:28:45,455 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E75 Training   32/35181, done at 2024-02-02 20:29:28, 0:00:43\n",
      "2024-02-02 20:28:45,739 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E75 Training  256/35181, done at 2024-02-02 20:29:29, 0:00:44\n",
      "2024-02-02 20:28:48,156 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E75 Training 2048/35181, done at 2024-02-02 20:29:32, 0:00:47\n",
      "2024-02-02 20:29:05,430 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E75 Training 16384/35181, done at 2024-02-02 20:29:28, 0:00:42\n",
      "2024-02-02 20:29:28,358 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E75 Training 35181/35181, done at 2024-02-02 20:29:28\n",
      "2024-02-02 20:29:28,791 INFO     pid:38964 __main__:011:logMetrics E75 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:29:28,823 INFO     pid:38964 __main__:072:logMetrics E75 trn      0.6665 loss\n",
      "2024-02-02 20:29:28,824 INFO     pid:38964 __main__:097:logMetrics E75 trn        58.6% correct, 0.5941 precision, 0.5408 recall, 0.5662 f1 score\n",
      "2024-02-02 20:29:28,825 INFO     pid:38964 __main__:112:logMetrics E75 trn_neg   0.6648 loss,  63.0% correct (354900 of 562892)\n",
      "2024-02-02 20:29:28,825 INFO     pid:38964 __main__:128:logMetrics E75 trn_pos   0.6682 loss,  54.1% correct (304389 of 562892)\n",
      "2024-02-02 20:29:28,859 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E75 Validation  ----/8413, starting\n",
      "2024-02-02 20:29:28,970 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E75 Validation    16/8413, done at 2024-02-02 20:29:39, 0:00:10\n",
      "2024-02-02 20:29:29,027 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E75 Validation    64/8413, done at 2024-02-02 20:29:39, 0:00:10\n",
      "2024-02-02 20:29:29,450 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E75 Validation   256/8413, done at 2024-02-02 20:29:45, 0:00:16\n",
      "2024-02-02 20:29:30,260 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E75 Validation  1024/8413, done at 2024-02-02 20:29:39, 0:00:10\n",
      "2024-02-02 20:29:33,811 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E75 Validation  4096/8413, done at 2024-02-02 20:29:38, 0:00:09\n",
      "2024-02-02 20:29:39,253 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E75 Validation  8413/8413, done at 2024-02-02 20:29:39\n",
      "2024-02-02 20:29:39,254 INFO     pid:38964 __main__:011:logMetrics E75 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:29:39,258 INFO     pid:38964 __main__:072:logMetrics E75 val      0.6887 loss\n",
      "2024-02-02 20:29:39,258 INFO     pid:38964 __main__:097:logMetrics E75 val        54.6% correct, 0.5296 precision, 0.8171 recall, 0.6427 f1 score\n",
      "2024-02-02 20:29:39,258 INFO     pid:38964 __main__:112:logMetrics E75 val_neg   0.7879 loss,  27.4% correct (36914 of 134598)\n",
      "2024-02-02 20:29:39,258 INFO     pid:38964 __main__:128:logMetrics E75 val_pos   0.5894 loss,  81.7% correct (109980 of 134598)\n",
      "2024-02-02 20:29:39,267 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E76 Training ----/35181, starting\n",
      "2024-02-02 20:29:39,432 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E76 Training   32/35181, done at 2024-02-02 20:30:25, 0:00:46\n",
      "2024-02-02 20:29:39,898 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E76 Training  256/35181, done at 2024-02-02 20:30:49, 0:01:10\n",
      "2024-02-02 20:29:42,226 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E76 Training 2048/35181, done at 2024-02-02 20:30:28, 0:00:48\n",
      "2024-02-02 20:30:00,573 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E76 Training 16384/35181, done at 2024-02-02 20:30:24, 0:00:45\n",
      "2024-02-02 20:30:23,659 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E76 Training 35181/35181, done at 2024-02-02 20:30:23\n",
      "2024-02-02 20:30:24,080 INFO     pid:38964 __main__:011:logMetrics E76 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:30:24,114 INFO     pid:38964 __main__:072:logMetrics E76 trn      0.6665 loss\n",
      "2024-02-02 20:30:24,115 INFO     pid:38964 __main__:097:logMetrics E76 trn        58.6% correct, 0.5961 precision, 0.5344 recall, 0.5636 f1 score\n",
      "2024-02-02 20:30:24,115 INFO     pid:38964 __main__:112:logMetrics E76 trn_neg   0.6648 loss,  63.8% correct (359030 of 562892)\n",
      "2024-02-02 20:30:24,116 INFO     pid:38964 __main__:128:logMetrics E76 trn_pos   0.6683 loss,  53.4% correct (300836 of 562892)\n",
      "2024-02-02 20:30:24,148 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E76 Validation  ----/8413, starting\n",
      "2024-02-02 20:30:24,260 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E76 Validation    16/8413, done at 2024-02-02 20:30:34, 0:00:10\n",
      "2024-02-02 20:30:24,344 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E76 Validation    64/8413, done at 2024-02-02 20:30:38, 0:00:13\n",
      "2024-02-02 20:30:24,550 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E76 Validation   256/8413, done at 2024-02-02 20:30:34, 0:00:10\n",
      "2024-02-02 20:30:25,350 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E76 Validation  1024/8413, done at 2024-02-02 20:30:33, 0:00:09\n",
      "2024-02-02 20:30:28,983 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E76 Validation  4096/8413, done at 2024-02-02 20:30:33, 0:00:09\n",
      "2024-02-02 20:30:34,065 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E76 Validation  8413/8413, done at 2024-02-02 20:30:34\n",
      "2024-02-02 20:30:34,067 INFO     pid:38964 __main__:011:logMetrics E76 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:30:34,071 INFO     pid:38964 __main__:072:logMetrics E76 val      0.6815 loss\n",
      "2024-02-02 20:30:34,071 INFO     pid:38964 __main__:097:logMetrics E76 val        57.3% correct, 0.5585 precision, 0.6946 recall, 0.6192 f1 score\n",
      "2024-02-02 20:30:34,072 INFO     pid:38964 __main__:112:logMetrics E76 val_neg   0.7323 loss,  45.1% correct (60680 of 134598)\n",
      "2024-02-02 20:30:34,072 INFO     pid:38964 __main__:128:logMetrics E76 val_pos   0.6307 loss,  69.5% correct (93498 of 134598)\n",
      "2024-02-02 20:30:34,083 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E77 Training ----/35181, starting\n",
      "2024-02-02 20:30:34,253 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E77 Training   32/35181, done at 2024-02-02 20:31:23, 0:00:49\n",
      "2024-02-02 20:30:34,557 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E77 Training  256/35181, done at 2024-02-02 20:31:22, 0:00:47\n",
      "2024-02-02 20:30:37,058 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E77 Training 2048/35181, done at 2024-02-02 20:31:23, 0:00:48\n",
      "2024-02-02 20:30:55,590 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E77 Training 16384/35181, done at 2024-02-02 20:31:20, 0:00:45\n",
      "2024-02-02 20:31:18,858 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E77 Training 35181/35181, done at 2024-02-02 20:31:18\n",
      "2024-02-02 20:31:19,274 INFO     pid:38964 __main__:011:logMetrics E77 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:31:19,309 INFO     pid:38964 __main__:072:logMetrics E77 trn      0.6669 loss\n",
      "2024-02-02 20:31:19,310 INFO     pid:38964 __main__:097:logMetrics E77 trn        58.7% correct, 0.5992 precision, 0.5237 recall, 0.5589 f1 score\n",
      "2024-02-02 20:31:19,310 INFO     pid:38964 __main__:112:logMetrics E77 trn_neg   0.6652 loss,  65.0% correct (365715 of 562892)\n",
      "2024-02-02 20:31:19,311 INFO     pid:38964 __main__:128:logMetrics E77 trn_pos   0.6686 loss,  52.4% correct (294804 of 562892)\n",
      "2024-02-02 20:31:19,344 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E77 Validation  ----/8413, starting\n",
      "2024-02-02 20:31:19,471 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E77 Validation    16/8413, done at 2024-02-02 20:31:28, 0:00:08\n",
      "2024-02-02 20:31:19,523 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E77 Validation    64/8413, done at 2024-02-02 20:31:28, 0:00:09\n",
      "2024-02-02 20:31:19,733 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E77 Validation   256/8413, done at 2024-02-02 20:31:28, 0:00:09\n",
      "2024-02-02 20:31:20,752 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E77 Validation  1024/8413, done at 2024-02-02 20:31:30, 0:00:10\n",
      "2024-02-02 20:31:24,589 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E77 Validation  4096/8413, done at 2024-02-02 20:31:30, 0:00:10\n",
      "2024-02-02 20:31:29,623 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E77 Validation  8413/8413, done at 2024-02-02 20:31:29\n",
      "2024-02-02 20:31:29,624 INFO     pid:38964 __main__:011:logMetrics E77 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:31:29,628 INFO     pid:38964 __main__:072:logMetrics E77 val      0.6825 loss\n",
      "2024-02-02 20:31:29,628 INFO     pid:38964 __main__:097:logMetrics E77 val        56.4% correct, 0.5479 precision, 0.7356 recall, 0.6280 f1 score\n",
      "2024-02-02 20:31:29,629 INFO     pid:38964 __main__:112:logMetrics E77 val_neg   0.7320 loss,  39.3% correct (52890 of 134598)\n",
      "2024-02-02 20:31:29,629 INFO     pid:38964 __main__:128:logMetrics E77 val_pos   0.6330 loss,  73.6% correct (99011 of 134598)\n",
      "2024-02-02 20:31:29,639 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E78 Training ----/35181, starting\n",
      "2024-02-02 20:31:29,806 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E78 Training   32/35181, done at 2024-02-02 20:32:13, 0:00:43\n",
      "2024-02-02 20:31:30,106 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E78 Training  256/35181, done at 2024-02-02 20:32:16, 0:00:46\n",
      "2024-02-02 20:31:32,530 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E78 Training 2048/35181, done at 2024-02-02 20:32:17, 0:00:47\n",
      "2024-02-02 20:31:51,821 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E78 Training 16384/35181, done at 2024-02-02 20:32:17, 0:00:47\n",
      "2024-02-02 20:32:14,237 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E78 Training 35181/35181, done at 2024-02-02 20:32:14\n",
      "2024-02-02 20:32:14,667 INFO     pid:38964 __main__:011:logMetrics E78 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:32:14,703 INFO     pid:38964 __main__:072:logMetrics E78 trn      0.6662 loss\n",
      "2024-02-02 20:32:14,703 INFO     pid:38964 __main__:097:logMetrics E78 trn        58.6% correct, 0.5989 precision, 0.5235 recall, 0.5587 f1 score\n",
      "2024-02-02 20:32:14,703 INFO     pid:38964 __main__:112:logMetrics E78 trn_neg   0.6643 loss,  64.9% correct (365582 of 562892)\n",
      "2024-02-02 20:32:14,704 INFO     pid:38964 __main__:128:logMetrics E78 trn_pos   0.6681 loss,  52.3% correct (294655 of 562892)\n",
      "2024-02-02 20:32:14,736 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E78 Validation  ----/8413, starting\n",
      "2024-02-02 20:32:14,844 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E78 Validation    16/8413, done at 2024-02-02 20:32:24, 0:00:09\n",
      "2024-02-02 20:32:14,946 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E78 Validation    64/8413, done at 2024-02-02 20:32:30, 0:00:15\n",
      "2024-02-02 20:32:15,146 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E78 Validation   256/8413, done at 2024-02-02 20:32:25, 0:00:10\n",
      "2024-02-02 20:32:16,161 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E78 Validation  1024/8413, done at 2024-02-02 20:32:25, 0:00:10\n",
      "2024-02-02 20:32:19,914 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E78 Validation  4096/8413, done at 2024-02-02 20:32:25, 0:00:10\n",
      "2024-02-02 20:32:24,976 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E78 Validation  8413/8413, done at 2024-02-02 20:32:24\n",
      "2024-02-02 20:32:24,978 INFO     pid:38964 __main__:011:logMetrics E78 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:32:24,982 INFO     pid:38964 __main__:072:logMetrics E78 val      0.6806 loss\n",
      "2024-02-02 20:32:24,982 INFO     pid:38964 __main__:097:logMetrics E78 val        57.1% correct, 0.5734 precision, 0.5507 recall, 0.5618 f1 score\n",
      "2024-02-02 20:32:24,983 INFO     pid:38964 __main__:112:logMetrics E78 val_neg   0.6833 loss,  59.0% correct (79463 of 134598)\n",
      "2024-02-02 20:32:24,983 INFO     pid:38964 __main__:128:logMetrics E78 val_pos   0.6779 loss,  55.1% correct (74121 of 134598)\n",
      "2024-02-02 20:32:24,994 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E79 Training ----/35181, starting\n",
      "2024-02-02 20:32:25,158 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E79 Training   32/35181, done at 2024-02-02 20:33:08, 0:00:43\n",
      "2024-02-02 20:32:25,438 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E79 Training  256/35181, done at 2024-02-02 20:33:08, 0:00:43\n",
      "2024-02-02 20:32:27,990 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E79 Training 2048/35181, done at 2024-02-02 20:33:14, 0:00:49\n",
      "2024-02-02 20:32:46,070 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E79 Training 16384/35181, done at 2024-02-02 20:33:10, 0:00:44\n",
      "2024-02-02 20:33:10,420 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E79 Training 35181/35181, done at 2024-02-02 20:33:10\n",
      "2024-02-02 20:33:10,827 INFO     pid:38964 __main__:011:logMetrics E79 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:33:10,864 INFO     pid:38964 __main__:072:logMetrics E79 trn      0.6673 loss\n",
      "2024-02-02 20:33:10,865 INFO     pid:38964 __main__:097:logMetrics E79 trn        58.6% correct, 0.5942 precision, 0.5440 recall, 0.5680 f1 score\n",
      "2024-02-02 20:33:10,865 INFO     pid:38964 __main__:112:logMetrics E79 trn_neg   0.6657 loss,  62.8% correct (353766 of 562892)\n",
      "2024-02-02 20:33:10,865 INFO     pid:38964 __main__:128:logMetrics E79 trn_pos   0.6689 loss,  54.4% correct (306197 of 562892)\n",
      "2024-02-02 20:33:10,897 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E79 Validation  ----/8413, starting\n",
      "2024-02-02 20:33:11,009 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E79 Validation    16/8413, done at 2024-02-02 20:33:22, 0:00:11\n",
      "2024-02-02 20:33:11,104 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E79 Validation    64/8413, done at 2024-02-02 20:33:26, 0:00:15\n",
      "2024-02-02 20:33:11,308 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E79 Validation   256/8413, done at 2024-02-02 20:33:21, 0:00:10\n",
      "2024-02-02 20:33:12,327 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E79 Validation  1024/8413, done at 2024-02-02 20:33:22, 0:00:11\n",
      "2024-02-02 20:33:15,937 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E79 Validation  4096/8413, done at 2024-02-02 20:33:21, 0:00:10\n",
      "2024-02-02 20:33:21,032 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E79 Validation  8413/8413, done at 2024-02-02 20:33:21\n",
      "2024-02-02 20:33:21,034 INFO     pid:38964 __main__:011:logMetrics E79 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:33:21,038 INFO     pid:38964 __main__:072:logMetrics E79 val      0.6878 loss\n",
      "2024-02-02 20:33:21,039 INFO     pid:38964 __main__:097:logMetrics E79 val        55.4% correct, 0.5367 precision, 0.7934 recall, 0.6403 f1 score\n",
      "2024-02-02 20:33:21,039 INFO     pid:38964 __main__:112:logMetrics E79 val_neg   0.7829 loss,  31.5% correct (42422 of 134598)\n",
      "2024-02-02 20:33:21,039 INFO     pid:38964 __main__:128:logMetrics E79 val_pos   0.5928 loss,  79.3% correct (106787 of 134598)\n",
      "2024-02-02 20:33:21,049 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E80 Training ----/35181, starting\n",
      "2024-02-02 20:33:21,219 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E80 Training   32/35181, done at 2024-02-02 20:34:06, 0:00:45\n",
      "2024-02-02 20:33:21,523 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E80 Training  256/35181, done at 2024-02-02 20:34:08, 0:00:47\n",
      "2024-02-02 20:33:24,110 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E80 Training 2048/35181, done at 2024-02-02 20:34:11, 0:00:50\n",
      "2024-02-02 20:33:42,589 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E80 Training 16384/35181, done at 2024-02-02 20:34:07, 0:00:45\n",
      "2024-02-02 20:34:05,964 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E80 Training 35181/35181, done at 2024-02-02 20:34:05\n",
      "2024-02-02 20:34:06,410 INFO     pid:38964 __main__:011:logMetrics E80 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:34:06,445 INFO     pid:38964 __main__:072:logMetrics E80 trn      0.6743 loss\n",
      "2024-02-02 20:34:06,446 INFO     pid:38964 __main__:097:logMetrics E80 trn        57.9% correct, 0.5763 precision, 0.5935 recall, 0.5848 f1 score\n",
      "2024-02-02 20:34:06,446 INFO     pid:38964 __main__:112:logMetrics E80 trn_neg   0.6739 loss,  56.4% correct (317240 of 562892)\n",
      "2024-02-02 20:34:06,446 INFO     pid:38964 __main__:128:logMetrics E80 trn_pos   0.6747 loss,  59.4% correct (334088 of 562892)\n",
      "2024-02-02 20:34:06,478 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E80 Validation  ----/8413, starting\n",
      "2024-02-02 20:34:06,590 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E80 Validation    16/8413, done at 2024-02-02 20:34:17, 0:00:10\n",
      "2024-02-02 20:34:06,648 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E80 Validation    64/8413, done at 2024-02-02 20:34:16, 0:00:10\n",
      "2024-02-02 20:34:07,087 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E80 Validation   256/8413, done at 2024-02-02 20:34:23, 0:00:17\n",
      "2024-02-02 20:34:07,899 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E80 Validation  1024/8413, done at 2024-02-02 20:34:17, 0:00:10\n",
      "2024-02-02 20:34:11,780 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E80 Validation  4096/8413, done at 2024-02-02 20:34:17, 0:00:10\n",
      "2024-02-02 20:34:17,220 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E80 Validation  8413/8413, done at 2024-02-02 20:34:17\n",
      "2024-02-02 20:34:17,222 INFO     pid:38964 __main__:011:logMetrics E80 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:34:17,227 INFO     pid:38964 __main__:072:logMetrics E80 val      0.6862 loss\n",
      "2024-02-02 20:34:17,227 INFO     pid:38964 __main__:097:logMetrics E80 val        54.8% correct, 0.5298 precision, 0.8573 recall, 0.6549 f1 score\n",
      "2024-02-02 20:34:17,227 INFO     pid:38964 __main__:112:logMetrics E80 val_neg   0.7978 loss,  23.9% correct (32188 of 134598)\n",
      "2024-02-02 20:34:17,227 INFO     pid:38964 __main__:128:logMetrics E80 val_pos   0.5746 loss,  85.7% correct (115392 of 134598)\n",
      "2024-02-02 20:34:17,236 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E81 Training ----/35181, starting\n",
      "2024-02-02 20:34:17,401 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E81 Training   32/35181, done at 2024-02-02 20:35:00, 0:00:43\n",
      "2024-02-02 20:34:17,897 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E81 Training  256/35181, done at 2024-02-02 20:35:31, 0:01:13\n",
      "2024-02-02 20:34:20,106 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E81 Training 2048/35181, done at 2024-02-02 20:35:04, 0:00:47\n",
      "2024-02-02 20:34:38,485 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E81 Training 16384/35181, done at 2024-02-02 20:35:02, 0:00:45\n",
      "2024-02-02 20:35:02,838 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E81 Training 35181/35181, done at 2024-02-02 20:35:02\n",
      "2024-02-02 20:35:03,255 INFO     pid:38964 __main__:011:logMetrics E81 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:35:03,287 INFO     pid:38964 __main__:072:logMetrics E81 trn      0.6765 loss\n",
      "2024-02-02 20:35:03,288 INFO     pid:38964 __main__:097:logMetrics E81 trn        57.9% correct, 0.5789 precision, 0.5779 recall, 0.5784 f1 score\n",
      "2024-02-02 20:35:03,288 INFO     pid:38964 __main__:112:logMetrics E81 trn_neg   0.6759 loss,  58.0% correct (326295 of 562892)\n",
      "2024-02-02 20:35:03,288 INFO     pid:38964 __main__:128:logMetrics E81 trn_pos   0.6771 loss,  57.8% correct (325284 of 562892)\n",
      "2024-02-02 20:35:03,322 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E81 Validation  ----/8413, starting\n",
      "2024-02-02 20:35:03,434 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E81 Validation    16/8413, done at 2024-02-02 20:35:12, 0:00:09\n",
      "2024-02-02 20:35:03,488 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E81 Validation    64/8413, done at 2024-02-02 20:35:12, 0:00:09\n",
      "2024-02-02 20:35:03,722 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E81 Validation   256/8413, done at 2024-02-02 20:35:13, 0:00:10\n",
      "2024-02-02 20:35:04,512 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E81 Validation  1024/8413, done at 2024-02-02 20:35:12, 0:00:09\n",
      "2024-02-02 20:35:08,186 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E81 Validation  4096/8413, done at 2024-02-02 20:35:13, 0:00:09\n",
      "2024-02-02 20:35:13,248 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E81 Validation  8413/8413, done at 2024-02-02 20:35:13\n",
      "2024-02-02 20:35:13,250 INFO     pid:38964 __main__:011:logMetrics E81 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:35:13,253 INFO     pid:38964 __main__:072:logMetrics E81 val      0.6844 loss\n",
      "2024-02-02 20:35:13,254 INFO     pid:38964 __main__:097:logMetrics E81 val        56.0% correct, 0.5415 precision, 0.7821 recall, 0.6399 f1 score\n",
      "2024-02-02 20:35:13,254 INFO     pid:38964 __main__:112:logMetrics E81 val_neg   0.7695 loss,  33.8% correct (45446 of 134598)\n",
      "2024-02-02 20:35:13,254 INFO     pid:38964 __main__:128:logMetrics E81 val_pos   0.5993 loss,  78.2% correct (105270 of 134598)\n",
      "2024-02-02 20:35:13,266 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E82 Training ----/35181, starting\n",
      "2024-02-02 20:35:13,472 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E82 Training   32/35181, done at 2024-02-02 20:36:02, 0:00:49\n",
      "2024-02-02 20:35:13,745 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E82 Training  256/35181, done at 2024-02-02 20:35:57, 0:00:43\n",
      "2024-02-02 20:35:16,075 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E82 Training 2048/35181, done at 2024-02-02 20:35:58, 0:00:45\n",
      "2024-02-02 20:35:33,788 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E82 Training 16384/35181, done at 2024-02-02 20:35:57, 0:00:43\n",
      "2024-02-02 20:35:57,242 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E82 Training 35181/35181, done at 2024-02-02 20:35:57\n",
      "2024-02-02 20:35:57,654 INFO     pid:38964 __main__:011:logMetrics E82 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:35:57,689 INFO     pid:38964 __main__:072:logMetrics E82 trn      0.6760 loss\n",
      "2024-02-02 20:35:57,690 INFO     pid:38964 __main__:097:logMetrics E82 trn        57.9% correct, 0.5759 precision, 0.5977 recall, 0.5866 f1 score\n",
      "2024-02-02 20:35:57,690 INFO     pid:38964 __main__:112:logMetrics E82 trn_neg   0.6756 loss,  56.0% correct (315190 of 562892)\n",
      "2024-02-02 20:35:57,691 INFO     pid:38964 __main__:128:logMetrics E82 trn_pos   0.6765 loss,  59.8% correct (336421 of 562892)\n",
      "2024-02-02 20:35:57,726 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E82 Validation  ----/8413, starting\n",
      "2024-02-02 20:35:57,837 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E82 Validation    16/8413, done at 2024-02-02 20:36:08, 0:00:11\n",
      "2024-02-02 20:35:57,937 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E82 Validation    64/8413, done at 2024-02-02 20:36:13, 0:00:16\n",
      "2024-02-02 20:35:58,134 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E82 Validation   256/8413, done at 2024-02-02 20:36:08, 0:00:10\n",
      "2024-02-02 20:35:59,346 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E82 Validation  1024/8413, done at 2024-02-02 20:36:10, 0:00:12\n",
      "2024-02-02 20:36:03,655 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E82 Validation  4096/8413, done at 2024-02-02 20:36:09, 0:00:11\n",
      "2024-02-02 20:36:08,855 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E82 Validation  8413/8413, done at 2024-02-02 20:36:08\n",
      "2024-02-02 20:36:08,857 INFO     pid:38964 __main__:011:logMetrics E82 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:36:08,860 INFO     pid:38964 __main__:072:logMetrics E82 val      0.6878 loss\n",
      "2024-02-02 20:36:08,861 INFO     pid:38964 __main__:097:logMetrics E82 val        55.5% correct, 0.5388 precision, 0.7659 recall, 0.6326 f1 score\n",
      "2024-02-02 20:36:08,861 INFO     pid:38964 __main__:112:logMetrics E82 val_neg   0.7944 loss,  34.4% correct (46366 of 134598)\n",
      "2024-02-02 20:36:08,861 INFO     pid:38964 __main__:128:logMetrics E82 val_pos   0.5813 loss,  76.6% correct (103086 of 134598)\n",
      "2024-02-02 20:36:08,870 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E83 Training ----/35181, starting\n",
      "2024-02-02 20:36:09,037 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E83 Training   32/35181, done at 2024-02-02 20:36:54, 0:00:45\n",
      "2024-02-02 20:36:09,313 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E83 Training  256/35181, done at 2024-02-02 20:36:52, 0:00:43\n",
      "2024-02-02 20:36:11,740 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E83 Training 2048/35181, done at 2024-02-02 20:36:56, 0:00:47\n",
      "2024-02-02 20:36:31,342 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E83 Training 16384/35181, done at 2024-02-02 20:36:56, 0:00:47\n",
      "2024-02-02 20:36:54,357 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E83 Training 35181/35181, done at 2024-02-02 20:36:54\n",
      "2024-02-02 20:36:54,790 INFO     pid:38964 __main__:011:logMetrics E83 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:36:54,824 INFO     pid:38964 __main__:072:logMetrics E83 trn      0.6764 loss\n",
      "2024-02-02 20:36:54,825 INFO     pid:38964 __main__:097:logMetrics E83 trn        57.7% correct, 0.5756 precision, 0.5873 recall, 0.5814 f1 score\n",
      "2024-02-02 20:36:54,825 INFO     pid:38964 __main__:112:logMetrics E83 trn_neg   0.6760 loss,  56.7% correct (319171 of 562892)\n",
      "2024-02-02 20:36:54,825 INFO     pid:38964 __main__:128:logMetrics E83 trn_pos   0.6768 loss,  58.7% correct (330610 of 562892)\n",
      "2024-02-02 20:36:54,859 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E83 Validation  ----/8413, starting\n",
      "2024-02-02 20:36:54,995 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E83 Validation    16/8413, done at 2024-02-02 20:37:03, 0:00:08\n",
      "2024-02-02 20:36:55,050 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E83 Validation    64/8413, done at 2024-02-02 20:37:04, 0:00:09\n",
      "2024-02-02 20:36:55,264 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E83 Validation   256/8413, done at 2024-02-02 20:37:04, 0:00:09\n",
      "2024-02-02 20:36:56,288 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E83 Validation  1024/8413, done at 2024-02-02 20:37:05, 0:00:10\n",
      "2024-02-02 20:37:00,268 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E83 Validation  4096/8413, done at 2024-02-02 20:37:05, 0:00:10\n",
      "2024-02-02 20:37:05,523 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E83 Validation  8413/8413, done at 2024-02-02 20:37:05\n",
      "2024-02-02 20:37:05,524 INFO     pid:38964 __main__:011:logMetrics E83 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:37:05,528 INFO     pid:38964 __main__:072:logMetrics E83 val      0.6857 loss\n",
      "2024-02-02 20:37:05,528 INFO     pid:38964 __main__:097:logMetrics E83 val        54.9% correct, 0.5312 precision, 0.8362 recall, 0.6497 f1 score\n",
      "2024-02-02 20:37:05,529 INFO     pid:38964 __main__:112:logMetrics E83 val_neg   0.7828 loss,  26.2% correct (35283 of 134598)\n",
      "2024-02-02 20:37:05,529 INFO     pid:38964 __main__:128:logMetrics E83 val_pos   0.5885 loss,  83.6% correct (112552 of 134598)\n",
      "2024-02-02 20:37:05,540 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E84 Training ----/35181, starting\n",
      "2024-02-02 20:37:05,734 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E84 Training   32/35181, done at 2024-02-02 20:38:17, 0:01:11\n",
      "2024-02-02 20:37:05,986 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E84 Training  256/35181, done at 2024-02-02 20:37:49, 0:00:43\n",
      "2024-02-02 20:37:08,428 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E84 Training 2048/35181, done at 2024-02-02 20:37:53, 0:00:47\n",
      "2024-02-02 20:37:26,677 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E84 Training 16384/35181, done at 2024-02-02 20:37:50, 0:00:45\n",
      "2024-02-02 20:37:50,612 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E84 Training 35181/35181, done at 2024-02-02 20:37:50\n",
      "2024-02-02 20:37:51,023 INFO     pid:38964 __main__:011:logMetrics E84 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:37:51,058 INFO     pid:38964 __main__:072:logMetrics E84 trn      0.6757 loss\n",
      "2024-02-02 20:37:51,059 INFO     pid:38964 __main__:097:logMetrics E84 trn        57.7% correct, 0.5709 precision, 0.6232 recall, 0.5959 f1 score\n",
      "2024-02-02 20:37:51,059 INFO     pid:38964 __main__:112:logMetrics E84 trn_neg   0.6754 loss,  53.2% correct (299244 of 562892)\n",
      "2024-02-02 20:37:51,059 INFO     pid:38964 __main__:128:logMetrics E84 trn_pos   0.6759 loss,  62.3% correct (350773 of 562892)\n",
      "2024-02-02 20:37:51,092 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E84 Validation  ----/8413, starting\n",
      "2024-02-02 20:37:51,204 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E84 Validation    16/8413, done at 2024-02-02 20:38:01, 0:00:10\n",
      "2024-02-02 20:37:51,282 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E84 Validation    64/8413, done at 2024-02-02 20:38:04, 0:00:13\n",
      "2024-02-02 20:37:51,488 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E84 Validation   256/8413, done at 2024-02-02 20:38:01, 0:00:09\n",
      "2024-02-02 20:37:52,491 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E84 Validation  1024/8413, done at 2024-02-02 20:38:01, 0:00:10\n",
      "2024-02-02 20:37:56,164 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E84 Validation  4096/8413, done at 2024-02-02 20:38:01, 0:00:10\n",
      "2024-02-02 20:38:01,210 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E84 Validation  8413/8413, done at 2024-02-02 20:38:01\n",
      "2024-02-02 20:38:01,211 INFO     pid:38964 __main__:011:logMetrics E84 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:38:01,216 INFO     pid:38964 __main__:072:logMetrics E84 val      0.6838 loss\n",
      "2024-02-02 20:38:01,217 INFO     pid:38964 __main__:097:logMetrics E84 val        55.6% correct, 0.5381 precision, 0.7955 recall, 0.6419 f1 score\n",
      "2024-02-02 20:38:01,217 INFO     pid:38964 __main__:112:logMetrics E84 val_neg   0.7214 loss,  31.7% correct (42684 of 134598)\n",
      "2024-02-02 20:38:01,217 INFO     pid:38964 __main__:128:logMetrics E84 val_pos   0.6462 loss,  79.5% correct (107071 of 134598)\n",
      "2024-02-02 20:38:01,227 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E85 Training ----/35181, starting\n",
      "2024-02-02 20:38:01,433 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E85 Training   32/35181, done at 2024-02-02 20:39:29, 0:01:28\n",
      "2024-02-02 20:38:01,688 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E85 Training  256/35181, done at 2024-02-02 20:38:47, 0:00:45\n",
      "2024-02-02 20:38:04,279 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E85 Training 2048/35181, done at 2024-02-02 20:38:51, 0:00:50\n",
      "2024-02-02 20:38:22,461 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E85 Training 16384/35181, done at 2024-02-02 20:38:46, 0:00:45\n",
      "2024-02-02 20:38:45,862 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E85 Training 35181/35181, done at 2024-02-02 20:38:45\n",
      "2024-02-02 20:38:46,292 INFO     pid:38964 __main__:011:logMetrics E85 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:38:46,325 INFO     pid:38964 __main__:072:logMetrics E85 trn      0.6751 loss\n",
      "2024-02-02 20:38:46,325 INFO     pid:38964 __main__:097:logMetrics E85 trn        57.8% correct, 0.5732 precision, 0.6122 recall, 0.5921 f1 score\n",
      "2024-02-02 20:38:46,326 INFO     pid:38964 __main__:112:logMetrics E85 trn_neg   0.6747 loss,  54.4% correct (306290 of 562892)\n",
      "2024-02-02 20:38:46,326 INFO     pid:38964 __main__:128:logMetrics E85 trn_pos   0.6754 loss,  61.2% correct (344621 of 562892)\n",
      "2024-02-02 20:38:46,358 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E85 Validation  ----/8413, starting\n",
      "2024-02-02 20:38:46,470 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E85 Validation    16/8413, done at 2024-02-02 20:38:56, 0:00:09\n",
      "2024-02-02 20:38:46,524 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E85 Validation    64/8413, done at 2024-02-02 20:38:55, 0:00:09\n",
      "2024-02-02 20:38:46,949 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E85 Validation   256/8413, done at 2024-02-02 20:39:02, 0:00:16\n",
      "2024-02-02 20:38:47,766 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E85 Validation  1024/8413, done at 2024-02-02 20:38:57, 0:00:10\n",
      "2024-02-02 20:38:51,318 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E85 Validation  4096/8413, done at 2024-02-02 20:38:56, 0:00:09\n",
      "2024-02-02 20:38:56,336 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E85 Validation  8413/8413, done at 2024-02-02 20:38:56\n",
      "2024-02-02 20:38:56,338 INFO     pid:38964 __main__:011:logMetrics E85 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:38:56,344 INFO     pid:38964 __main__:072:logMetrics E85 val      0.6893 loss\n",
      "2024-02-02 20:38:56,345 INFO     pid:38964 __main__:097:logMetrics E85 val        55.0% correct, 0.5317 precision, 0.8411 recall, 0.6515 f1 score\n",
      "2024-02-02 20:38:56,345 INFO     pid:38964 __main__:112:logMetrics E85 val_neg   0.8142 loss,  25.9% correct (34870 of 134598)\n",
      "2024-02-02 20:38:56,346 INFO     pid:38964 __main__:128:logMetrics E85 val_pos   0.5644 loss,  84.1% correct (113216 of 134598)\n",
      "2024-02-02 20:38:56,360 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E86 Training ----/35181, starting\n",
      "2024-02-02 20:38:56,529 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E86 Training   32/35181, done at 2024-02-02 20:39:37, 0:00:40\n",
      "2024-02-02 20:38:57,036 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E86 Training  256/35181, done at 2024-02-02 20:40:11, 0:01:14\n",
      "2024-02-02 20:38:59,213 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E86 Training 2048/35181, done at 2024-02-02 20:39:43, 0:00:46\n",
      "2024-02-02 20:39:16,658 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E86 Training 16384/35181, done at 2024-02-02 20:39:39, 0:00:43\n",
      "2024-02-02 20:39:39,302 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E86 Training 35181/35181, done at 2024-02-02 20:39:39\n",
      "2024-02-02 20:39:39,689 INFO     pid:38964 __main__:011:logMetrics E86 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:39:39,726 INFO     pid:38964 __main__:072:logMetrics E86 trn      0.6749 loss\n",
      "2024-02-02 20:39:39,727 INFO     pid:38964 __main__:097:logMetrics E86 trn        57.8% correct, 0.5784 precision, 0.5776 recall, 0.5780 f1 score\n",
      "2024-02-02 20:39:39,727 INFO     pid:38964 __main__:112:logMetrics E86 trn_neg   0.6744 loss,  57.9% correct (325851 of 562892)\n",
      "2024-02-02 20:39:39,727 INFO     pid:38964 __main__:128:logMetrics E86 trn_pos   0.6754 loss,  57.8% correct (325141 of 562892)\n",
      "2024-02-02 20:39:39,760 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E86 Validation  ----/8413, starting\n",
      "2024-02-02 20:39:39,871 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E86 Validation    16/8413, done at 2024-02-02 20:39:48, 0:00:09\n",
      "2024-02-02 20:39:39,924 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E86 Validation    64/8413, done at 2024-02-02 20:39:49, 0:00:09\n",
      "2024-02-02 20:39:40,175 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E86 Validation   256/8413, done at 2024-02-02 20:39:50, 0:00:10\n",
      "2024-02-02 20:39:40,980 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E86 Validation  1024/8413, done at 2024-02-02 20:39:49, 0:00:09\n",
      "2024-02-02 20:39:44,946 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E86 Validation  4096/8413, done at 2024-02-02 20:39:50, 0:00:10\n",
      "2024-02-02 20:39:50,302 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E86 Validation  8413/8413, done at 2024-02-02 20:39:50\n",
      "2024-02-02 20:39:50,304 INFO     pid:38964 __main__:011:logMetrics E86 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:39:50,308 INFO     pid:38964 __main__:072:logMetrics E86 val      0.6824 loss\n",
      "2024-02-02 20:39:50,309 INFO     pid:38964 __main__:097:logMetrics E86 val        57.2% correct, 0.5594 precision, 0.6770 recall, 0.6126 f1 score\n",
      "2024-02-02 20:39:50,309 INFO     pid:38964 __main__:112:logMetrics E86 val_neg   0.7283 loss,  46.7% correct (62839 of 134598)\n",
      "2024-02-02 20:39:50,309 INFO     pid:38964 __main__:128:logMetrics E86 val_pos   0.6366 loss,  67.7% correct (91117 of 134598)\n",
      "2024-02-02 20:39:50,320 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E87 Training ----/35181, starting\n",
      "2024-02-02 20:39:50,489 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E87 Training   32/35181, done at 2024-02-02 20:40:35, 0:00:44\n",
      "2024-02-02 20:39:50,791 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E87 Training  256/35181, done at 2024-02-02 20:40:37, 0:00:47\n",
      "2024-02-02 20:39:53,009 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E87 Training 2048/35181, done at 2024-02-02 20:40:34, 0:00:43\n",
      "2024-02-02 20:40:11,295 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E87 Training 16384/35181, done at 2024-02-02 20:40:35, 0:00:44\n",
      "2024-02-02 20:40:35,379 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E87 Training 35181/35181, done at 2024-02-02 20:40:35\n",
      "2024-02-02 20:40:35,790 INFO     pid:38964 __main__:011:logMetrics E87 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:40:35,825 INFO     pid:38964 __main__:072:logMetrics E87 trn      0.6746 loss\n",
      "2024-02-02 20:40:35,826 INFO     pid:38964 __main__:097:logMetrics E87 trn        58.0% correct, 0.5796 precision, 0.5803 recall, 0.5800 f1 score\n",
      "2024-02-02 20:40:35,826 INFO     pid:38964 __main__:112:logMetrics E87 trn_neg   0.6741 loss,  57.9% correct (325990 of 562892)\n",
      "2024-02-02 20:40:35,826 INFO     pid:38964 __main__:128:logMetrics E87 trn_pos   0.6750 loss,  58.0% correct (326650 of 562892)\n",
      "2024-02-02 20:40:35,860 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E87 Validation  ----/8413, starting\n",
      "2024-02-02 20:40:35,977 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E87 Validation    16/8413, done at 2024-02-02 20:40:47, 0:00:11\n",
      "2024-02-02 20:40:36,043 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E87 Validation    64/8413, done at 2024-02-02 20:40:47, 0:00:11\n",
      "2024-02-02 20:40:36,253 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E87 Validation   256/8413, done at 2024-02-02 20:40:45, 0:00:09\n",
      "2024-02-02 20:40:37,272 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E87 Validation  1024/8413, done at 2024-02-02 20:40:46, 0:00:10\n",
      "2024-02-02 20:40:41,140 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E87 Validation  4096/8413, done at 2024-02-02 20:40:46, 0:00:10\n",
      "2024-02-02 20:40:46,276 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E87 Validation  8413/8413, done at 2024-02-02 20:40:46\n",
      "2024-02-02 20:40:46,279 INFO     pid:38964 __main__:011:logMetrics E87 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:40:46,282 INFO     pid:38964 __main__:072:logMetrics E87 val      0.6797 loss\n",
      "2024-02-02 20:40:46,282 INFO     pid:38964 __main__:097:logMetrics E87 val        57.4% correct, 0.5744 precision, 0.5737 recall, 0.5740 f1 score\n",
      "2024-02-02 20:40:46,283 INFO     pid:38964 __main__:112:logMetrics E87 val_neg   0.6678 loss,  57.5% correct (77377 of 134598)\n",
      "2024-02-02 20:40:46,283 INFO     pid:38964 __main__:128:logMetrics E87 val_pos   0.6916 loss,  57.4% correct (77221 of 134598)\n",
      "2024-02-02 20:40:46,293 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E88 Training ----/35181, starting\n",
      "2024-02-02 20:40:46,462 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E88 Training   32/35181, done at 2024-02-02 20:41:33, 0:00:46\n",
      "2024-02-02 20:40:46,782 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E88 Training  256/35181, done at 2024-02-02 20:41:36, 0:00:49\n",
      "2024-02-02 20:40:49,296 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E88 Training 2048/35181, done at 2024-02-02 20:41:35, 0:00:49\n",
      "2024-02-02 20:41:06,901 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E88 Training 16384/35181, done at 2024-02-02 20:41:30, 0:00:43\n",
      "2024-02-02 20:41:30,199 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E88 Training 35181/35181, done at 2024-02-02 20:41:30\n",
      "2024-02-02 20:41:30,598 INFO     pid:38964 __main__:011:logMetrics E88 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:41:30,633 INFO     pid:38964 __main__:072:logMetrics E88 trn      0.6743 loss\n",
      "2024-02-02 20:41:30,633 INFO     pid:38964 __main__:097:logMetrics E88 trn        57.9% correct, 0.5723 precision, 0.6258 recall, 0.5978 f1 score\n",
      "2024-02-02 20:41:30,633 INFO     pid:38964 __main__:112:logMetrics E88 trn_neg   0.6740 loss,  53.2% correct (299670 of 562892)\n",
      "2024-02-02 20:41:30,634 INFO     pid:38964 __main__:128:logMetrics E88 trn_pos   0.6746 loss,  62.6% correct (352230 of 562892)\n",
      "2024-02-02 20:41:30,668 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E88 Validation  ----/8413, starting\n",
      "2024-02-02 20:41:30,781 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E88 Validation    16/8413, done at 2024-02-02 20:41:41, 0:00:10\n",
      "2024-02-02 20:41:30,880 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E88 Validation    64/8413, done at 2024-02-02 20:41:46, 0:00:15\n",
      "2024-02-02 20:41:31,077 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E88 Validation   256/8413, done at 2024-02-02 20:41:41, 0:00:10\n",
      "2024-02-02 20:41:32,074 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E88 Validation  1024/8413, done at 2024-02-02 20:41:41, 0:00:10\n",
      "2024-02-02 20:41:35,873 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E88 Validation  4096/8413, done at 2024-02-02 20:41:41, 0:00:10\n",
      "2024-02-02 20:41:41,014 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E88 Validation  8413/8413, done at 2024-02-02 20:41:41\n",
      "2024-02-02 20:41:41,016 INFO     pid:38964 __main__:011:logMetrics E88 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:41:41,020 INFO     pid:38964 __main__:072:logMetrics E88 val      0.6809 loss\n",
      "2024-02-02 20:41:41,021 INFO     pid:38964 __main__:097:logMetrics E88 val        55.2% correct, 0.5336 precision, 0.8303 recall, 0.6497 f1 score\n",
      "2024-02-02 20:41:41,021 INFO     pid:38964 __main__:112:logMetrics E88 val_neg   0.7114 loss,  27.4% correct (36904 of 134598)\n",
      "2024-02-02 20:41:41,021 INFO     pid:38964 __main__:128:logMetrics E88 val_pos   0.6503 loss,  83.0% correct (111756 of 134598)\n",
      "2024-02-02 20:41:41,030 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E89 Training ----/35181, starting\n",
      "2024-02-02 20:41:41,203 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E89 Training   32/35181, done at 2024-02-02 20:42:28, 0:00:47\n",
      "2024-02-02 20:41:41,510 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E89 Training  256/35181, done at 2024-02-02 20:42:29, 0:00:48\n",
      "2024-02-02 20:41:44,101 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E89 Training 2048/35181, done at 2024-02-02 20:42:31, 0:00:50\n",
      "2024-02-02 20:42:02,154 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E89 Training 16384/35181, done at 2024-02-02 20:42:26, 0:00:45\n",
      "2024-02-02 20:42:26,088 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E89 Training 35181/35181, done at 2024-02-02 20:42:26\n",
      "2024-02-02 20:42:26,512 INFO     pid:38964 __main__:011:logMetrics E89 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:42:26,547 INFO     pid:38964 __main__:072:logMetrics E89 trn      0.6748 loss\n",
      "2024-02-02 20:42:26,548 INFO     pid:38964 __main__:097:logMetrics E89 trn        58.0% correct, 0.5723 precision, 0.6296 recall, 0.5996 f1 score\n",
      "2024-02-02 20:42:26,548 INFO     pid:38964 __main__:112:logMetrics E89 trn_neg   0.6746 loss,  53.0% correct (298097 of 562892)\n",
      "2024-02-02 20:42:26,548 INFO     pid:38964 __main__:128:logMetrics E89 trn_pos   0.6751 loss,  63.0% correct (354370 of 562892)\n",
      "2024-02-02 20:42:26,581 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E89 Validation  ----/8413, starting\n",
      "2024-02-02 20:42:26,692 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E89 Validation    16/8413, done at 2024-02-02 20:42:37, 0:00:10\n",
      "2024-02-02 20:42:26,745 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E89 Validation    64/8413, done at 2024-02-02 20:42:36, 0:00:09\n",
      "2024-02-02 20:42:26,993 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E89 Validation   256/8413, done at 2024-02-02 20:42:37, 0:00:10\n",
      "2024-02-02 20:42:28,040 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E89 Validation  1024/8413, done at 2024-02-02 20:42:37, 0:00:11\n",
      "2024-02-02 20:42:31,680 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E89 Validation  4096/8413, done at 2024-02-02 20:42:36, 0:00:10\n",
      "2024-02-02 20:42:36,959 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E89 Validation  8413/8413, done at 2024-02-02 20:42:36\n",
      "2024-02-02 20:42:36,961 INFO     pid:38964 __main__:011:logMetrics E89 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:42:36,966 INFO     pid:38964 __main__:072:logMetrics E89 val      0.6818 loss\n",
      "2024-02-02 20:42:36,966 INFO     pid:38964 __main__:097:logMetrics E89 val        57.5% correct, 0.5605 precision, 0.6935 recall, 0.6199 f1 score\n",
      "2024-02-02 20:42:36,966 INFO     pid:38964 __main__:112:logMetrics E89 val_neg   0.7535 loss,  45.6% correct (61401 of 134598)\n",
      "2024-02-02 20:42:36,967 INFO     pid:38964 __main__:128:logMetrics E89 val_pos   0.6102 loss,  69.4% correct (93346 of 134598)\n",
      "2024-02-02 20:42:36,976 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E90 Training ----/35181, starting\n",
      "2024-02-02 20:42:37,185 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E90 Training   32/35181, done at 2024-02-02 20:44:06, 0:01:29\n",
      "2024-02-02 20:42:37,445 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E90 Training  256/35181, done at 2024-02-02 20:43:23, 0:00:46\n",
      "2024-02-02 20:42:39,988 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E90 Training 2048/35181, done at 2024-02-02 20:43:26, 0:00:49\n",
      "2024-02-02 20:42:58,138 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E90 Training 16384/35181, done at 2024-02-02 20:43:22, 0:00:45\n",
      "2024-02-02 20:43:21,794 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E90 Training 35181/35181, done at 2024-02-02 20:43:21\n",
      "2024-02-02 20:43:22,231 INFO     pid:38964 __main__:011:logMetrics E90 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:43:22,264 INFO     pid:38964 __main__:072:logMetrics E90 trn      0.6762 loss\n",
      "2024-02-02 20:43:22,265 INFO     pid:38964 __main__:097:logMetrics E90 trn        57.8% correct, 0.5743 precision, 0.6012 recall, 0.5875 f1 score\n",
      "2024-02-02 20:43:22,265 INFO     pid:38964 __main__:112:logMetrics E90 trn_neg   0.6759 loss,  55.4% correct (312087 of 562892)\n",
      "2024-02-02 20:43:22,265 INFO     pid:38964 __main__:128:logMetrics E90 trn_pos   0.6766 loss,  60.1% correct (338405 of 562892)\n",
      "2024-02-02 20:43:22,301 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E90 Validation  ----/8413, starting\n",
      "2024-02-02 20:43:22,426 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E90 Validation    16/8413, done at 2024-02-02 20:43:34, 0:00:12\n",
      "2024-02-02 20:43:22,513 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E90 Validation    64/8413, done at 2024-02-02 20:43:37, 0:00:14\n",
      "2024-02-02 20:43:22,917 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E90 Validation   256/8413, done at 2024-02-02 20:43:39, 0:00:16\n",
      "2024-02-02 20:43:23,709 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E90 Validation  1024/8413, done at 2024-02-02 20:43:33, 0:00:10\n",
      "2024-02-02 20:43:27,306 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E90 Validation  4096/8413, done at 2024-02-02 20:43:32, 0:00:10\n",
      "2024-02-02 20:43:32,357 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E90 Validation  8413/8413, done at 2024-02-02 20:43:32\n",
      "2024-02-02 20:43:32,359 INFO     pid:38964 __main__:011:logMetrics E90 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:43:32,362 INFO     pid:38964 __main__:072:logMetrics E90 val      0.6828 loss\n",
      "2024-02-02 20:43:32,363 INFO     pid:38964 __main__:097:logMetrics E90 val        55.5% correct, 0.5360 precision, 0.8197 recall, 0.6482 f1 score\n",
      "2024-02-02 20:43:32,363 INFO     pid:38964 __main__:112:logMetrics E90 val_neg   0.7713 loss,  29.0% correct (39094 of 134598)\n",
      "2024-02-02 20:43:32,363 INFO     pid:38964 __main__:128:logMetrics E90 val_pos   0.5943 loss,  82.0% correct (110336 of 134598)\n",
      "2024-02-02 20:43:32,373 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E91 Training ----/35181, starting\n",
      "2024-02-02 20:43:32,564 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E91 Training   32/35181, done at 2024-02-02 20:44:30, 0:00:58\n",
      "2024-02-02 20:43:33,033 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E91 Training  256/35181, done at 2024-02-02 20:44:44, 0:01:11\n",
      "2024-02-02 20:43:35,293 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E91 Training 2048/35181, done at 2024-02-02 20:44:20, 0:00:47\n",
      "2024-02-02 20:43:54,055 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E91 Training 16384/35181, done at 2024-02-02 20:44:18, 0:00:46\n",
      "2024-02-02 20:44:18,355 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E91 Training 35181/35181, done at 2024-02-02 20:44:18\n",
      "2024-02-02 20:44:18,790 INFO     pid:38964 __main__:011:logMetrics E91 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:44:18,826 INFO     pid:38964 __main__:072:logMetrics E91 trn      0.6755 loss\n",
      "2024-02-02 20:44:18,827 INFO     pid:38964 __main__:097:logMetrics E91 trn        57.5% correct, 0.5737 precision, 0.5876 recall, 0.5805 f1 score\n",
      "2024-02-02 20:44:18,827 INFO     pid:38964 __main__:112:logMetrics E91 trn_neg   0.6752 loss,  56.3% correct (317126 of 562892)\n",
      "2024-02-02 20:44:18,827 INFO     pid:38964 __main__:128:logMetrics E91 trn_pos   0.6757 loss,  58.8% correct (330731 of 562892)\n",
      "2024-02-02 20:44:18,861 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E91 Validation  ----/8413, starting\n",
      "2024-02-02 20:44:19,185 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E91 Validation    16/8413, done at 2024-02-02 20:44:29, 0:00:09\n",
      "2024-02-02 20:44:19,242 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E91 Validation    64/8413, done at 2024-02-02 20:44:29, 0:00:09\n",
      "2024-02-02 20:44:19,452 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E91 Validation   256/8413, done at 2024-02-02 20:44:28, 0:00:09\n",
      "2024-02-02 20:44:20,251 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E91 Validation  1024/8413, done at 2024-02-02 20:44:28, 0:00:08\n",
      "2024-02-02 20:44:23,821 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E91 Validation  4096/8413, done at 2024-02-02 20:44:28, 0:00:09\n",
      "2024-02-02 20:44:29,183 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E91 Validation  8413/8413, done at 2024-02-02 20:44:29\n",
      "2024-02-02 20:44:29,184 INFO     pid:38964 __main__:011:logMetrics E91 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:44:29,189 INFO     pid:38964 __main__:072:logMetrics E91 val      0.6799 loss\n",
      "2024-02-02 20:44:29,190 INFO     pid:38964 __main__:097:logMetrics E91 val        56.5% correct, 0.5518 precision, 0.6968 recall, 0.6159 f1 score\n",
      "2024-02-02 20:44:29,190 INFO     pid:38964 __main__:112:logMetrics E91 val_neg   0.7216 loss,  43.4% correct (58423 of 134598)\n",
      "2024-02-02 20:44:29,190 INFO     pid:38964 __main__:128:logMetrics E91 val_pos   0.6383 loss,  69.7% correct (93785 of 134598)\n",
      "2024-02-02 20:44:29,203 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E92 Training ----/35181, starting\n",
      "2024-02-02 20:44:29,575 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E92 Training   32/35181, done at 2024-02-02 20:45:16, 0:00:46\n",
      "2024-02-02 20:44:29,867 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E92 Training  256/35181, done at 2024-02-02 20:45:15, 0:00:46\n",
      "2024-02-02 20:44:32,271 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E92 Training 2048/35181, done at 2024-02-02 20:45:16, 0:00:47\n",
      "2024-02-02 20:44:49,877 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E92 Training 16384/35181, done at 2024-02-02 20:45:13, 0:00:43\n",
      "2024-02-02 20:45:13,112 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E92 Training 35181/35181, done at 2024-02-02 20:45:13\n",
      "2024-02-02 20:45:13,527 INFO     pid:38964 __main__:011:logMetrics E92 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:45:13,561 INFO     pid:38964 __main__:072:logMetrics E92 trn      0.6756 loss\n",
      "2024-02-02 20:45:13,562 INFO     pid:38964 __main__:097:logMetrics E92 trn        57.7% correct, 0.5729 precision, 0.6036 recall, 0.5879 f1 score\n",
      "2024-02-02 20:45:13,562 INFO     pid:38964 __main__:112:logMetrics E92 trn_neg   0.6753 loss,  55.0% correct (309605 of 562892)\n",
      "2024-02-02 20:45:13,562 INFO     pid:38964 __main__:128:logMetrics E92 trn_pos   0.6759 loss,  60.4% correct (339784 of 562892)\n",
      "2024-02-02 20:45:13,596 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E92 Validation  ----/8413, starting\n",
      "2024-02-02 20:45:13,709 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E92 Validation    16/8413, done at 2024-02-02 20:45:23, 0:00:10\n",
      "2024-02-02 20:45:13,765 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E92 Validation    64/8413, done at 2024-02-02 20:45:23, 0:00:09\n",
      "2024-02-02 20:45:14,015 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E92 Validation   256/8413, done at 2024-02-02 20:45:24, 0:00:10\n",
      "2024-02-02 20:45:15,035 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E92 Validation  1024/8413, done at 2024-02-02 20:45:24, 0:00:11\n",
      "2024-02-02 20:45:18,455 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E92 Validation  4096/8413, done at 2024-02-02 20:45:23, 0:00:09\n",
      "2024-02-02 20:45:23,472 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E92 Validation  8413/8413, done at 2024-02-02 20:45:23\n",
      "2024-02-02 20:45:23,474 INFO     pid:38964 __main__:011:logMetrics E92 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:45:23,478 INFO     pid:38964 __main__:072:logMetrics E92 val      0.6818 loss\n",
      "2024-02-02 20:45:23,479 INFO     pid:38964 __main__:097:logMetrics E92 val        56.9% correct, 0.5582 precision, 0.6648 recall, 0.6068 f1 score\n",
      "2024-02-02 20:45:23,479 INFO     pid:38964 __main__:112:logMetrics E92 val_neg   0.7174 loss,  47.4% correct (63758 of 134598)\n",
      "2024-02-02 20:45:23,480 INFO     pid:38964 __main__:128:logMetrics E92 val_pos   0.6463 loss,  66.5% correct (89486 of 134598)\n",
      "2024-02-02 20:45:23,490 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E93 Training ----/35181, starting\n",
      "2024-02-02 20:45:23,663 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E93 Training   32/35181, done at 2024-02-02 20:46:06, 0:00:43\n",
      "2024-02-02 20:45:23,966 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E93 Training  256/35181, done at 2024-02-02 20:46:10, 0:00:47\n",
      "2024-02-02 20:45:26,422 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E93 Training 2048/35181, done at 2024-02-02 20:46:11, 0:00:48\n",
      "2024-02-02 20:45:45,039 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E93 Training 16384/35181, done at 2024-02-02 20:46:09, 0:00:45\n",
      "2024-02-02 20:46:08,730 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E93 Training 35181/35181, done at 2024-02-02 20:46:08\n",
      "2024-02-02 20:46:09,164 INFO     pid:38964 __main__:011:logMetrics E93 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:46:09,198 INFO     pid:38964 __main__:072:logMetrics E93 trn      0.6753 loss\n",
      "2024-02-02 20:46:09,199 INFO     pid:38964 __main__:097:logMetrics E93 trn        57.7% correct, 0.5736 precision, 0.6018 recall, 0.5874 f1 score\n",
      "2024-02-02 20:46:09,199 INFO     pid:38964 __main__:112:logMetrics E93 trn_neg   0.6751 loss,  55.3% correct (311120 of 562892)\n",
      "2024-02-02 20:46:09,199 INFO     pid:38964 __main__:128:logMetrics E93 trn_pos   0.6754 loss,  60.2% correct (338729 of 562892)\n",
      "2024-02-02 20:46:09,234 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E93 Validation  ----/8413, starting\n",
      "2024-02-02 20:46:09,346 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E93 Validation    16/8413, done at 2024-02-02 20:46:20, 0:00:11\n",
      "2024-02-02 20:46:09,419 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E93 Validation    64/8413, done at 2024-02-02 20:46:21, 0:00:12\n",
      "2024-02-02 20:46:09,637 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E93 Validation   256/8413, done at 2024-02-02 20:46:19, 0:00:10\n",
      "2024-02-02 20:46:10,642 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E93 Validation  1024/8413, done at 2024-02-02 20:46:20, 0:00:10\n",
      "2024-02-02 20:46:14,296 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E93 Validation  4096/8413, done at 2024-02-02 20:46:19, 0:00:10\n",
      "2024-02-02 20:46:19,587 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E93 Validation  8413/8413, done at 2024-02-02 20:46:19\n",
      "2024-02-02 20:46:19,589 INFO     pid:38964 __main__:011:logMetrics E93 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:46:19,594 INFO     pid:38964 __main__:072:logMetrics E93 val      0.6810 loss\n",
      "2024-02-02 20:46:19,595 INFO     pid:38964 __main__:097:logMetrics E93 val        56.2% correct, 0.5934 precision, 0.3946 recall, 0.4740 f1 score\n",
      "2024-02-02 20:46:19,595 INFO     pid:38964 __main__:112:logMetrics E93 val_neg   0.6620 loss,  73.0% correct (98205 of 134598)\n",
      "2024-02-02 20:46:19,595 INFO     pid:38964 __main__:128:logMetrics E93 val_pos   0.7001 loss,  39.5% correct (53108 of 134598)\n",
      "2024-02-02 20:46:19,605 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E94 Training ----/35181, starting\n",
      "2024-02-02 20:46:19,774 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E94 Training   32/35181, done at 2024-02-02 20:47:05, 0:00:45\n",
      "2024-02-02 20:46:20,090 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E94 Training  256/35181, done at 2024-02-02 20:47:08, 0:00:49\n",
      "2024-02-02 20:46:22,930 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E94 Training 2048/35181, done at 2024-02-02 20:47:14, 0:00:54\n",
      "2024-02-02 20:46:40,622 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E94 Training 16384/35181, done at 2024-02-02 20:47:04, 0:00:44\n",
      "2024-02-02 20:47:03,920 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E94 Training 35181/35181, done at 2024-02-02 20:47:03\n",
      "2024-02-02 20:47:04,348 INFO     pid:38964 __main__:011:logMetrics E94 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:47:04,382 INFO     pid:38964 __main__:072:logMetrics E94 trn      0.6755 loss\n",
      "2024-02-02 20:47:04,383 INFO     pid:38964 __main__:097:logMetrics E94 trn        57.7% correct, 0.5748 precision, 0.5911 recall, 0.5829 f1 score\n",
      "2024-02-02 20:47:04,383 INFO     pid:38964 __main__:112:logMetrics E94 trn_neg   0.6752 loss,  56.3% correct (316783 of 562892)\n",
      "2024-02-02 20:47:04,383 INFO     pid:38964 __main__:128:logMetrics E94 trn_pos   0.6758 loss,  59.1% correct (332732 of 562892)\n",
      "2024-02-02 20:47:04,418 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E94 Validation  ----/8413, starting\n",
      "2024-02-02 20:47:04,530 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E94 Validation    16/8413, done at 2024-02-02 20:47:14, 0:00:09\n",
      "2024-02-02 20:47:04,615 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E94 Validation    64/8413, done at 2024-02-02 20:47:18, 0:00:13\n",
      "2024-02-02 20:47:04,819 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E94 Validation   256/8413, done at 2024-02-02 20:47:14, 0:00:10\n",
      "2024-02-02 20:47:06,098 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E94 Validation  1024/8413, done at 2024-02-02 20:47:17, 0:00:13\n",
      "2024-02-02 20:47:09,826 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E94 Validation  4096/8413, done at 2024-02-02 20:47:15, 0:00:10\n",
      "2024-02-02 20:47:15,416 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E94 Validation  8413/8413, done at 2024-02-02 20:47:15\n",
      "2024-02-02 20:47:15,418 INFO     pid:38964 __main__:011:logMetrics E94 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:47:15,422 INFO     pid:38964 __main__:072:logMetrics E94 val      0.6863 loss\n",
      "2024-02-02 20:47:15,423 INFO     pid:38964 __main__:097:logMetrics E94 val        55.5% correct, 0.5365 precision, 0.8071 recall, 0.6445 f1 score\n",
      "2024-02-02 20:47:15,423 INFO     pid:38964 __main__:112:logMetrics E94 val_neg   0.7746 loss,  30.3% correct (40730 of 134598)\n",
      "2024-02-02 20:47:15,423 INFO     pid:38964 __main__:128:logMetrics E94 val_pos   0.5981 loss,  80.7% correct (108639 of 134598)\n",
      "2024-02-02 20:47:15,433 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E95 Training ----/35181, starting\n",
      "2024-02-02 20:47:15,641 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E95 Training   32/35181, done at 2024-02-02 20:48:00, 0:00:45\n",
      "2024-02-02 20:47:15,917 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E95 Training  256/35181, done at 2024-02-02 20:47:59, 0:00:43\n",
      "2024-02-02 20:47:18,384 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E95 Training 2048/35181, done at 2024-02-02 20:48:03, 0:00:47\n",
      "2024-02-02 20:47:37,111 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E95 Training 16384/35181, done at 2024-02-02 20:48:01, 0:00:46\n",
      "2024-02-02 20:48:00,842 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E95 Training 35181/35181, done at 2024-02-02 20:48:00\n",
      "2024-02-02 20:48:01,266 INFO     pid:38964 __main__:011:logMetrics E95 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:48:01,303 INFO     pid:38964 __main__:072:logMetrics E95 trn      0.6753 loss\n",
      "2024-02-02 20:48:01,304 INFO     pid:38964 __main__:097:logMetrics E95 trn        57.9% correct, 0.5762 precision, 0.5977 recall, 0.5867 f1 score\n",
      "2024-02-02 20:48:01,304 INFO     pid:38964 __main__:112:logMetrics E95 trn_neg   0.6751 loss,  56.0% correct (315414 of 562892)\n",
      "2024-02-02 20:48:01,304 INFO     pid:38964 __main__:128:logMetrics E95 trn_pos   0.6755 loss,  59.8% correct (336437 of 562892)\n",
      "2024-02-02 20:48:01,340 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E95 Validation  ----/8413, starting\n",
      "2024-02-02 20:48:01,454 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E95 Validation    16/8413, done at 2024-02-02 20:48:11, 0:00:10\n",
      "2024-02-02 20:48:01,546 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E95 Validation    64/8413, done at 2024-02-02 20:48:16, 0:00:14\n",
      "2024-02-02 20:48:01,967 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E95 Validation   256/8413, done at 2024-02-02 20:48:18, 0:00:17\n",
      "2024-02-02 20:48:02,783 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E95 Validation  1024/8413, done at 2024-02-02 20:48:12, 0:00:11\n",
      "2024-02-02 20:48:06,455 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E95 Validation  4096/8413, done at 2024-02-02 20:48:11, 0:00:10\n",
      "2024-02-02 20:48:11,791 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E95 Validation  8413/8413, done at 2024-02-02 20:48:11\n",
      "2024-02-02 20:48:11,793 INFO     pid:38964 __main__:011:logMetrics E95 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:48:11,796 INFO     pid:38964 __main__:072:logMetrics E95 val      0.6870 loss\n",
      "2024-02-02 20:48:11,797 INFO     pid:38964 __main__:097:logMetrics E95 val        55.9% correct, 0.5392 precision, 0.8063 recall, 0.6463 f1 score\n",
      "2024-02-02 20:48:11,797 INFO     pid:38964 __main__:112:logMetrics E95 val_neg   0.7990 loss,  31.1% correct (41871 of 134598)\n",
      "2024-02-02 20:48:11,797 INFO     pid:38964 __main__:128:logMetrics E95 val_pos   0.5751 loss,  80.6% correct (108525 of 134598)\n",
      "2024-02-02 20:48:11,806 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E96 Training ----/35181, starting\n",
      "2024-02-02 20:48:11,997 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E96 Training   32/35181, done at 2024-02-02 20:48:57, 0:00:45\n",
      "2024-02-02 20:48:12,464 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E96 Training  256/35181, done at 2024-02-02 20:49:22, 0:01:10\n",
      "2024-02-02 20:48:14,873 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E96 Training 2048/35181, done at 2024-02-02 20:49:02, 0:00:50\n",
      "2024-02-02 20:48:33,140 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E96 Training 16384/35181, done at 2024-02-02 20:48:57, 0:00:45\n",
      "2024-02-02 20:48:57,452 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E96 Training 35181/35181, done at 2024-02-02 20:48:57\n",
      "2024-02-02 20:48:57,893 INFO     pid:38964 __main__:011:logMetrics E96 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:48:57,931 INFO     pid:38964 __main__:072:logMetrics E96 trn      0.6756 loss\n",
      "2024-02-02 20:48:57,931 INFO     pid:38964 __main__:097:logMetrics E96 trn        57.9% correct, 0.5746 precision, 0.6050 recall, 0.5894 f1 score\n",
      "2024-02-02 20:48:57,932 INFO     pid:38964 __main__:112:logMetrics E96 trn_neg   0.6754 loss,  55.2% correct (310764 of 562892)\n",
      "2024-02-02 20:48:57,932 INFO     pid:38964 __main__:128:logMetrics E96 trn_pos   0.6758 loss,  60.5% correct (340573 of 562892)\n",
      "2024-02-02 20:48:57,965 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E96 Validation  ----/8413, starting\n",
      "2024-02-02 20:48:58,077 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E96 Validation    16/8413, done at 2024-02-02 20:49:08, 0:00:10\n",
      "2024-02-02 20:48:58,352 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E96 Validation    64/8413, done at 2024-02-02 20:49:37, 0:00:39\n",
      "2024-02-02 20:48:58,565 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E96 Validation   256/8413, done at 2024-02-02 20:49:14, 0:00:16\n",
      "2024-02-02 20:48:59,383 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E96 Validation  1024/8413, done at 2024-02-02 20:49:08, 0:00:10\n",
      "2024-02-02 20:49:03,014 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E96 Validation  4096/8413, done at 2024-02-02 20:49:08, 0:00:10\n",
      "2024-02-02 20:49:08,128 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E96 Validation  8413/8413, done at 2024-02-02 20:49:08\n",
      "2024-02-02 20:49:08,130 INFO     pid:38964 __main__:011:logMetrics E96 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:49:08,134 INFO     pid:38964 __main__:072:logMetrics E96 val      0.6795 loss\n",
      "2024-02-02 20:49:08,134 INFO     pid:38964 __main__:097:logMetrics E96 val        58.0% correct, 0.5810 precision, 0.5765 recall, 0.5787 f1 score\n",
      "2024-02-02 20:49:08,135 INFO     pid:38964 __main__:112:logMetrics E96 val_neg   0.7128 loss,  58.4% correct (78626 of 134598)\n",
      "2024-02-02 20:49:08,135 INFO     pid:38964 __main__:128:logMetrics E96 val_pos   0.6462 loss,  57.7% correct (77602 of 134598)\n",
      "2024-02-02 20:49:08,147 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E97 Training ----/35181, starting\n",
      "2024-02-02 20:49:08,521 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E97 Training   32/35181, done at 2024-02-02 20:53:44, 0:04:36\n",
      "2024-02-02 20:49:08,835 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E97 Training  256/35181, done at 2024-02-02 20:50:24, 0:01:16\n",
      "2024-02-02 20:49:11,216 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E97 Training 2048/35181, done at 2024-02-02 20:49:58, 0:00:50\n",
      "2024-02-02 20:49:29,931 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E97 Training 16384/35181, done at 2024-02-02 20:49:54, 0:00:46\n",
      "2024-02-02 20:49:54,449 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E97 Training 35181/35181, done at 2024-02-02 20:49:54\n",
      "2024-02-02 20:49:54,874 INFO     pid:38964 __main__:011:logMetrics E97 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:49:54,909 INFO     pid:38964 __main__:072:logMetrics E97 trn      0.6756 loss\n",
      "2024-02-02 20:49:54,909 INFO     pid:38964 __main__:097:logMetrics E97 trn        57.9% correct, 0.5762 precision, 0.5972 recall, 0.5865 f1 score\n",
      "2024-02-02 20:49:54,910 INFO     pid:38964 __main__:112:logMetrics E97 trn_neg   0.6752 loss,  56.1% correct (315674 of 562892)\n",
      "2024-02-02 20:49:54,910 INFO     pid:38964 __main__:128:logMetrics E97 trn_pos   0.6760 loss,  59.7% correct (336150 of 562892)\n",
      "2024-02-02 20:49:54,944 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E97 Validation  ----/8413, starting\n",
      "2024-02-02 20:49:55,056 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E97 Validation    16/8413, done at 2024-02-02 20:50:04, 0:00:09\n",
      "2024-02-02 20:49:55,111 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E97 Validation    64/8413, done at 2024-02-02 20:50:04, 0:00:09\n",
      "2024-02-02 20:49:55,339 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E97 Validation   256/8413, done at 2024-02-02 20:50:04, 0:00:09\n",
      "2024-02-02 20:49:56,571 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E97 Validation  1024/8413, done at 2024-02-02 20:50:07, 0:00:12\n",
      "2024-02-02 20:50:00,185 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E97 Validation  4096/8413, done at 2024-02-02 20:50:05, 0:00:10\n",
      "2024-02-02 20:50:05,604 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E97 Validation  8413/8413, done at 2024-02-02 20:50:05\n",
      "2024-02-02 20:50:05,605 INFO     pid:38964 __main__:011:logMetrics E97 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:50:05,610 INFO     pid:38964 __main__:072:logMetrics E97 val      0.6800 loss\n",
      "2024-02-02 20:50:05,610 INFO     pid:38964 __main__:097:logMetrics E97 val        57.4% correct, 0.5598 precision, 0.6958 recall, 0.6204 f1 score\n",
      "2024-02-02 20:50:05,610 INFO     pid:38964 __main__:112:logMetrics E97 val_neg   0.7026 loss,  45.3% correct (60957 of 134598)\n",
      "2024-02-02 20:50:05,610 INFO     pid:38964 __main__:128:logMetrics E97 val_pos   0.6573 loss,  69.6% correct (93653 of 134598)\n",
      "2024-02-02 20:50:05,620 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E98 Training ----/35181, starting\n",
      "2024-02-02 20:50:05,783 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E98 Training   32/35181, done at 2024-02-02 20:50:48, 0:00:42\n",
      "2024-02-02 20:50:06,092 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E98 Training  256/35181, done at 2024-02-02 20:50:53, 0:00:47\n",
      "2024-02-02 20:50:08,383 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E98 Training 2048/35181, done at 2024-02-02 20:50:51, 0:00:45\n",
      "2024-02-02 20:50:27,159 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E98 Training 16384/35181, done at 2024-02-02 20:50:51, 0:00:45\n",
      "2024-02-02 20:50:50,874 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E98 Training 35181/35181, done at 2024-02-02 20:50:50\n",
      "2024-02-02 20:50:51,282 INFO     pid:38964 __main__:011:logMetrics E98 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:50:51,319 INFO     pid:38964 __main__:072:logMetrics E98 trn      0.6751 loss\n",
      "2024-02-02 20:50:51,320 INFO     pid:38964 __main__:097:logMetrics E98 trn        57.9% correct, 0.5766 precision, 0.5955 recall, 0.5859 f1 score\n",
      "2024-02-02 20:50:51,320 INFO     pid:38964 __main__:112:logMetrics E98 trn_neg   0.6748 loss,  56.3% correct (316727 of 562892)\n",
      "2024-02-02 20:50:51,320 INFO     pid:38964 __main__:128:logMetrics E98 trn_pos   0.6753 loss,  59.5% correct (335194 of 562892)\n",
      "2024-02-02 20:50:51,353 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E98 Validation  ----/8413, starting\n",
      "2024-02-02 20:50:51,463 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E98 Validation    16/8413, done at 2024-02-02 20:51:01, 0:00:10\n",
      "2024-02-02 20:50:51,521 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E98 Validation    64/8413, done at 2024-02-02 20:51:01, 0:00:10\n",
      "2024-02-02 20:50:51,766 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E98 Validation   256/8413, done at 2024-02-02 20:51:02, 0:00:10\n",
      "2024-02-02 20:50:52,790 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E98 Validation  1024/8413, done at 2024-02-02 20:51:02, 0:00:11\n",
      "2024-02-02 20:50:56,572 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E98 Validation  4096/8413, done at 2024-02-02 20:51:01, 0:00:10\n",
      "2024-02-02 20:51:01,786 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E98 Validation  8413/8413, done at 2024-02-02 20:51:01\n",
      "2024-02-02 20:51:01,788 INFO     pid:38964 __main__:011:logMetrics E98 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:51:01,792 INFO     pid:38964 __main__:072:logMetrics E98 val      0.6792 loss\n",
      "2024-02-02 20:51:01,792 INFO     pid:38964 __main__:097:logMetrics E98 val        56.5% correct, 0.5484 precision, 0.7401 recall, 0.6300 f1 score\n",
      "2024-02-02 20:51:01,792 INFO     pid:38964 __main__:112:logMetrics E98 val_neg   0.7008 loss,  39.1% correct (52563 of 134598)\n",
      "2024-02-02 20:51:01,792 INFO     pid:38964 __main__:128:logMetrics E98 val_pos   0.6576 loss,  74.0% correct (99615 of 134598)\n",
      "2024-02-02 20:51:01,802 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E99 Training ----/35181, starting\n",
      "2024-02-02 20:51:01,975 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E99 Training   32/35181, done at 2024-02-02 20:51:47, 0:00:45\n",
      "2024-02-02 20:51:02,294 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E99 Training  256/35181, done at 2024-02-02 20:51:51, 0:00:49\n",
      "2024-02-02 20:51:04,777 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E99 Training 2048/35181, done at 2024-02-02 20:51:50, 0:00:48\n",
      "2024-02-02 20:51:24,058 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E99 Training 16384/35181, done at 2024-02-02 20:51:49, 0:00:47\n",
      "2024-02-02 20:51:47,666 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E99 Training 35181/35181, done at 2024-02-02 20:51:47\n",
      "2024-02-02 20:51:48,084 INFO     pid:38964 __main__:011:logMetrics E99 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:51:48,118 INFO     pid:38964 __main__:072:logMetrics E99 trn      0.6744 loss\n",
      "2024-02-02 20:51:48,119 INFO     pid:38964 __main__:097:logMetrics E99 trn        58.1% correct, 0.5768 precision, 0.6076 recall, 0.5918 f1 score\n",
      "2024-02-02 20:51:48,119 INFO     pid:38964 __main__:112:logMetrics E99 trn_neg   0.6741 loss,  55.4% correct (311924 of 562892)\n",
      "2024-02-02 20:51:48,119 INFO     pid:38964 __main__:128:logMetrics E99 trn_pos   0.6748 loss,  60.8% correct (342034 of 562892)\n",
      "2024-02-02 20:51:48,151 INFO     pid:38964 myutil.util:130:enumerateWithEstimate E99 Validation  ----/8413, starting\n",
      "2024-02-02 20:51:48,261 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E99 Validation    16/8413, done at 2024-02-02 20:51:58, 0:00:10\n",
      "2024-02-02 20:51:48,339 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E99 Validation    64/8413, done at 2024-02-02 20:52:01, 0:00:12\n",
      "2024-02-02 20:51:48,562 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E99 Validation   256/8413, done at 2024-02-02 20:51:58, 0:00:10\n",
      "2024-02-02 20:51:49,600 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E99 Validation  1024/8413, done at 2024-02-02 20:51:59, 0:00:11\n",
      "2024-02-02 20:51:53,446 INFO     pid:38964 myutil.util:150:enumerateWithEstimate E99 Validation  4096/8413, done at 2024-02-02 20:51:58, 0:00:10\n",
      "2024-02-02 20:51:58,632 INFO     pid:38964 myutil.util:165:enumerateWithEstimate E99 Validation  8413/8413, done at 2024-02-02 20:51:58\n",
      "2024-02-02 20:51:58,634 INFO     pid:38964 __main__:011:logMetrics E99 StockPCTLabelPredictLSTM\n",
      "2024-02-02 20:51:58,638 INFO     pid:38964 __main__:072:logMetrics E99 val      0.6838 loss\n",
      "2024-02-02 20:51:58,638 INFO     pid:38964 __main__:097:logMetrics E99 val        57.1% correct, 0.5531 precision, 0.7382 recall, 0.6324 f1 score\n",
      "2024-02-02 20:51:58,638 INFO     pid:38964 __main__:112:logMetrics E99 val_neg   0.7702 loss,  40.4% correct (54329 of 134598)\n",
      "2024-02-02 20:51:58,639 INFO     pid:38964 __main__:128:logMetrics E99 val_pos   0.5975 loss,  73.8% correct (99363 of 134598)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time:1:32:19.607661\n"
     ]
    }
   ],
   "source": [
    "time_str = datetime.now().strftime(\"%Y-%m-%d_%H.%M.%S\")\n",
    "log_dir = f\"{log_dir_base}/{time_str}\"\n",
    "config = {\n",
    "    \"return_period\": 5,\n",
    "    \"seq_len\": 5,\n",
    "    \"lr\": 0.01,\n",
    "    \"momentum\": 0.11646759543664197,\n",
    "    \"optim_type\": 1,  # Adam\n",
    "    \"num_layers\": 4,\n",
    "    \"hidden_size\": 64,\n",
    "    \"num_fc_layers\": 1,\n",
    "    \"activation_type\": 2,  # Sigmoid\n",
    "}\n",
    "# epoch_num = 20\n",
    "# os.mkdir(log_dir)\n",
    "report_f1 = False\n",
    "print(log_dir)\n",
    "start = datetime.now()\n",
    "train_LSTM(config)\n",
    "print(f\"Elapsed time:{datetime.now() - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['seq_len', 'num_layers', 'hidden_size', 'num_fc_layers']\n",
      "Total count of configs = 16\n"
     ]
    }
   ],
   "source": [
    "search_space = {\n",
    "    \"return_period\": tune.grid_search([5]),  # [2,3,5,10]\n",
    "    \"seq_len\": tune.grid_search([3, 5]),  # 10]),\n",
    "    \"lr\": tune.grid_search([0.01]),  # [0.001, 0.01, 0.1]\n",
    "    \"momentum\": tune.uniform(0.1, 0.9),\n",
    "    \"optim_type\": tune.grid_search([1]),  # 1: Adam, 2: SGD\n",
    "    \"num_layers\": tune.grid_search([4, 8]),  # , 16]),  # [1, 2, 4, 8]\n",
    "    \"hidden_size\": tune.grid_search([32, 64]),  # , 128, 256]),  # [8, 16, 32, 64, 128]\n",
    "    \"num_fc_layers\": tune.grid_search([1, 2]),  # 1, 2, 3]),\n",
    "    \"activation_type\": tune.grid_search([2]),  # 1: ReLU(),  2: Sigmoid(),  3: Tanh()\n",
    "}\n",
    "\n",
    "turning_parameters = []\n",
    "total_configs = 1\n",
    "for k, v in search_space.items():\n",
    "    if (\n",
    "        type(v).__name__ == \"dict\"\n",
    "        and list(v.keys())[0] == \"grid_search\"\n",
    "        and len(list(v.values())[0]) > 1\n",
    "    ):\n",
    "        turning_parameters.append(k)\n",
    "        total_configs *= len(list(v.values())[0])\n",
    "print(turning_parameters)\n",
    "print(f\"Total count of configs = {total_configs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Tracked actor is not managed by this event manager: <TrackedActor 65205874685968341843178332314064884833>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/venv/ml4t/lib/python3.8/site-packages/ray/tune/tune.py:1002\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, storage_path, storage_filesystem, search_alg, scheduler, checkpoint_config, verbose, progress_reporter, log_to_file, trial_name_creator, trial_dirname_creator, sync_config, export_formats, max_failures, fail_fast, restore, resume, reuse_actors, raise_on_failed_trial, callbacks, max_concurrent_trials, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, chdir_to_trial_dir, local_dir, _remote, _remote_string_queue, _entrypoint)\u001b[0m\n\u001b[1;32m   1001\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mis_finished() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m experiment_interrupted_event\u001b[38;5;241m.\u001b[39mis_set():\n\u001b[0;32m-> 1002\u001b[0m     \u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1003\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m has_verbosity(Verbosity\u001b[38;5;241m.\u001b[39mV1_EXPERIMENT):\n",
      "File \u001b[0;32m~/venv/ml4t/lib/python3.8/site-packages/ray/tune/execution/tune_controller.py:728\u001b[0m, in \u001b[0;36mTuneController.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;66;03m# Handle one event\u001b[39;00m\n\u001b[0;32m--> 728\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_actor_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    729\u001b[0m     \u001b[38;5;66;03m# If there are no actors running, warn about potentially\u001b[39;00m\n\u001b[1;32m    730\u001b[0m     \u001b[38;5;66;03m# insufficient resources\u001b[39;00m\n\u001b[1;32m    731\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_actor_manager\u001b[38;5;241m.\u001b[39mnum_live_actors:\n",
      "File \u001b[0;32m~/venv/ml4t/lib/python3.8/site-packages/ray/air/execution/_internal/actor_manager.py:191\u001b[0m, in \u001b[0;36mRayActorManager.next\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m# We always try to start actors as this won't trigger an event callback\u001b[39;00m\n\u001b[0;32m--> 191\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_start_actors\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;66;03m# If an actor was killed, this was our event, and we return.\u001b[39;00m\n",
      "File \u001b[0;32m~/venv/ml4t/lib/python3.8/site-packages/ray/air/execution/_internal/actor_manager.py:361\u001b[0m, in \u001b[0;36mRayActorManager._try_start_actors\u001b[0;34m(self, max_actors)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;66;03m# Start Ray actor\u001b[39;00m\n\u001b[0;32m--> 361\u001b[0m actor \u001b[38;5;241m=\u001b[39m \u001b[43mremote_actor_cls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mremote\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;66;03m# Track\u001b[39;00m\n",
      "File \u001b[0;32m~/venv/ml4t/lib/python3.8/site-packages/ray/actor.py:753\u001b[0m, in \u001b[0;36mActorClass.options.<locals>.ActorOptionWrapper.remote\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    752\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mremote\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 753\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mactor_cls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_remote\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mupdated_options\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venv/ml4t/lib/python3.8/site-packages/ray/_private/auto_init_hook.py:22\u001b[0m, in \u001b[0;36mwrap_auto_init.<locals>.auto_init_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m auto_init_ray()\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venv/ml4t/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py:388\u001b[0m, in \u001b[0;36m_tracing_actor_creation.<locals>._invocation_actor_class_remote_span\u001b[0;34m(self, args, kwargs, *_args, **_kwargs)\u001b[0m\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_ray_trace_ctx\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs\n\u001b[0;32m--> 388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    390\u001b[0m class_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__ray_metadata__\u001b[38;5;241m.\u001b[39mclass_name\n",
      "File \u001b[0;32m~/venv/ml4t/lib/python3.8/site-packages/ray/actor.py:956\u001b[0m, in \u001b[0;36mActorClass._remote\u001b[0;34m(self, args, kwargs, **actor_options)\u001b[0m\n\u001b[1;32m    952\u001b[0m     \u001b[38;5;66;03m# After serialize / deserialize modified class, the __module__\u001b[39;00m\n\u001b[1;32m    953\u001b[0m     \u001b[38;5;66;03m# of modified class will be ray.cloudpickle.cloudpickle.\u001b[39;00m\n\u001b[1;32m    954\u001b[0m     \u001b[38;5;66;03m# So, here pass actor_creation_function_descriptor to make\u001b[39;00m\n\u001b[1;32m    955\u001b[0m     \u001b[38;5;66;03m# sure export actor class correct.\u001b[39;00m\n\u001b[0;32m--> 956\u001b[0m     \u001b[43mworker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_actor_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport_actor_class\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmeta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodified_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmeta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactor_creation_function_descriptor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmeta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod_meta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethods\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    962\u001b[0m resources \u001b[38;5;241m=\u001b[39m ray\u001b[38;5;241m.\u001b[39m_private\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mresources_from_ray_options(actor_options)\n",
      "File \u001b[0;32m~/venv/ml4t/lib/python3.8/site-packages/ray/_private/function_manager.py:531\u001b[0m, in \u001b[0;36mFunctionActorManager.export_actor_class\u001b[0;34m(self, Class, actor_creation_function_descriptor, actor_method_names)\u001b[0m\n\u001b[1;32m    522\u001b[0m actor_class_info \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    523\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: actor_creation_function_descriptor\u001b[38;5;241m.\u001b[39mclass_name\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m    524\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule\u001b[39m\u001b[38;5;124m\"\u001b[39m: actor_creation_function_descriptor\u001b[38;5;241m.\u001b[39mmodule_name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactor_method_names\u001b[39m\u001b[38;5;124m\"\u001b[39m: json\u001b[38;5;241m.\u001b[39mdumps(\u001b[38;5;28mlist\u001b[39m(actor_method_names)),\n\u001b[1;32m    529\u001b[0m }\n\u001b[0;32m--> 531\u001b[0m \u001b[43mcheck_oversized_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    532\u001b[0m \u001b[43m    \u001b[49m\u001b[43mactor_class_info\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclass\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[43m    \u001b[49m\u001b[43mactor_class_info\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclass_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    534\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mactor\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_worker\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    536\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_worker\u001b[38;5;241m.\u001b[39mgcs_client\u001b[38;5;241m.\u001b[39minternal_kv_put(\n\u001b[1;32m    539\u001b[0m     key, pickle\u001b[38;5;241m.\u001b[39mdumps(actor_class_info), \u001b[38;5;28;01mTrue\u001b[39;00m, KV_NAMESPACE_FUNCTION_TABLE\n\u001b[1;32m    540\u001b[0m )\n",
      "File \u001b[0;32m~/venv/ml4t/lib/python3.8/site-packages/ray/_private/utils.py:749\u001b[0m, in \u001b[0;36mcheck_oversized_function\u001b[0;34m(pickled, name, obj_type, worker)\u001b[0m\n\u001b[1;32m    738\u001b[0m error \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    739\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m is too large (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m MiB > FUNCTION_SIZE_ERROR_THRESHOLD=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    740\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m MiB). Check that its definition is not implicitly capturing a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    747\u001b[0m     ray_constants\u001b[38;5;241m.\u001b[39mFUNCTION_SIZE_ERROR_THRESHOLD \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1024\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1024\u001b[39m),\n\u001b[1;32m    748\u001b[0m )\n\u001b[0;32m--> 749\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(error)\n",
      "\u001b[0;31mValueError\u001b[0m: The actor ImplicitFunc is too large (144 MiB > FUNCTION_SIZE_ERROR_THRESHOLD=95 MiB). Check that its definition is not implicitly capturing a large array or other object in scope. Tip: use ray.put() to put large objects in the Ray object store.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 26\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# analysis = tune.run(\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#     train_LSTM,\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#     config=search_space,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m#     mode=\"max\",\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[1;32m     16\u001b[0m tuner \u001b[38;5;241m=\u001b[39m tune\u001b[38;5;241m.\u001b[39mTuner(\n\u001b[1;32m     17\u001b[0m     tune\u001b[38;5;241m.\u001b[39mwith_resources(\n\u001b[1;32m     18\u001b[0m         tune\u001b[38;5;241m.\u001b[39mwith_parameters(train_LSTM), resources\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpu\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0.5\u001b[39m}\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m     param_space\u001b[38;5;241m=\u001b[39msearch_space,\n\u001b[1;32m     25\u001b[0m )\n\u001b[0;32m---> 26\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venv/ml4t/lib/python3.8/site-packages/ray/tune/tuner.py:381\u001b[0m, in \u001b[0;36mTuner.fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_ray_client:\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 381\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_local_tuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    382\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TuneError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    383\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m TuneError(\n\u001b[1;32m    384\u001b[0m             _TUNER_FAILED_MSG\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    385\u001b[0m                 path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_local_tuner\u001b[38;5;241m.\u001b[39mget_experiment_checkpoint_dir()\n\u001b[1;32m    386\u001b[0m             )\n\u001b[1;32m    387\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m~/venv/ml4t/lib/python3.8/site-packages/ray/tune/impl/tuner_internal.py:509\u001b[0m, in \u001b[0;36mTunerInternal.fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    507\u001b[0m param_space \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_space)\n\u001b[1;32m    508\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_restored:\n\u001b[0;32m--> 509\u001b[0m     analysis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_space\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    511\u001b[0m     analysis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_resume(trainable, param_space)\n",
      "File \u001b[0;32m~/venv/ml4t/lib/python3.8/site-packages/ray/tune/impl/tuner_internal.py:628\u001b[0m, in \u001b[0;36mTunerInternal._fit_internal\u001b[0;34m(self, trainable, param_space)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fitting for a fresh Tuner.\"\"\"\u001b[39;00m\n\u001b[1;32m    616\u001b[0m args \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tune_run_arguments(trainable),\n\u001b[1;32m    618\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mdict\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tuner_kwargs,\n\u001b[1;32m    627\u001b[0m }\n\u001b[0;32m--> 628\u001b[0m analysis \u001b[38;5;241m=\u001b[39m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    630\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclear_remote_string_queue()\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m analysis\n",
      "File \u001b[0;32m~/venv/ml4t/lib/python3.8/site-packages/ray/tune/tune.py:1009\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, storage_path, storage_filesystem, search_alg, scheduler, checkpoint_config, verbose, progress_reporter, log_to_file, trial_name_creator, trial_dirname_creator, sync_config, export_formats, max_failures, fail_fast, restore, resume, reuse_actors, raise_on_failed_trial, callbacks, max_concurrent_trials, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, chdir_to_trial_dir, local_dir, _remote, _remote_string_queue, _entrypoint)\u001b[0m\n\u001b[1;32m   1007\u001b[0m             _report_air_progress(runner, air_progress_reporter)\n\u001b[1;32m   1008\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m-> 1009\u001b[0m     \u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcleanup\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1010\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m   1012\u001b[0m tune_taken \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m tune_start\n",
      "File \u001b[0;32m~/venv/ml4t/lib/python3.8/site-packages/ray/tune/execution/tune_controller.py:2017\u001b[0m, in \u001b[0;36mTuneController.cleanup\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2015\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcleanup\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   2016\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Cleanup trials and callbacks.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2017\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cleanup_trials\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2018\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mend_experiment_callbacks()\n",
      "File \u001b[0;32m~/venv/ml4t/lib/python3.8/site-packages/ray/tune/execution/tune_controller.py:835\u001b[0m, in \u001b[0;36mTuneController._cleanup_trials\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    830\u001b[0m     trial \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_actor_to_trial[tracked_actor]\n\u001b[1;32m    831\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m    832\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScheduling trial stop at end of experiment (trial \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrial\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m): \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    833\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtracked_actor\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    834\u001b[0m     )\n\u001b[0;32m--> 835\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_schedule_trial_stop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[38;5;66;03m# Clean up cached actors now\u001b[39;00m\n\u001b[1;32m    838\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cleanup_cached_actors(force_all\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/venv/ml4t/lib/python3.8/site-packages/ray/tune/execution/tune_controller.py:1446\u001b[0m, in \u001b[0;36mTuneController._schedule_trial_stop\u001b[0;34m(self, trial, exception)\u001b[0m\n\u001b[1;32m   1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_actor_to_trial\u001b[38;5;241m.\u001b[39mpop(tracked_actor)\n\u001b[1;32m   1444\u001b[0m trial\u001b[38;5;241m.\u001b[39mset_ray_actor(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 1446\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_remove_actor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtracked_actor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtracked_actor\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venv/ml4t/lib/python3.8/site-packages/ray/tune/execution/tune_controller.py:854\u001b[0m, in \u001b[0;36mTuneController._remove_actor\u001b[0;34m(self, tracked_actor)\u001b[0m\n\u001b[1;32m    853\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_remove_actor\u001b[39m(\u001b[38;5;28mself\u001b[39m, tracked_actor: TrackedActor):\n\u001b[0;32m--> 854\u001b[0m     stop_future \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_actor_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mschedule_actor_task\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtracked_actor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_return_future\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    857\u001b[0m     now \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_actor_manager\u001b[38;5;241m.\u001b[39mremove_actor(\n\u001b[1;32m    860\u001b[0m         tracked_actor, kill\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, stop_future\u001b[38;5;241m=\u001b[39mstop_future\n\u001b[1;32m    861\u001b[0m     ):\n\u001b[1;32m    862\u001b[0m         \u001b[38;5;66;03m# If the actor was previously alive, track\u001b[39;00m\n",
      "File \u001b[0;32m~/venv/ml4t/lib/python3.8/site-packages/ray/air/execution/_internal/actor_manager.py:725\u001b[0m, in \u001b[0;36mRayActorManager.schedule_actor_task\u001b[0;34m(self, tracked_actor, method_name, args, kwargs, on_result, on_error, _return_future)\u001b[0m\n\u001b[1;32m    722\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tracked_actor \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_live_actors_to_ray_actors_resources:\n\u001b[1;32m    723\u001b[0m     \u001b[38;5;66;03m# Actor is not started, yet\u001b[39;00m\n\u001b[1;32m    724\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tracked_actor \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pending_actors_to_attrs:\n\u001b[0;32m--> 725\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    726\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTracked actor is not managed by this event manager: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    727\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtracked_actor\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    728\u001b[0m         )\n\u001b[1;32m    730\u001b[0m     \u001b[38;5;66;03m# Cache tasks for future execution\u001b[39;00m\n\u001b[1;32m    731\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pending_actors_to_enqueued_actor_tasks[tracked_actor]\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m    732\u001b[0m         (tracked_actor_task, method_name, args, kwargs)\n\u001b[1;32m    733\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Tracked actor is not managed by this event manager: <TrackedActor 65205874685968341843178332314064884833>"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=Warning)\n",
    "\n",
    "time_str = datetime.now().strftime(\"%Y-%m-%d_%H.%M.%S\")\n",
    "log_dir = f\"{log_dir_base}/{time_str}\"\n",
    "os.mkdir(log_dir)\n",
    "# analysis = tune.run(\n",
    "#     train_LSTM,\n",
    "#     config=search_space,\n",
    "#     resources_per_trial={\"cpu\": 0.5, \"gpu\": 0.5},\n",
    "#     metric=\"f1_score\",\n",
    "#     mode=\"max\",\n",
    "# )\n",
    "tuner = tune.Tuner(\n",
    "    tune.with_resources(\n",
    "        tune.with_parameters(train_LSTM), resources={\"cpu\": 0.5, \"gpu\": 0.5}\n",
    "    ),\n",
    "    tune_config=tune.TuneConfig(\n",
    "        metric=\"f1_score\",\n",
    "        mode=\"max\",\n",
    "    ),\n",
    "    param_space=search_space,\n",
    ")\n",
    "results = tuner.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    mean_accuracy     trial_id\n",
      "0           0.760  d8976_00000\n",
      "1           0.770  d8976_00001\n",
      "2           0.781  d8976_00002\n",
      "3           0.775  d8976_00003\n",
      "4           0.782  d8976_00004\n",
      "5           0.760  d8976_00005\n",
      "6           0.750  d8976_00006\n",
      "7           0.763  d8976_00007\n",
      "8           0.774  d8976_00008\n",
      "9           0.753  d8976_00009\n",
      "10          0.750  d8976_00010\n",
      "11          0.753  d8976_00011\n",
      "12          0.764  d8976_00012\n",
      "13          0.758  d8976_00013\n",
      "14          0.775  d8976_00014\n",
      "15          0.777  d8976_00015\n",
      "16          0.760  d8976_00016\n",
      "17          0.760  d8976_00017\n",
      "18          0.758  d8976_00018\n",
      "19          0.758  d8976_00019\n",
      "20          0.755  d8976_00020\n",
      "21          0.761  d8976_00021\n",
      "22          0.738  d8976_00022\n",
      "23          0.757  d8976_00023\n",
      "24          0.758  d8976_00024\n",
      "25          0.767  d8976_00025\n",
      "26          0.762  d8976_00026\n",
      "27          0.767  d8976_00027\n",
      "28          0.764  d8976_00028\n",
      "29          0.764  d8976_00029\n",
      "30          0.768  d8976_00030\n",
      "31          0.765  d8976_00031\n",
      "32          0.767  d8976_00032\n",
      "33          0.763  d8976_00033\n",
      "34          0.757  d8976_00034\n",
      "35          0.760  d8976_00035\n",
      "36          0.769  d8976_00036\n",
      "37          0.767  d8976_00037\n",
      "38          0.767  d8976_00038\n",
      "39          0.765  d8976_00039\n",
      "40          0.765  d8976_00040\n",
      "41          0.762  d8976_00041\n",
      "42          0.756  d8976_00042\n",
      "43          0.759  d8976_00043\n",
      "44          0.768  d8976_00044\n",
      "45          0.764  d8976_00045\n",
      "46          0.762  d8976_00046\n",
      "47          0.759  d8976_00047\n"
     ]
    }
   ],
   "source": [
    "accuracy_list = []\n",
    "trial_list = list(analysis.trial_dataframes.values())\n",
    "for i, trial in enumerate(trial_list):\n",
    "    if trial.empty == False:\n",
    "        d = pd.DataFrame.from_dict(\n",
    "            {\n",
    "                \"mean_accuracy\": trial.describe().loc[\"mean\", \"mean_accuracy\"],\n",
    "                \"trial_id\": trial.loc[0:0, \"trial_id\"],\n",
    "            }\n",
    "        )\n",
    "    else:\n",
    "        d = pd.DataFrame.from_dict({\"mean_accuracy\": [np.NaN], \"trial_id\": [np.NaN]})\n",
    "    accuracy_list.append(d)\n",
    "accuracy_df = pd.concat(accuracy_list)\n",
    "accuracy_df = accuracy_df.reset_index().loc[:, [\"mean_accuracy\", \"trial_id\"]]\n",
    "print(accuracy_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    return_period  seq_len    lr  momentum  optim_type  num_layers  hidden_size  num_fc_layers  activation_type\n",
      "0               5        5 0.010     0.146           1           4           32              1                1\n",
      "1               5        5 0.010     0.793           1           4           32              1                2\n",
      "2               5        5 0.010     0.581           1           4           32              1                3\n",
      "3               5        5 0.010     0.666           1           4           64              1                1\n",
      "4               5        5 0.010     0.116           1           4           64              1                2\n",
      "5               5        5 0.010     0.876           1           4           64              1                3\n",
      "6               5        5 0.010     0.766           1           4          128              1                1\n",
      "7               5        5 0.010     0.270           1           4          128              1                2\n",
      "8               5        5 0.010     0.245           1           4          128              1                3\n",
      "9               5        5 0.010     0.247           1           4          256              1                1\n",
      "10              5        5 0.010     0.343           1           4          256              1                2\n",
      "11              5        5 0.010     0.520           1           4          256              1                3\n",
      "12              5        5 0.010     0.446           1           4           32              2                1\n",
      "13              5        5 0.010     0.333           1           4           32              2                2\n",
      "14              5        5 0.010     0.589           1           4           32              2                3\n",
      "15              5        5 0.010     0.212           1           4           64              2                1\n",
      "16              5        5 0.010     0.334           1           4           64              2                2\n",
      "17              5        5 0.010     0.393           1           4           64              2                3\n",
      "18              5        5 0.010     0.465           1           4          128              2                1\n",
      "19              5        5 0.010     0.728           1           4          128              2                2\n",
      "20              5        5 0.010     0.260           1           4          128              2                3\n",
      "21              5        5 0.010     0.511           1           4          256              2                1\n",
      "22              5        5 0.010     0.574           1           4          256              2                2\n",
      "23              5        5 0.010     0.137           1           4          256              2                3\n",
      "24              5        5 0.010     0.586           1          16           32              1                1\n",
      "25              5        5 0.010     0.236           1          16           32              1                2\n",
      "26              5        5 0.010     0.152           1          16           32              1                3\n",
      "27              5        5 0.010     0.859           1          16           64              1                1\n",
      "28              5        5 0.010     0.873           1          16           64              1                2\n",
      "29              5        5 0.010     0.747           1          16           64              1                3\n",
      "30              5        5 0.010     0.344           1          16          128              1                1\n",
      "31              5        5 0.010     0.178           1          16          128              1                2\n",
      "32              5        5 0.010     0.647           1          16          128              1                3\n",
      "33              5        5 0.010     0.452           1          16          256              1                1\n",
      "34              5        5 0.010     0.198           1          16          256              1                2\n",
      "35              5        5 0.010     0.496           1          16          256              1                3\n",
      "36              5        5 0.010     0.128           1          16           32              2                1\n",
      "37              5        5 0.010     0.827           1          16           32              2                2\n",
      "38              5        5 0.010     0.307           1          16           32              2                3\n",
      "39              5        5 0.010     0.630           1          16           64              2                1\n",
      "40              5        5 0.010     0.349           1          16           64              2                2\n",
      "41              5        5 0.010     0.516           1          16           64              2                3\n",
      "42              5        5 0.010     0.537           1          16          128              2                1\n",
      "43              5        5 0.010     0.248           1          16          128              2                2\n",
      "44              5        5 0.010     0.876           1          16          128              2                3\n",
      "45              5        5 0.010     0.720           1          16          256              2                1\n",
      "46              5        5 0.010     0.852           1          16          256              2                2\n",
      "47              5        5 0.010     0.816           1          16          256              2                3\n",
      "    mean_accuracy     trial_id  return_period  seq_len    lr  momentum  optim_type  num_layers  hidden_size  num_fc_layers  activation_type\n",
      "0           0.760  d8976_00000              5        5 0.010     0.146           1           4           32              1                1\n",
      "1           0.770  d8976_00001              5        5 0.010     0.793           1           4           32              1                2\n",
      "2           0.781  d8976_00002              5        5 0.010     0.581           1           4           32              1                3\n",
      "3           0.775  d8976_00003              5        5 0.010     0.666           1           4           64              1                1\n",
      "4           0.782  d8976_00004              5        5 0.010     0.116           1           4           64              1                2\n",
      "5           0.760  d8976_00005              5        5 0.010     0.876           1           4           64              1                3\n",
      "6           0.750  d8976_00006              5        5 0.010     0.766           1           4          128              1                1\n",
      "7           0.763  d8976_00007              5        5 0.010     0.270           1           4          128              1                2\n",
      "8           0.774  d8976_00008              5        5 0.010     0.245           1           4          128              1                3\n",
      "9           0.753  d8976_00009              5        5 0.010     0.247           1           4          256              1                1\n",
      "10          0.750  d8976_00010              5        5 0.010     0.343           1           4          256              1                2\n",
      "11          0.753  d8976_00011              5        5 0.010     0.520           1           4          256              1                3\n",
      "12          0.764  d8976_00012              5        5 0.010     0.446           1           4           32              2                1\n",
      "13          0.758  d8976_00013              5        5 0.010     0.333           1           4           32              2                2\n",
      "14          0.775  d8976_00014              5        5 0.010     0.589           1           4           32              2                3\n",
      "15          0.777  d8976_00015              5        5 0.010     0.212           1           4           64              2                1\n",
      "16          0.760  d8976_00016              5        5 0.010     0.334           1           4           64              2                2\n",
      "17          0.760  d8976_00017              5        5 0.010     0.393           1           4           64              2                3\n",
      "18          0.758  d8976_00018              5        5 0.010     0.465           1           4          128              2                1\n",
      "19          0.758  d8976_00019              5        5 0.010     0.728           1           4          128              2                2\n",
      "20          0.755  d8976_00020              5        5 0.010     0.260           1           4          128              2                3\n",
      "21          0.761  d8976_00021              5        5 0.010     0.511           1           4          256              2                1\n",
      "22          0.738  d8976_00022              5        5 0.010     0.574           1           4          256              2                2\n",
      "23          0.757  d8976_00023              5        5 0.010     0.137           1           4          256              2                3\n",
      "24          0.758  d8976_00024              5        5 0.010     0.586           1          16           32              1                1\n",
      "25          0.767  d8976_00025              5        5 0.010     0.236           1          16           32              1                2\n",
      "26          0.762  d8976_00026              5        5 0.010     0.152           1          16           32              1                3\n",
      "27          0.767  d8976_00027              5        5 0.010     0.859           1          16           64              1                1\n",
      "28          0.764  d8976_00028              5        5 0.010     0.873           1          16           64              1                2\n",
      "29          0.764  d8976_00029              5        5 0.010     0.747           1          16           64              1                3\n",
      "30          0.768  d8976_00030              5        5 0.010     0.344           1          16          128              1                1\n",
      "31          0.765  d8976_00031              5        5 0.010     0.178           1          16          128              1                2\n",
      "32          0.767  d8976_00032              5        5 0.010     0.647           1          16          128              1                3\n",
      "33          0.763  d8976_00033              5        5 0.010     0.452           1          16          256              1                1\n",
      "34          0.757  d8976_00034              5        5 0.010     0.198           1          16          256              1                2\n",
      "35          0.760  d8976_00035              5        5 0.010     0.496           1          16          256              1                3\n",
      "36          0.769  d8976_00036              5        5 0.010     0.128           1          16           32              2                1\n",
      "37          0.767  d8976_00037              5        5 0.010     0.827           1          16           32              2                2\n",
      "38          0.767  d8976_00038              5        5 0.010     0.307           1          16           32              2                3\n",
      "39          0.765  d8976_00039              5        5 0.010     0.630           1          16           64              2                1\n",
      "40          0.765  d8976_00040              5        5 0.010     0.349           1          16           64              2                2\n",
      "41          0.762  d8976_00041              5        5 0.010     0.516           1          16           64              2                3\n",
      "42          0.756  d8976_00042              5        5 0.010     0.537           1          16          128              2                1\n",
      "43          0.759  d8976_00043              5        5 0.010     0.248           1          16          128              2                2\n",
      "44          0.768  d8976_00044              5        5 0.010     0.876           1          16          128              2                3\n",
      "45          0.764  d8976_00045              5        5 0.010     0.720           1          16          256              2                1\n",
      "46          0.762  d8976_00046              5        5 0.010     0.852           1          16          256              2                2\n",
      "47          0.759  d8976_00047              5        5 0.010     0.816           1          16          256              2                3\n",
      "    mean_accuracy     trial_id  return_period  seq_len    lr  momentum  optim_type  num_layers  hidden_size  num_fc_layers  activation_type\n",
      "4           0.782  d8976_00004              5        5 0.010     0.116           1           4           64              1                2\n",
      "2           0.781  d8976_00002              5        5 0.010     0.581           1           4           32              1                3\n",
      "15          0.777  d8976_00015              5        5 0.010     0.212           1           4           64              2                1\n",
      "3           0.775  d8976_00003              5        5 0.010     0.666           1           4           64              1                1\n",
      "14          0.775  d8976_00014              5        5 0.010     0.589           1           4           32              2                3\n",
      "8           0.774  d8976_00008              5        5 0.010     0.245           1           4          128              1                3\n",
      "1           0.770  d8976_00001              5        5 0.010     0.793           1           4           32              1                2\n",
      "36          0.769  d8976_00036              5        5 0.010     0.128           1          16           32              2                1\n",
      "44          0.768  d8976_00044              5        5 0.010     0.876           1          16          128              2                3\n",
      "30          0.768  d8976_00030              5        5 0.010     0.344           1          16          128              1                1\n",
      "32          0.767  d8976_00032              5        5 0.010     0.647           1          16          128              1                3\n",
      "27          0.767  d8976_00027              5        5 0.010     0.859           1          16           64              1                1\n",
      "37          0.767  d8976_00037              5        5 0.010     0.827           1          16           32              2                2\n",
      "38          0.767  d8976_00038              5        5 0.010     0.307           1          16           32              2                3\n",
      "25          0.767  d8976_00025              5        5 0.010     0.236           1          16           32              1                2\n",
      "39          0.765  d8976_00039              5        5 0.010     0.630           1          16           64              2                1\n",
      "40          0.765  d8976_00040              5        5 0.010     0.349           1          16           64              2                2\n",
      "31          0.765  d8976_00031              5        5 0.010     0.178           1          16          128              1                2\n",
      "45          0.764  d8976_00045              5        5 0.010     0.720           1          16          256              2                1\n",
      "29          0.764  d8976_00029              5        5 0.010     0.747           1          16           64              1                3\n",
      "12          0.764  d8976_00012              5        5 0.010     0.446           1           4           32              2                1\n",
      "28          0.764  d8976_00028              5        5 0.010     0.873           1          16           64              1                2\n",
      "7           0.763  d8976_00007              5        5 0.010     0.270           1           4          128              1                2\n",
      "33          0.763  d8976_00033              5        5 0.010     0.452           1          16          256              1                1\n",
      "46          0.762  d8976_00046              5        5 0.010     0.852           1          16          256              2                2\n",
      "41          0.762  d8976_00041              5        5 0.010     0.516           1          16           64              2                3\n",
      "26          0.762  d8976_00026              5        5 0.010     0.152           1          16           32              1                3\n",
      "21          0.761  d8976_00021              5        5 0.010     0.511           1           4          256              2                1\n",
      "16          0.760  d8976_00016              5        5 0.010     0.334           1           4           64              2                2\n",
      "5           0.760  d8976_00005              5        5 0.010     0.876           1           4           64              1                3\n",
      "17          0.760  d8976_00017              5        5 0.010     0.393           1           4           64              2                3\n",
      "0           0.760  d8976_00000              5        5 0.010     0.146           1           4           32              1                1\n",
      "35          0.760  d8976_00035              5        5 0.010     0.496           1          16          256              1                3\n",
      "47          0.759  d8976_00047              5        5 0.010     0.816           1          16          256              2                3\n",
      "43          0.759  d8976_00043              5        5 0.010     0.248           1          16          128              2                2\n",
      "18          0.758  d8976_00018              5        5 0.010     0.465           1           4          128              2                1\n",
      "13          0.758  d8976_00013              5        5 0.010     0.333           1           4           32              2                2\n",
      "24          0.758  d8976_00024              5        5 0.010     0.586           1          16           32              1                1\n",
      "19          0.758  d8976_00019              5        5 0.010     0.728           1           4          128              2                2\n",
      "34          0.757  d8976_00034              5        5 0.010     0.198           1          16          256              1                2\n",
      "23          0.757  d8976_00023              5        5 0.010     0.137           1           4          256              2                3\n",
      "42          0.756  d8976_00042              5        5 0.010     0.537           1          16          128              2                1\n",
      "20          0.755  d8976_00020              5        5 0.010     0.260           1           4          128              2                3\n",
      "11          0.753  d8976_00011              5        5 0.010     0.520           1           4          256              1                3\n",
      "9           0.753  d8976_00009              5        5 0.010     0.247           1           4          256              1                1\n",
      "6           0.750  d8976_00006              5        5 0.010     0.766           1           4          128              1                1\n",
      "10          0.750  d8976_00010              5        5 0.010     0.343           1           4          256              1                2\n",
      "22          0.738  d8976_00022              5        5 0.010     0.574           1           4          256              2                2\n",
      "/mnt/AIWorkSpace/work/fin-ml/runs/StockPCTLabelPredictLSTM/2024-01-31_07.46.06/5_5_0.01_0.11646759543664197_1_4_64_1_2.pt\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "config_df = pd.DataFrame(analysis.get_all_configs().values())\n",
    "print(config_df)\n",
    "\n",
    "results = pd.concat([accuracy_df, config_df], axis=1)\n",
    "print(results)\n",
    "\n",
    "sorted_results = results.sort_values(by=\"mean_accuracy\", ascending=False)\n",
    "print(sorted_results.head(100))\n",
    "sorted_results_file = f\"{log_dir}/sorted_results.csv\"\n",
    "sorted_results.to_csv(sorted_results_file)\n",
    "\n",
    "best_config = config_df.iloc[sorted_results.index[0]]\n",
    "id_str = \"_\".join(str(v) if v < 1 else f\"{v:g}\" for v in best_config.to_list())\n",
    "best_model_name = f\"{log_dir}/{id_str}.pt\"\n",
    "print(best_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/AIWorkSpace/work/fin-ml/runs/StockPCTLabelPredictLSTM/StockPCTLabelPredictLSTM.pt'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.copy(best_model_name, f\"{log_dir_base}/{task_name}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x200 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x200 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracy_desc = sorted_results[\"mean_accuracy\"].astype(\"float32\").describe()\n",
    "xlimit_range = [\n",
    "    accuracy_desc[\"min\"] - accuracy_desc[\"std\"],\n",
    "    accuracy_desc[\"max\"] + accuracy_desc[\"std\"],\n",
    "]\n",
    "for hperparameter_name in turning_parameters:\n",
    "    parameter_group = sorted_results.groupby(hperparameter_name)\n",
    "    fix, axs = pyplot.subplots(\n",
    "        1,\n",
    "        len(parameter_group),\n",
    "        layout=\"constrained\",\n",
    "        sharex=False,\n",
    "        sharey=True,\n",
    "        figsize=(12, 2),\n",
    "    )\n",
    "    for i, g in enumerate(parameter_group):\n",
    "        g[1][\"mean_accuracy\"].astype(\"float32\").plot(\n",
    "            kind=\"hist\", bins=50, subplots=True, sharex=False, sharey=True, ax=axs[i]\n",
    "        )\n",
    "        axs[i].set_title(f\"{hperparameter_name}_{g[0]}\")\n",
    "\n",
    "pyplot.xlim(xlimit_range)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0                           4\n",
      "mean_accuracy       0.7823684782608694\n",
      "trial_id                   d8976_00004\n",
      "return_period                        5\n",
      "seq_len                              5\n",
      "lr                                0.01\n",
      "momentum           0.11646759543664197\n",
      "optim_type                           1\n",
      "num_layers                           4\n",
      "hidden_size                         64\n",
      "num_fc_layers                        1\n",
      "activation_type                      2\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "sorted_results_file = f\"{log_dir}/sorted_results.csv\"\n",
    "sorted_results = pd.read_csv(sorted_results_file, dtype=\"str\")\n",
    "best_config = sorted_results.loc[0]\n",
    "print(best_config)\n",
    "# id_str_of_best = f\"5_5_0.01_{best_config.momentum}_{best_config.optim_type}_{best_config.num_layers}_{best_config.hidden_size}_{best_config.num_fc_layers}_{best_config.activation_type}\"\n",
    "# best_model_name = f\"/mnt/AIWorkSpace/work/fin-ml/runs/{_TARGET_STK}/{time_str}/{id_str_of_best}.pt\"\n",
    "# print(best_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.87\n",
      "Test Accuracy: 0.76500\n",
      "Train F1: 0.00\n",
      "Test F1: 0.00000\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "pd.set_option(\"display.precision\", 5)\n",
    "\n",
    "model, config = load_model(f\"{log_dir_base}/{task_name}.pt\")\n",
    "model.to(device)\n",
    "\n",
    "train_loader, test_loader, features_size = prepare_dataloader(config[\"return_period\"])\n",
    "model.eval()\n",
    "\n",
    "(trainAccuracy, trainF1) = eval_dl_method(model, train_loader, device=device)\n",
    "(testAccuracy, testF1) = eval_dl_method(model, test_loader, device=device)\n",
    "print(f\"Train Accuracy: {trainAccuracy:.2f}\\nTest Accuracy: {testAccuracy:.5f}\")\n",
    "print(f\"Train F1: {trainF1:.2f}\\nTest F1: {testF1:.5f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml4t",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
